[{"content":" *Spring Security in Action을 읽고 작성했습니다.\nhttps://product.kyobobook.co.kr/detail/S000061695014\nSpring Security와 구성 요소 Spring Security는 스프링 프로젝트의 사실상 표준(defacto)입니다. 보안에 관련된 사전 구성 요소가 제공되며, 필요에 따라 일부 구성 요소만 재정의하여 사용할 수 있습니다.\nSpring Security 의존성을 프로젝트에 추가하고 애플리케이션을 시작하면 아래와 같은 메시지를 확인할 수 있습니다.\nUsing generated security password: 41632cba-2835-43e3-85c8-3aeac7ce686a This generated password is for development use only. Your security configuration must be updated before running your application in production. 구성 요소를 재정의 하지 않으면 위와 같이 기본 사용자 user와 암호(UUID)를 제공합니다. 애플리케이션의 엔드포인트를 호출하기 위해서는 Basic Auth를 사용하여 인증해야 합니다.\n# 인증을 사용한 경우 curl -u user:41632cba-2835-43e3-85c8-3aeac7ce686a http://localhost:8080/hello \u0026lt; Hello! # 인증을 사용하지 않은 경우 curl -v -X GET http://localhost:8080/hello \u0026lt; ... \u0026lt; HTTP/1.1 401 \u0026lt; ... 위와 같은 기본 사용자와 애플리케이션이 시작될 때 발급되는 암호를 이용한 인증은 사전 구성된 UserDetailsService, PasswordEncoder를 통해 구현됩니다.\n가장 기본적인 Spring Security의 구성 요소는 아래와 같습니다. AuthenticationProvider: 인증 논리를 정의하고 사용자와 암호의 관리를 위임합니다. UserDetailsService: 사용자에 대한 세부 정보를 제공합니다. PasswordEncoder: 인호를 인코딩하며, 암호가 기존 인코딩과 일치하는지 검증합니다. 기본 구성 요소 재정의 기본 구성 요소를 재정의하여 상황에 맞게 인증을 구현하고 보안을 적용할 수 있습니다. 기본 구성 요소는 직접 구현하여 만들거나, Spring Security에서 재공하는 구현을 사용할 수 있습니다. UserDetailsService와 PasswordEncoder는 가장 기본적인 구성 요소로, 인증에 이용되며 대부분의 애플리케이션은 이 두 구성 요소를 재정의합니다. *\u0026ldquo;hello!\u0026ldquo;응답을 반환해주는 /hello 엔드포인트를 구현했다고 가정합니다.\nPasswordEncoder 재정의 먼저 PasswordEncoder부터 재정의해보겠습니다. 이 구성 요소는 암호를 인코딩하는 정책에 관한 내용을 설정합니다. BCryptPasswordEncoder는 Spring Security에서 제공하는 권장 구현입니다. @Bean public PasswordEncoder passwordEncoder() { int strength = 10; // the log rounds to use, between 4 and 31 return new BCryptPasswordEncoder(strength); } UserDetailsService 재정의 UserDetailService는 사용자의 이름, 암호 등 정보를 제공해주며, 단 하나의 read-only 메서드를 제공합니다. UserDetails loadUserByUsername(String username) throws UsernameNotFoundException; Spring Security는 InMemoryUserDetailsManager 구현을 제공해줍니다. 이 구현은 메모리에 자격 증명을 저장해서 Spring Security가 요청을 인증할 때 사용할 수 있게 해줍니다. InMemoryUserDetailsManager 구현은 예제나 개념 증명 또는 테스트 용도로 사용하기 편리한 구현입니다.\n상용 환경에서의 사용은 권장하지 않습니다.\n@Bean public UserDetailsService userDetailsService(PasswordEncoder passwordEncoder) { UserDetails user = User.builder() .username(\u0026#34;user\u0026#34;) .password(passwordEncoder.encode(\u0026#34;password\u0026#34;)) .roles(\u0026#34;USER\u0026#34;) .build(); return new InMemoryUserDetailsManager(user); 이제 기본 구성 요소 재정의를 완료했습니다. 아래 명령어를 사용하면 InMemoryUserDetailsManager에 등록한 사용자를 이용해서 요청할 수 있습니다. curl -u user:password http://localhost:8080/hello \u0026lt; hello! 엔드포인트 권한 부여 구성 재정의 우리는 모든 엔드포인트를 보호할 필요는 없으며, 보안이 필요한 엔드포인트에 대해 다른 권한 부여 규칙을 선택할 수 있어야 합니다. 엔드포인트별 다른 권한 부여 규칙을 선택하기 위해 SecurityFilterChain을 사용합니다. SecurityFilterChain는 @Bean으로 등록해야 하며, SecurityFilterChain과 관련된 자동 구성 설정을 사용하기 위해서 @EnableWebSecurity을 사용해야 합니다. @Configuration @EnableWebSecurity public class SecurityConfiguration { @Bean public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception { return http.httpBasic(Customizer.withDefaults()) .authorizeHttpRequests(authorize -\u0026gt; authorize .requestMatchers(\u0026#34;/hello\u0026#34;).authenticated() .anyRequest().permitAll() ) .build(); } // UserDetailsService, PasswordEncoder } 위 설정은 /hello 엔드포인트에 대해 인증을 요구하며, 다른 엔드포인트는 인증을 요구하지 않습니다. curl http://localhost:8080/bye \u0026lt; bye! *Spring Security in Action에서 사용된 WebSecurityConfigurerAdapter는 Spring Security 5.7버전 이후로 지원이 중단되었습니다.\nAuthenticationProvider 재정의 위 내용처럼 Spring Security는 상당히 유연하므로 다양한 옵션을 선택할 수 있습니다. 그림을 다시 살펴봅시다. AuthenticationProvider는 인증 논리를 구현하고 사용자와 암호 관리를 UserDetailsService와 PasswordEncoder에 위임합니다.\n따라서 AuthenticationProvider를 재정의할 때는 주어진 구성 요소를 활용하는 것이 좋습니다. @Component @RequiredArgsConstructor public class CustomAuthenticationProvider implements AuthenticationProvider { private final UserDetailsService userDetailsService; private final PasswordEncoder passwordEncoder; @Override public Authentication authenticate(Authentication authentication) throws AuthenticationException { String username = authentication.getName(); String password = String.valueOf(authentication.getCredentials()); final UserDetails userDetails = userDetailsService.loadUserByUsername(username); // BCryptPasswordEncoder는 해쉬를 생성할 때마다 다른 salt 값을 사용합니다. // 따라서 matches 메서드를 사용해서 값이 일치하는지 검증해야 합니다. if (passwordEncoder.matches(password, userDetails.getPassword())) { return new UsernamePasswordAuthenticationToken(username, password, new ArrayList\u0026lt;\u0026gt;()); } throw new AuthenticationCredentialsNotFoundException(\u0026#34;Failed to authenticate\u0026#34;); } @Override // Authentication 객체가 지원하는 유형인지 확인합니다. public boolean supports(Class\u0026lt;?\u0026gt; authentication) { return authentication.equals(UsernamePasswordAuthenticationToken.class); } } ","permalink":"https://jo-minjun.github.io/notes/spring-security-in-action1/","summary":"*Spring Security in Action을 읽고 작성했습니다.\nhttps://product.kyobobook.co.kr/detail/S000061695014\nSpring Security와 구성 요소 Spring Security는 스프링 프로젝트의 사실상 표준(defacto)입니다. 보안에 관련된 사전 구성 요소가 제공되며, 필요에 따라 일부 구성 요소만 재정의하여 사용할 수 있습니다.\nSpring Security 의존성을 프로젝트에 추가하고 애플리케이션을 시작하면 아래와 같은 메시지를 확인할 수 있습니다.\nUsing generated security password: 41632cba-2835-43e3-85c8-3aeac7ce686a This generated password is for development use only. Your security configuration must be updated before running your application in production.","title":"Spring Security 기본 구성"},{"content":"ExecutorService ExecutorService를 사용하면 간단하게 스레드풀을 생성해서 병렬처리를 할 수 있습니다. Executors의 스태틱 메서드를 통해 간단하게 ExecutorService를 사용할 수 있습니다. 생성자를 이용해 커스텀하게 생성할 수도 있습니다. 이상적인 풀 사이즈 Task Type Ideal pool size Considerations CPU bound CPU Core count 얼마나 많은 작업이 같은 CPU에서 동작하는지 (Context switching 비용) I/O bound High 각 작업의 평균 대기 시간, 너무 큰 스레드 풀은 메모리 사용량을 고려해야함. int coreCount = Runtime.getRuntime().availableProcessors(); // int coreCount = taskExecutionProperties.getPool().getCoreSize(); ExecutorService service = Executors.newFixedThreadPool(coreCount); ThreadPoolExecutor 생성자 파라미터 Parameter Type Meaning corePoolSize Integer pool 최소 크기 maxPoolSize Integer pool 최대 크기 keepAliveTime + unit Long Thread를 idle 상태로 유지할 시간 (시간 초과 후에는 kill) workQueue BlockingQueue 작업을 저장해두는 큐 threadFactory ThreadFactory 새로운 Thread를 생성하는 Factory handler RejectedExecutionHandler 작업 실행이 거부되었을 때 사용할 callback core pool thread는 allowCoreThreadTimeOut(boolean value)를 true로 설정하지 않으면 Kill되지 않습니다. Executors 스태틱 메서드로 제공하는 풀의 종류 FixedThreadPool 고정된 수의 Thread를 가집니다. Blocking queue에 작업을 쌓아두고 Thread가 작업을 하나씩 수행합니다. CachedThreadPool 고정된 수의 Thread가 없습니다. 하나의 작업만 저장할 수 있는 Syncronus queue에 작업을 저장해두고 사용 가능한 Thread에 할당합니다. 사용 가능한 Thread가 없으면 새로운 Thread를 생성합니다. ScheduledThreadPool 고정된 수의 Thread를 가집니다. 작업을 일정 시간 지연 후에 수행하거나 일정 시간 간격으로 실행시킵니다. schedule(Runnable runnable, Long delay, TimeUnit timeunit) 일정 시간 뒤에 작업을 한번 실행시킵니다. scheduleAtFixedRate(Runnable runnable, Long delay, Long period, TimeUnit timeunit) 작업을 일정 시간 간격으로 반복적으로 실행시킵니다. scheduleAtFixedDelay(Runnable runnable, Long initDelay, Long period, TimeUnit timeunit) 이전 작업 완료 시 작업을 일정 시간 간격으로 반복적으로 실행시킵니다. SingleThreadExecutor 1개의 Thread를 가집니다. Blocking queue에 작업을 쌓아두고 Thread가 작업을 하나씩 수행합니다. Thread가 kill되면 다시 Thread생성됩니다. 풀 종류 별 Queue Pool Queue Type Why? FixedThreadPool LinkedBlockingQueue Unbounded queue에 모든 작업을 저장해두고, 한정된 Thread에서 작업을 순서대로 처리한다. SingleThreadExecutor LinkedBlockingQueue Unbounded queue에 모든 작업을 저장해두고, 한정된 Thread에서 작업을 순서대로 처리한다. CachedThreadPool SynchronousQueue Thread가 Unbounded이므로, 작업을 queue에 저장해두지 않아도 된다. 단 하나의 slot만 가진다. ScheduledThreadPool DelayWorkQueue 시간 딜레이를 가지는 특별한 queue. 작업이 거부되었을 때 정책 Policy Meaning AbortPolicy 제출된 새로운 작업이 RejectedExecutionException을 발생시킨다. 정책을 등록하지 않으면 기본으로 사용된다. DiscardPolicy 새로운 작업이 삭제된다. DiscardOldestPolicy 가장 오래된 작업이 삭제되고, 새로운 작업이 queue에 저장된다. CallerRunsPolicy 작업을 요청한 스레드에서 작업이 실행된다. 작업을 요청한 스레드에서 제출한 작업이 실행되는 동안 새로운 작업을 생성하지 못할 수 있다. 정책은 아래와 같은 생성자 방식으로 사용할 수 있습니다. ExecutorService executorService = new ThreadPoolExecutor( 10, // corePoolSize 100, // maxPoolSize 120, TimeUnit.SECONDS, // keepAliveTime new ArrayBlockingQueue\u0026lt;\u0026gt;(300), // Queue new DiscardPolicy() // Policy ); RejectedExecutionException 핸들링 \u0026lt;방법 1\u0026gt;\nExecutorService executorService = new ThreadPoolExecutor( 10, // corePoolSize 100, // maxPoolSize 120, TimeUnit.SECONDS, // keepAliveTime new ArrayBlockingQueue\u0026lt;\u0026gt;(300) // Queue ); try { executorService.execute(new Task()); } catch (RejectedExecutionException e) { log.error(\u0026#34;task rejected\u0026#34;, e) } \u0026lt;방법2\u0026gt;\nExecutorService executorService = new ThreadPoolExecutor( 10, // corePoolSize 100, // maxPoolSize 120, TimeUnit.SECONDS, // keepAliveTime new ArrayBlockingQueue\u0026lt;\u0026gt;(300), // Queue new CustomRejectionHandler() // 커스텀 핸들러를 Policy로 등록한다. ); executorService.execute(new Task()); public class CustomRejectionHandler implements RejectedExecutionHandler { @Overrid public void rejectedExecution(Runnable runnble, ThreadPoolExecutor executor) { // logging, operations to perform on rejection } } LifeCycle 메서드 ExecutorService executorService = new ThreadPoolExecutor( 10, // corePoolSize 100, // maxPoolSize 120, TimeUnit.SECONDS, // keepAliveTime new ArrayBlockingQueue\u0026lt;\u0026gt;(300) // Queue ); executorService.execute(new Task()); // init shutdown executorService.shutdown(); // throw RejectionExecutionException executorService.execute(new Task()); // return true, since shutdown has begun executorService.isShutdown(); // return true if all tasks are completed executorService.isTerminated(); // block until all tasks are completed or timeouted executorService.awaitTermination(10, TimeUnit.SECOND); // init shutdown and return all queued tasks List\u0026lt;Runnable\u0026gt; runnables = executorService.shutdownNow(); ","permalink":"https://jo-minjun.github.io/notes/about-executor-service/","summary":"ExecutorService ExecutorService를 사용하면 간단하게 스레드풀을 생성해서 병렬처리를 할 수 있습니다. Executors의 스태틱 메서드를 통해 간단하게 ExecutorService를 사용할 수 있습니다. 생성자를 이용해 커스텀하게 생성할 수도 있습니다. 이상적인 풀 사이즈 Task Type Ideal pool size Considerations CPU bound CPU Core count 얼마나 많은 작업이 같은 CPU에서 동작하는지 (Context switching 비용) I/O bound High 각 작업의 평균 대기 시간, 너무 큰 스레드 풀은 메모리 사용량을 고려해야함. int coreCount = Runtime.getRuntime().availableProcessors(); // int coreCount = taskExecutionProperties.","title":"Java ExecutorService에 대하여"},{"content":" 가능하다면 로컬 변수를 사용합니다. 프레임워크에 위임합니다. e.g. RequestContextHolder ConcurrentHashMap 같은 요소를 ThreadLocal 변수로 변경할 수 있는지 검토합니다. public class UserContextHolder { public static ThreadLocal\u0026lt;User\u0026gt; holder = new ThreadLocal(); } class HoldingService { public void holdUser() { // Set user for this thread User user = getUser(); UserContextHolder.holder.set(user); } } class SomeService { public void getUser() { // Get user for this thread User user = UserContextHolder.holder.get(); // Remove user; user no longer required UserContextHolder.holder.remove(); } } ","permalink":"https://jo-minjun.github.io/notes/thread-safe-tips/","summary":"가능하다면 로컬 변수를 사용합니다. 프레임워크에 위임합니다. e.g. RequestContextHolder ConcurrentHashMap 같은 요소를 ThreadLocal 변수로 변경할 수 있는지 검토합니다. public class UserContextHolder { public static ThreadLocal\u0026lt;User\u0026gt; holder = new ThreadLocal(); } class HoldingService { public void holdUser() { // Set user for this thread User user = getUser(); UserContextHolder.holder.set(user); } } class SomeService { public void getUser() { // Get user for this thread User user = UserContextHolder.holder.get(); // Remove user; user no longer required UserContextHolder.","title":"사소한 Thread-safe Tips"},{"content":"최근 인스타그램에서 정흥수님 릴스를 보았습니다. 말을 잘하는 방법에 대한 것인데요.\n저의 소통 습관이 좋지 않다는 것을 느끼면서, 인상이 깊어서 두고두고 보려고 남깁니다.\nhttps://instagram.com/heungburton?igshid=YmMyMTA2M2Y= 1. 아니, 근데 -\u0026gt; 어때 협업을 하면 의사소통으로 의견을 조율하고 의사결정을 합니다.\n이 과정에서 어쩔수 없는 의견 충돌이 발생하고, 저는 보통 \u0026lsquo;근데\u0026rsquo;로 시작하는 말을 많이 했습니다.\n근데, 그렇게하면 ~하지 않나요? 이렇게 해야될 것 같은데요? 제가 자주 사용한 이 문장은 상대방 말에 반박을 하면서 내 말이 옳다는 것을 강조합니다.\n이 말을 아래처럼 바꿀 수 있습니다.\n이렇게 하는게 어때요? 왜냐하면 ~할 것 같아요., ~할 것 같은데 이렇게 하는게 어때요?\n2. 과거 -\u0026gt; 미래 과거는 돌이킬 수 없습니다. 쿨하게 보내버리고 나무라지 않는겁니다.\n왜 그걸 이제 말하세요? 보다는 이제는 미리 말씀해주세요 처럼 미래형으로 바꿔서 말하는 겁니다.\n3. 불가능 -\u0026gt; 가능 1번과 마찬가지로 부정적인 말보다 긍정적인 말을 하는 겁니다.\n유튜브 보지 말고 공부해라.보다는 공부하고 유튜브 보자.로 말하는 겁니다.\n4. 혹시, 다름이 아니라 붙이지 않기 혹시는 다소 미심적인 부분이 있어서, 말하지를 주저할 때 사용하는 단어입니다.\n업무적으로 적극적으로 소통을 할 때는 혹시를 빼버리는 겁니다.\n혹시, 다음주에 시간 언제되세요?, 다름이 아니라, 업무 요청드릴게 있어서 연락드립니다. 처럼 말하기 보다는 적극적으로 다음주에 시간 언제 편하세요?, 업무 요청드릴게 있어서 연락드립니다. 시간 괜찮으세요로 바꿔서 말하는 겁니다.\n5. 이슈, 문제가 있으면 연락주세요. -\u0026gt; 언제든 연락주세요. 이렇게 이메일 끝에 이슈, 문제가 있으면 연락주세요.를 습관적으로 작성하는 사람들이 있습니다.\n이슈, 문제는 부정적인 느낌을 주는 단어입니다. 이슈, 문제가 있으면 연락주세요.라는 문장은 상대방에게 못했다는 느낌을 줄 수 있습니다.\n대신에 언제든 연락주세요., 궁금하거나 논의하고 싶은 점이 있으면 연락주세요.를 쓰는 겁니다.\n","permalink":"https://jo-minjun.github.io/doodles/%EB%8C%80%ED%99%94%EB%B2%95/","summary":"최근 인스타그램에서 정흥수님 릴스를 보았습니다. 말을 잘하는 방법에 대한 것인데요.\n저의 소통 습관이 좋지 않다는 것을 느끼면서, 인상이 깊어서 두고두고 보려고 남깁니다.\nhttps://instagram.com/heungburton?igshid=YmMyMTA2M2Y= 1. 아니, 근데 -\u0026gt; 어때 협업을 하면 의사소통으로 의견을 조율하고 의사결정을 합니다.\n이 과정에서 어쩔수 없는 의견 충돌이 발생하고, 저는 보통 \u0026lsquo;근데\u0026rsquo;로 시작하는 말을 많이 했습니다.\n근데, 그렇게하면 ~하지 않나요? 이렇게 해야될 것 같은데요? 제가 자주 사용한 이 문장은 상대방 말에 반박을 하면서 내 말이 옳다는 것을 강조합니다.","title":"대화법"},{"content":"Introduction 12 factor app은 서비스형 소프트웨어를 구성하기 위한 방법론입니다.\n개발 언어/프레임워크에 상관없는 이식성과 플랫폼 호환성 향상을 위한 디자인 원칙입니다. 애플리케이션의 수평적 확장이 용이하도록 합니다. 애플리케이션 확장 가능성 CI/CD에 용이성 플랫폼간 이식성 기본적인 기대치, 정책 설정 1. Codebase 형상관리 시스템에서 하나의 코드베이스를 관리하면서, 다수에 배포한다. 하나의 코드베이스에 여러개의 애플리케이션 코드가 있다면 12 factor app 위반입니다.\n코드베이스는 모든 배포에 사용되지만 각 배포는 다른 버전이 사용될 수 있습니다.\n2. Dependencies 의존성을 명시적으로 선언하고 분리한다. 의존성은 명시적으로 선언되어, 신규 개발자 또는 시스템 설정을 편리하게 해야합니다.\n대부분의 프로그래밍 언어는 패키징 시스템을 제공하기 때문에 새로 설정을 해야할 때는 언어와 패키지 매니저만 설치하면 됩니다.\n3. Config 설정값을 환경에 저장한다. 애플리케이션 설정값은 배포 환경에 따라 달라지는 값들입니다.\n데이터베이스 또는 Backing 서비스를 처리하는 리소스 Amazon S3 또는 트위터와 같은 외부 서비스에 대한 인증 정보 배포 환경 호스트 이름과 같은 값 4. Backing services Backing service Backing 서비스는 데이터베이스와, 메시징, 메일 서비스 등 통해 연결된 모든 서비스입니다.\n12 factor app은 Backing 서비스를 모두 리소스로 취급하고, 설정에서 값을 읽어서 처리하여 느슨하게 연결합니다.\n5. Build, release, run 빌드와 실행 단계를 엄격하게 구분한다. 코드베이스는 3단계를 거쳐 배포되고, 엄격하게 구분되어야 합니다.\nBuild: 지정된 코드 버전을 사용하여 의존성을 가져오고 컴파일합니다. Release: 컴파일된 결과물과 현재 배포 환경의 설정을 연결합니다. Release 단계의 결과물은 즉시 실행될 수 있습니다. Run: 애플리케이션을 실행합니다. 코드 변경은 반드시 빌드 단계에서만 이루어져야만 하며 만들어진 Release 결과는 변경될 수 없고, 이전 버전으로 롤백이 가능해야합니다.\n6. Processes 애플리케이션을 하나 이상의 Stateless 프로세스로 실행한다. 애플리케이션은 실행 환경에서 하나 이상의 프로세스로 실행됩니다.\n상태는 데이터베이스와 같은 상태 저장 서비스에 저장해야 하며, 애플리케이션은 Stateless하게 유지해야 합니다.\n7. Port binding 포트 바인딩을 통해 서비스 제공을 한다. 애플리케이션은 포트를 바인딩하여 서비스를 제공해야 합니다.\n포트를 통해 서비스를 제공함으로써 다른 애플리케이션의 Backing 서비스가 될 수 있습니다.\n8. Concurrency 프로세스 모델을 통해 수평적 확장을 한다. 애플리케이션은 리소스 추가를 통한 수직 확장 뿐만 아니라, 수를 늘리는 수평적 확장이 가능해야 합니다.\nProcesses를 준수함으로써 확장하거나 축소할 수 있습니다. 9. Disposability 빠른 시작과 그레이스풀 셧다운으로 안정성을 최대화한다. 배포와 수평 확장시 빠른 애플리케이션 구동을 위해 필요합니다.\n종료 시그널을 받은 애플리케이션은 새로운 요청을 받지 않고, 기존 요청을 처리한 후 안정적으로 종료되어야 합니다.\n10. Dev/prod parity 개발, 스테이징, 상용 환경을 최대한 비슷하게 유지한다. Local에서는 H2 database를 사용하고 상용에서는 MySQL을 사용하는 것과 같은 차이를 줄이는 것입니다.\n12 factor app은 개발과 상용 환경 사이의 차이를 줄여 지속적인 배포가 가능하도록 해야합니다.\n11. Logs 로그를 이벤트 스트림으로 처리한다. 애플리케이션은 로그에 관여하면 안되며, 단순히 버퍼링없이 출력할 뿐입니다.\n애플리케이션은 언제든지 생성되고 삭제될 수 있습니다. 따라서 이벤트는 별도 저장소에 보관되는 것이 좋습니다.\n12. Admin processes 어드민/관리 작업을 일회성 프로세스로 실행해야 한다. 개발자는 종종 일회성으로 애플리케이션 관리 작업을 수행해야 하며, 작업을 스크립트화하여 한번에 실행할 수 있도록 해야합니다.\n데이터베이스 마이그레이션 일회성 스크립트 실행 관리 스크립트는 애플리케이션과 같은 코드베이스에서 같은 설정 값을 사용해야 합니다.\n케빈 허프만이 “Beyond the 12 factor app”을 통해 MSA 환경에 적합한 3가지 요소를 제시했다.\n13. API first API 스펙 정의를 우선으로 한다. API 스펙을 먼저 정의하여 어떤 스키마로 통신할지 결정해야 합니다.\nAPI first를 통해 클라이언트와 서버가 동시에 작업을 진행할 수 있습니다.\n14. Telemetry 애플리케이션 및 리소스를 모니터링한다. 애플리케이션 및 CPU, RAM등 리소스를 모니터링하여 성능, 이벤트 및 헬스 체크 등을 확인할 수 있습니다.\n서비스 관리 및 경고 알람 트리거 설정에 도움을 줍니다.\n15. Security 보안 정책이 적절한지 확인한다. API, DB 등 보안 정책이 적절한지 확인해야 합니다.\nAPI는 OAuth 등으로 보호되어야 하며 HTTPS를 이용해서 노출시켜야 합니다.\n","permalink":"https://jo-minjun.github.io/notes/12-factor-app/","summary":"Introduction 12 factor app은 서비스형 소프트웨어를 구성하기 위한 방법론입니다.\n개발 언어/프레임워크에 상관없는 이식성과 플랫폼 호환성 향상을 위한 디자인 원칙입니다. 애플리케이션의 수평적 확장이 용이하도록 합니다. 애플리케이션 확장 가능성 CI/CD에 용이성 플랫폼간 이식성 기본적인 기대치, 정책 설정 1. Codebase 형상관리 시스템에서 하나의 코드베이스를 관리하면서, 다수에 배포한다. 하나의 코드베이스에 여러개의 애플리케이션 코드가 있다면 12 factor app 위반입니다.\n코드베이스는 모든 배포에 사용되지만 각 배포는 다른 버전이 사용될 수 있습니다.\n2. Dependencies 의존성을 명시적으로 선언하고 분리한다.","title":"12 factor app (15 factor app)"},{"content":"Pod container Pod에는 container가 여러개 있을 수 있으며, localhost로 접근할 수 있다. Pod가 생성될 때는 IP가 할당되며, 이 IP를 통해 Pod에 접근할 수 있다. 쿠버네티스 클러스터 내에서만 IP로 접근 가능하다. Pod가 재생성되면 IP 주소가 바뀐다. apiVersion: v1 # 하나의 Pod kind: Pod metadata: name: pod-1 spec: # 여러 개의 container containers: - name: container1 image: image1 ports: - containerPort: 8000 - name: container2 image: image2 ports: - containerPort: 8080 label Pod 뿐만 아니라 다른 오브젝트에도 사용할 수 있지만, Pod에서 가장 많이 사용된다. 목적에 따라 오브젝트를 분류하고 분류된 오브젝트만 연결하기 위해서 사용한다. key:value Pod1 Pod2 Pod3 type:web type:db type:server env:dev env:dev env:dev ================================================================ Pod4 Pod5 Pod6 type:web type:db type:server env:prod env:prod env:prod 위와 같은 dev/prod 환경에서 web/db/server 종류가 있는 경우 웹 개발자가 web만 보고 싶다면 type:web label인 Pod만 서비스에 연결해서 확인하면 된다. prod환경 운영자는 env:prod label인 Pod만 서비스에 연결해서 확인하면 된다. # Pod 생성 apiVersion: v1 kind: Pod metadata: name: pod-2 labels: type: db env: dev spec: containers: - name: container image: image # Service 생성 apiVersion: v1 kind: Service metadata: name: svc-1 spec: selector: type: web ports: -port: 8080 node scheduler Pod는 Node들 중 하나에 올라가야 한다. 수동으로 지정하는 방법과 자동으로 지정되는 방법이 있다. 수동 Node를 생성할 때 label을 설정하고 Pod를 만들 때 Node를 선택한다. NodeSelector, NodeAffinity, Pod Affinity, Anti-Affinity, Toleration, Taint… apiVersion: v1 kind: Pod metadata: name: pod-3 spec: nodeSelector: hostname: node1 # node에 지정한 label의 key, value containers: - name: container image: image 자동 Pod가 요구하는 리소스 할당량과 각 Node의 리소스 할당 가능량을 계산해서 scheduler가 선택한다. Service Service는 자신의 IP를 가지고 있다. Service를 Pod에 연결해 놓으면 Service의 IP를 가지고 Pod에 접근할 수 있다. Pod의 IP를 가지고 접근할 수도 있지만, Pod의 IP는 변경될 수 있다. ClusterIP 가장 기본적인 Service이다. 클러스터 내에서만 접근이 가능한 IP이다. 클러스터 내의 오브젝트에서는 접근 가능하지만 외부에서는 접근할 수 없다. 하나의 Pod 뿐만아니라 여러개의 Pod를 연결할 수 있다. 요청이 오면 여러개의 Pod로 분산도 해준다. apiVersion: v1 kind: Service metadata: name: svc-1 spec: # label을 이용해서 Pod 연결 selector: app: pod # 9000번 포트로 요청이 들어오면 8080번 포트로 연결이도 된다. ports: - port: 9000 targetPort: 8080 type: ClusterIP apiVersion: v1 kind: Pod metadata: name: pod-1 labels: app: pod spec: containers: - name: container image: tmkube:app ports: -containerPort: 8080 NodePort Service에 IP가 포함되어 있어 ClusterIP와 같은 기능이 포함되어 있다. 클러스터 내부 모든 Node에 포트를 할당하여 Node의 IP로 접근을 하면 Service로 트래픽이 전달된다. Service는 다시 자신에게 연결된 Pod로 트래픽을 전달한다. apiVersion: v1 kind: Service metadata: name: svc-2 spec: selector: app: pod ports: - port: 9000 targetPort: 8080 nodePort: 30000 type: NodePort # 이 옵션을 사용하면 Service가 요청이 들어온 Node의 Pod로 트래픽을 전달한다. externalTrafficPolicy: local Load Balancer NodePort의 특징을 포함하고 있다. Load Balancer라는 오브젝트가 생성되어 각 Node에 트래픽을 분산 시킨다. 외부에서 Load Balancer에 접근하기 위한 IP는 기본적으로 설정되어 있지 않다. apiVersion: v1 kind: Service metadata: name: svc-3 spec: selector: app: pod ports: - port: 9000 targetPort: 8080 nodePort: 30000 type: LoadBalancer ExternalName 클러스터 외부 서비스에 접근하기 위해 사용하는 서비스이다. ","permalink":"https://jo-minjun.github.io/notes/kubernetes-pod-service/","summary":"Pod container Pod에는 container가 여러개 있을 수 있으며, localhost로 접근할 수 있다. Pod가 생성될 때는 IP가 할당되며, 이 IP를 통해 Pod에 접근할 수 있다. 쿠버네티스 클러스터 내에서만 IP로 접근 가능하다. Pod가 재생성되면 IP 주소가 바뀐다. apiVersion: v1 # 하나의 Pod kind: Pod metadata: name: pod-1 spec: # 여러 개의 container containers: - name: container1 image: image1 ports: - containerPort: 8000 - name: container2 image: image2 ports: - containerPort: 8080 label Pod 뿐만 아니라 다른 오브젝트에도 사용할 수 있지만, Pod에서 가장 많이 사용된다.","title":"Kubernetes: pod와 service"},{"content":"What, Why Kubernetes? What 쿠버네티스는 컨테이너들을 운영, 관리하는 컨테이너 오케스트레이터이다. 컨테이너 오케스트레이터는 개별 컨테이너의 배포, 관리, 확장, 네트워킹을 자동화해준다. Why 물리 서버에서 동작하는 서비스는 리소스 관리를 효율적으로 할 수 없다. 3개의 서비스에 트래픽이 몰리는 시간대가 다르다. 각 서비스는 최소 트래픽 때 0.5대, 최대 트래픽 때 3개의 서버가 사용된다. 이 경우 총 9대의 서버가 사용된다. 배포시에도 비효율적이다. 중단이 가능한 경우 모든 서비스를 내린 후, 업데이트하여 다시 올린다. 중단이 불가능하면 서비스를 하나씩 내리고 하나씩 업데이트하여 다시 올린다. → 쿠버네티스를 사용하면 리소스 관리를 효율적으로 할 수 있다.\n시간대 별로 평균 서버 필요량을 예측하여 다음과 같은 운용이 가능하다. 평균 4개의 서버 A서비스에 트래픽이 몰리는 경우 3개 서버에 A서비스 할당, 1개 서버에 B, C 서비스 할당 서버에 장애가 발생한 경우에 유연하게 대처할 수 있다. 쿠버네티스에는 Auto Healing 기능이 있다. 여분의 서버 1개가 있는 경우 자동으로 여분 서버에 서비스를 옮긴다. 배포할 때는 Deployment Object를 통해서 자동화 해준다. → 서버가 효율적인 개수를 유지하고 자동화 됨으로써 유지보수 비용이 감소한다.\nOverview 서버 한대는 Master, 나머지 서버는 Node가 된다. → 이것이 연결되어 하나의 쿠버네티스 클러스터가 된다.\nMaster는 쿠버네티스의 기능을 컨트롤하고 Node는 리소스를 제공한다. 클러스터의 리소스를 늘리고 싶다면 Node를 추가하면 된다. namespace를 이용해서 쿠버네티스 오브젝트를 독립된 공간으로 분리시켜준다. namespace에는 쿠버네티스 최소 배포 단위인 Pod가 있고, Pod에 IP를 할당되도록 연결되는 Service가 있다. Service는 다른 namespace와는 연결될 수 없다. Pod에는 여러 Container가 있을 수 있다. 또한 Volume을 마운트해서 Pod의 데이터가 증발되지 않도록 한다. namespace에는 ResourceQuota와 LimitRange를 설정해서 namespace의 리소스의 양을 제한시킬 수 있다. ConfigMap과 Secret으로 Pod의 컨테이너에 환경변수를 설정할 수 있게 한다. 여러가지 컨트롤러는 Pod들을 관리한다. Replication Controller, ReplicaSet은 Pod가 죽으면 다시 구동시키거나 스케일 인/아웃을 해준다. Deployment는 배포 후에 Pod를 새 버전으로 업그레이드하고, 문제가 생기면 롤백 해준다. DaemonSet은 한 Node에 하나의 Pod만 사용되도록 해준다. CronJob은 특정 Job을 주기적으로 수행되도록 해준다. Job은 특정 작업만 하고 종료되는 것이다. Components master 노드 kube-apiserver etcd kube-scheduler kube-controller-manager worker 노드 kubelet kube-proxy kube-apiserver 쿠버네티스 클러스터의 API를 사용할 수 있게 해준다. kubectl과 같은 클라이언트로부터 요청 받아낸다. etcd key-value 형식의 데이터 저장소이다. kube-scheduler Node들의 리소스 상태와 kube-apiserver를 확인하면서, Pod에 Node 정보를 할당한다. kube-controller-manager Controller들을 실행한다. kubelet kube-apiserver를 확인하면서 Pod에 자신의 Node 정보가 할당된 것이 있으면 Pod를 생성한다. 컨테이너를 생성하고 kube-proxy에 네트워크 생성 요청을 한다. kube-proxy 네트워크 규칙을 관리하고 컨테이너가 네트워크를 사용할 수 있도록 한다. 실습 환경 구축 강의에서 소개된 환경이 아닌 minikube를 사용한다. minikube start \\ --driver=\u0026#39;docker\u0026#39; \\ --kubernetes-version=\u0026#39;stable\u0026#39; \\ --nodes=3 # 실습을 위해 dashboard 사용 # 실제 업무에서는 secret 등의 값 노출을 막기위해 dashboard를 잘 사용하지 않는다. minikube dashboard 위와 같은 방법으로 master 1개, worker node 2개를 구축하고 dashboard를 사용할 수 있다. ","permalink":"https://jo-minjun.github.io/notes/introduce-kubernetes/","summary":"What, Why Kubernetes? What 쿠버네티스는 컨테이너들을 운영, 관리하는 컨테이너 오케스트레이터이다. 컨테이너 오케스트레이터는 개별 컨테이너의 배포, 관리, 확장, 네트워킹을 자동화해준다. Why 물리 서버에서 동작하는 서비스는 리소스 관리를 효율적으로 할 수 없다. 3개의 서비스에 트래픽이 몰리는 시간대가 다르다. 각 서비스는 최소 트래픽 때 0.5대, 최대 트래픽 때 3개의 서버가 사용된다. 이 경우 총 9대의 서버가 사용된다. 배포시에도 비효율적이다. 중단이 가능한 경우 모든 서비스를 내린 후, 업데이트하여 다시 올린다. 중단이 불가능하면 서비스를 하나씩 내리고 하나씩 업데이트하여 다시 올린다.","title":"Introduce Kubernetes"},{"content":"kubectl command 쿠버네티스 API를 사용하는 CLI 도구이다. kubectl [command] [TYPE] [NAME] [flags] [command] 하나 이상의 리소스에서 수행하는 동작을 지정한다. ex) create get describe delete [TYPE] 리소스 타입을 지정한다. 대소문자를 구분하지 않으며 단수형, 복수형, 약어를 지정할 수 있다. ex) pod pods po [NAME] 하나 이상의 리소스의 이름을 지정한다. 대소문자를 구분하며 리소스 이름을 지정하지 않으면 모든 리소스가 대상이 된다. 리소스가 모두 동일한 TYPE인 경우 ex) kubectl get pod name1 name2 리소스 타입을 개별로 지정하는 경우 ex) kubectl get pod/name1 replicaset/name2 [flags] 플래그를 지정한다. ex) -A 주요 명령어 command description example get 하나 이상의 리소스를 보여준다. kubectl get pod edit 서버의 리소스를 수정한다. kubectl edit pod name1 delete 파일 또는 리소스를 삭제한다. kubectl delete -f file.yaml kubectl delete pod name1 scale deployment, replicaset 등의 scale을 조정한다. kubectl scale replicaset name1 \u0026ndash;replicas=3 top CPU/memory 등 리소스 상태를 보여준다. kubectl top pod kubectl top node describe 리소스의 상세 정보를 보여준다. kubectl describe -l key=value logs pod의 로그를 보여준다. kubectl logs -f pod_name exec container에 커맨드를 실행시킨다. kubectl exec -it pod_name \u0026ndash; /bin/bash port-forward pod의 포트로 local 포트를 포워드한다. kubectl port-forward pod_name 13231:80 kubectl replicaset/replicaset_name 13231:80 kubectl deployment/deployment_name 13231:80 cp 파일 또는 디렉터리를 복사한다. pod_name을 명시하지 않으면 local로 설정된다. kubectl cp pod_name:path path apply 리소스를 생성하거나 업데이트한다. kubectl apply -f file.yaml config kubeconfig(~/.kube/config) 파일을 관리한다. kubectl config view kubectl config use-context dev1 ","permalink":"https://jo-minjun.github.io/notes/kubectl-command/","summary":"kubectl command 쿠버네티스 API를 사용하는 CLI 도구이다. kubectl [command] [TYPE] [NAME] [flags] [command] 하나 이상의 리소스에서 수행하는 동작을 지정한다. ex) create get describe delete [TYPE] 리소스 타입을 지정한다. 대소문자를 구분하지 않으며 단수형, 복수형, 약어를 지정할 수 있다. ex) pod pods po [NAME] 하나 이상의 리소스의 이름을 지정한다. 대소문자를 구분하며 리소스 이름을 지정하지 않으면 모든 리소스가 대상이 된다. 리소스가 모두 동일한 TYPE인 경우 ex) kubectl get pod name1 name2 리소스 타입을 개별로 지정하는 경우 ex) kubectl get pod/name1 replicaset/name2 [flags] 플래그를 지정한다.","title":"kubectl command"},{"content":"Shell Script 쉘 스크립트로 만든 UP-DOWN 게임 Shell이란 운영체제에서 커널과 사용자 사이를 이어주는 역할을 하는 명령어 해석기이다.\nShell은 bash sh csh zsh등이 있다.\nShell Script란 운영체제의 Shell을 이용해서 Shell 명령어들을 순차적으로 실행시켜주는 스크립트이다.\nShell Script를 사용하기 위해서는 다음과 같이 시작해야 한다.\n#!/bin/bash #!/usr/bin/env bash #!/usr/bin/env python3 위와 같이 #!으로 시작하여 Shell의 경로를 선언해준다. 이를 쉬뱅이라 한다. 쉬뱅은 어느 인터프리터가 스크립트의 명령어를 해석할 지 가리킨다. 변수 변수 number=1 string=\u0026#34;string\u0026#34; echo \u0026#34;$number\u0026#34; echo \u0026#34;$string\u0026#34; echo \u0026#34;${number}\u0026#34; echo \u0026#34;${string}\u0026#34; 변수는 위와 같이 공백을 사용하지 않고 선언한다. 변수명은 대소문자를 구분한다. 변수명은 숫자를 포함할 수 있으나, 숫자로 시작할 수 없다. 변수에 숫자를 대입해도 문자열로 취급된다. 변수는 $변수명 또는 ${변수명}으로 사용할 수 있다. 배열 array=(\u0026#34;a\u0026#34; \u0026#34;b\u0026#34; \u0026#34;c\u0026#34;) array+=(\u0026#34;d\u0026#34;) echo \u0026#34;${array[0]}\u0026#34; echo \u0026#34;${array[*]}\u0026#34; echo \u0026#34;${#array[*]}\u0026#34; 배열은 각 원소를 공백으로 구분한다. 원소를 추가할 경우 +=으로 한다. 변수명[index]를 사용해서 특정 인덱스(0 ~ n)의 원소에 접근할 수 있고, 변수명[*]으로 모든 원소에 접근할 수 있다. #변수명[*]으로 원소의 수를 확인할 수 있다. 미리 정의된 변수 변수 설명 $0 쉘 스크립트의 파일명 $# 쉘 스크립트에 전달된 인자의 수 $$ 쉘 스크립트의 PID $1 ~ $n 쉘 스크립트에 전달된 인자 값 $* 쉘 스크립트에 전달된 인자들의 문자열 비교 연산자 변수 비교 연산자 연산자 설명 -z ${변수A} 변수A의 문자열 길이가 0이면 참 -n ${변수A} 변수A의 문자열 길이가 0이 아니면 참 ${변수A} -eq ${변수B} 변수A와 변수B의 값이 같으면 참 ${변수A} -ne ${변수B} 변수A와 변수B의 값이 다르면 참 ${변수A} -gt ${변수B} 변수A의 값이 변수B의 값보다 크면 참 ${변수A} -ge ${변수B} 변수A의 값이 변수B의 값보다 크거나 같으면 참 ${변수A} -lt ${변수B} 변수A의 값이 변수B의 값보다 작으면 참 ${변수A} -le ${변수B} 변수A의 값이 변수B의 값보다 작거나 같으면 참 연산1 -a 연산2 연산1과 연산2가 모두 참이면 참 연산1 -o 연산2 연산1과 연산2중 하나라도 참이면 참 파일/디렉터리 비교 연산자 연산자 설명 -d ${A} A가 디렉터리면 참 -e ${A} A파일이 존재하면 참 -L ${A} A파일이 심볼릭 링크면 참 -r ${A} A파일에 읽기 권한이 존재하면 참 -w ${A} A파일에 쓰기 권한이 존재하면 참 -x ${A} A파일에 실행 권한이 존재하면 참 -s ${A} A파일의 크기가 0보다 크면 참 -f ${A} A파일이 존재하면 참 ${A} -nt ${B} A파일이 B파일보다 최신 파일이면 참 ${A} -ot ${B} A파일이 B파일보다 이전 파일이면 참 ${A} -ef ${B} A파일이 B파일과 같은 파일이면 참 주로 -d -f 를 자주 사용한다. 제어문 분기문 if [ 비교 연산자 ]; then # 실행 elif [ 비교 연산자 ]; then # 실행 else # 실행 fi if로 시작하고 fi로 끝난다. 분기문에서 비교 연산은 [ 비교 연산자 ]; then 구분을 사용한다. case target in 값1) # 실행 ;; 값2|값3) # 실행 ;; *) # 실행 ;; esac case로 시작하고 esac로 끝난다. ;; 를 이용해서 break를 할 수 있다. 반복문 반복문은 공통적으로 do로 시작하고 done으로 끝난다.\ncontinue와 break를 이용해서 반복문을 제어할 수 있다.\nwhile (비교 연산자); do # 실행 done for i in ${array[*]}; do # 실행 done 배열의 각 요소에 접근한다. for i in {0..10}; do # 실행 done 0 ~ 10 범위의 값을 접근한다. for (( i = 0; i \u0026lt; 10; i++)); do # 실행 done 0 ~ 10 범위의 값을 접근한다. ","permalink":"https://jo-minjun.github.io/notes/shell-script/","summary":"Shell Script 쉘 스크립트로 만든 UP-DOWN 게임 Shell이란 운영체제에서 커널과 사용자 사이를 이어주는 역할을 하는 명령어 해석기이다.\nShell은 bash sh csh zsh등이 있다.\nShell Script란 운영체제의 Shell을 이용해서 Shell 명령어들을 순차적으로 실행시켜주는 스크립트이다.\nShell Script를 사용하기 위해서는 다음과 같이 시작해야 한다.\n#!/bin/bash #!/usr/bin/env bash #!/usr/bin/env python3 위와 같이 #!으로 시작하여 Shell의 경로를 선언해준다. 이를 쉬뱅이라 한다. 쉬뱅은 어느 인터프리터가 스크립트의 명령어를 해석할 지 가리킨다. 변수 변수 number=1 string=\u0026#34;string\u0026#34; echo \u0026#34;$number\u0026#34; echo \u0026#34;$string\u0026#34; echo \u0026#34;${number}\u0026#34; echo \u0026#34;${string}\u0026#34; 변수는 위와 같이 공백을 사용하지 않고 선언한다.","title":"Shell Script"},{"content":"Linux 주요 커맨드와 옵션 커맨드 라인 단축키\nctrl + a: 커서를 라인 가장 앞으로 옮긴다. ctrl + e: 커서를 라인 가장 뒤로 옮긴다. ctrl + k: 커서를 기준으로 뒤쪽을 모두 지운다. 유틸리티 piping, redirect\n\u0026lt;COMMAND\u0026gt; | \u0026lt;COMMAND\u0026gt; |를 기준으로 앞 커맨드의 표준 출력을 뒷 커맨드의 표준 입력으로 사용한다. curl -s https://apigateway.dev1.meshdev.io/neogeo/management/info | jq \u0026lt;COMMAND\u0026gt; \u0026lt; \u0026lt;FILE\u0026gt; \u0026lt;COMMAND\u0026gt; \u0026gt; \u0026lt;FILE\u0026gt; \u0026lt;COMMAND\u0026gt; 1\u0026gt; \u0026lt;FILE\u0026gt; # 위 명령어와 같다. \u0026lt;COMMAND\u0026gt; 2\u0026gt; \u0026lt;FILE\u0026gt; # 커맨드의 에러 내용을 파일에 덮어 쓴다. \u0026lt;COMMAND\u0026gt; \u0026gt;\u0026gt; \u0026lt;FILE\u0026gt; \u0026lt;는 뒷 파일의 내용을 커맨드의 입력으로 사용한다. \u0026gt;는 앞 커맨드의 결과를 파일 등에 덮어 쓴다. \u0026gt;\u0026gt;는 앞 커맨드의 결과를 파일 등에 추가한다. cat \u0026lt;\u0026lt; EOT \u0026gt; template.json { \u0026#34;tag\u0026#34;: \u0026#34;\u0026#34; } EOT cat template.json grep\n지정한 패턴이나 문자열에 매칭되는 내용만 출력한다. grep [OPTIONS] [PATTERN] [FILE] -c 패턴이 일치하는 행의 수를 출력한다. -i 대소문자를 구분하지 않는다. -v 패턴이 일치하는 않는 내용만 출력한다. -A 패턴 일치 줄 이후 n개 라인을 출력한다. -B 패턴 일치 줄 이전 n개 라인을 출력한다. watch\nCOMMAND의 결과를 계속해서 보여준다. watch [OPTIONS] \u0026lt;COMMAND\u0026gt; -d 변경된 부분을 표시한다. -n m초 주기로 리프레쉬한다. time\n특정 명령어 또는 프로그램의 수행 시간을 보여준다. time \u0026lt;COMMAND\u0026gt; real: 총 수행 시간 user: CPU가 사용자 영역에서 보낸 시간 sys: CPU가 커널 영역에서 보낸 시간 xargs\n앞 커맨드의 수행 결과를 뒤 커맨드의 인자로 넘긴다. \u0026lt;COMMAND\u0026gt; | xargs \u0026lt;COMMAND\u0026gt; 아무 커맨드를 입력하지 않으면 echo가 수행된다. 파일/DIR cat\n파일 이름을 받아서 내용을 터미널에 출력한다. cat [OPTIONS] \u0026lt;FILE_NAME\u0026gt; cat name # name 파일의 내용을 터미널에 출력한다. cat name1 name2 # name1, name2 파일의 내용을 터미널에 출력한다. -b 줄번호를 출력한다. 비어있는 행은 포함하지 않는다. -n 줄번호를 출력한다. 비어있는 행을 포함한다. -s 2개 이상의 빈 행을 한 행으로 출력한다. touch\n파일의 날짜와 시간을 수정하는 명령어다. 빈 파일을 생성하기 위해 자주 사용된다. touch [OPTIONS] \u0026lt;FILE_NAME\u0026gt; # 파일이 없으면 생성하고, 접근 시간, 상태 변경 시간, 수정 시간을 현재로 변경 mkdir\n디렉토리를 생성한다. mkdir [OPTIONS] \u0026lt;DIRECTORY_NAME\u0026gt; -m \u0026ndash;mode 권한을 함께 부여한다. -p \u0026ndash;parent 상위 디렉토리를 같이 생성한다. rm\n파일이나 디렉토리를 삭제한다. rm [OPTIONS] \u0026lt;FILE_NAME | DIRECTORY_NAME\u0026gt; -f \u0026ndash;force 삭제 여부를 묻지 않는다. -r \u0026ndash;recursive 해당 디렉토리와 해당 디렉토리 하위의 모든 파일과 디렉토리를 삭제한다. tree\n디렉토리의 하위 구조를 계층적으로 보여준다. tree [OPTIONS] \u0026lt;DIRECTORY_NAME\u0026gt; -L 하위 구조의 레벨을 지정한다. (해당 레벨까지 출력) -d 파일은 제외하고 디렉토리만 출력한다. echo\n텍스트를 터미널에 출력한다. 텍스트에 특수문자가 있는 경우 \u0026quot;\u0026lt;text\u0026gt;\u0026quot;로 명시해주어야 한다. echo [OPTIONS] \u0026lt;TEXT\u0026gt; sed\nLinux sed command help and examples\n파일을 수정하는 stream editor이다. sed OPTIONS... [SCRIPT] [INPUT_FILE] -i 결과를 터미널에 출력하지 않고 파일에서 처리한다. -r 정규식을 사용한다. -n 적용 부분만 구분해서 출력한다. \u0026rsquo;s/문자1/문자2/' 문자1을 문자2로 대체한다. (/은 (공백) . 으로 사용해도 된다.) \u0026rsquo;n,ms/문자1/문자2/' n ~ m 번 줄에서 문자1을 문자2로 대체한다. \u0026rsquo;n,mp' n ~ m 번 줄을 출력한다. \u0026rsquo;n,md' n ~ m 번 줄을 지운다. gsed \u0026#39;s/\u0026#34;tag\u0026#34;: ./\u0026#34;tag\u0026#34;: \u0026#34;latest\u0026#34;/g\u0026#39; template.json \u0026gt; output.json cat output.json file: mail billy@example.org tom@example.org jay@example.org root@example.org billy와 tom의 example.org만 example.com으로 변경하고 싶은 경우 gsed -i -r \u0026#39;s/^(billy|tom)@example.org/\\1@example.com/\u0026#39; file 1~2번 라인만 출력하고 싶은 경우 gsed -n \u0026#39;1,2p\u0026#39; file 1~2번 라인을 지우고 출력하고 싶은 경우 gsed \u0026#39;1,2d\u0026#39; file tee\n입력과 출력을 동시에 한다. tee [OPTIONS] [FILE] 출력을 redirection할 경우 파일이 root 권한이라면 실패한다. 이 경우 tee를 사용할 수 있다. sudo echo \u0026#34;TEXT\u0026#34; \u0026gt; ROOT_FILE # permission denied sudo echo \u0026#34;TEXT\u0026#34; | tee ROOT_FILE less\n내용을 터미널에 출력한다. 위 → 아래, 아래 → 위 방향으로 이동할 수 있다. 종료하려면 q를 눌러야 한다. less file more\n파일의 내용을 터미널에 출력한다. 위 → 아래 방향으로만 이동 가능하다. 가장 아래로 이동하면 more가 종료된다. more file ls\n디렉토리에 있는 파일이나 디렉토리를 출력한다. ls [OPTIONS] [DIRECTORY] -a 모든 파일과 디렉토리를 보여준다. -l 사용자의 권한, 소유자, 크기, 날짜 등 디테일 정보를 보여준다. which\n특정 명령어의 위치를 출력한다. which [OPTIONS] COMMAND -n 옵션은 모든 위치에서의 명령어를 찾는다. head\n파일의 앞 부분을 출력한다. head [OPTIONS] FILE -n 파일의 앞 부분 m줄 만큼 출력한다. tail\n파일의 끝 부분을 출력한다. tail [OPTIONS] FILE -n 파일의 끝 부분 m줄 만큼 출력한다. -f 파일의 끝부터 10줄을 출력하고, 새로 입력되는 정보를 계속해서 출력한다. -F 파일이 변경되어도 계속해서 추적하며 출력한다. (삭제되어도 다시 파일이 생기면 출력) tar\n여러개의 파일과 디렉토리를 하나의 파일로 묶거나 해제한다. tar [OPTIONS] \u0026lt;TARGET\u0026gt; tar cvf name.tar ./dir # tar 생성 tar xvf name.tar # tar 해제 c tar 파일 생성 x tar 파일 해제 v 생성 또는 해제 시 파일 리스트 출력 t tar에 포함된 내용 확인 f 파일 이름 지정 gzip / gunzip\ngzip: 파일을 압축한다. gunzip: gz파일을 해제한다. gzip [OPTIONS] \u0026lt;TARGET\u0026gt; - n(1 ~ 9)은 압축 속도이다. 압축 속도가 빠르면 압축률이 낮아진다. (1: 빠름, 9: 느림) -c 압축 결과를 출력하고 원본은 유지한다. -d 압축을 해제한다. -v 압축 시 자세한 정보를 출력한다. (진행률 등) -r 디렉토리의 모든 파일을 압축한다. gunzip [OPTIONS] \u0026lt;TARGET\u0026gt; -l 압축 파일 정보를 출력한다. -v 해제 시 자세한 정보를 출력한다. (진행률 등) -r 디렉토리의 모든 파일을 해제한다. zip / unzip\nzip: 파일 또는 디렉토리를 압축한다. unzip: zip 파일을 해제한다. zip [OPTIONS] \u0026lt;ZIP_NAME.zip\u0026gt; \u0026lt;TARGET...\u0026gt; - 압축 정도 (0: store only ~ 9: compress better) -e 압축 파일에 암호 적용 -s \u0026lt;n(k m g t)\u0026gt; 분할 압축 (k: kilobytes, m: megabytes, g: gigabytes, t: terabytes) -q 메시지 출력 제한 -r 하위 디렉토리의 파일과 숨겨진 파일을 포함한다. upzip [OPTIONS] \u0026lt;TARGET\u0026gt; -d 특정 디렉토리에 zip을 해제한다. chmod\nchmod [OPTIONS] \u0026lt;MODE\u0026gt; \u0026lt;TARGET\u0026gt; 파일 또는 디렉토리의 권한 등을 변경한다. -R 지정한 모드를 하위 디렉토리 및 파일에 전부 적용한다. 000 모든 사용자가 r/w/x 불가능 440 소유자 및 그룹은 r 가능, 그 외에는 불가능 664 소유자 및 그룹은 r/w 가능, 그 외에는 r만 가능 755 소유자는 r/w/x 가능, 그룹 및 그 외에는 r/x만 가능 777 모든 사용자가 r/w/x 가능 네트워크 curl\ncurl [OPTIONS] \u0026lt;URL\u0026gt; 여러 통신 프로토콜을 이용해서 데이터를 전송한다. -X HTTP METHOD를 지정한다. -H HEADER 값을 지정한다. -d BODY에 들어갈 값을 지정한다. -T PUT 방식으로 파일을 업로드 한다. -b 쿠키를 지정한다. -s 진행 상태, 에러 메세지 등을 보여주지 않는다. -v 헤어 등의 데이터를 추가로 보여준다. wget\nwget [OPTIONS] \u0026lt;URL\u0026gt; 웹에서 파일 다운로드를 한다. -c 중단된 파일 다운로드를 다시 시작한다. -b 파일 다운로드를 백그라운드로 한다. -O 파일의 이름을 지정한다. nc\nnc [OPTIONS] [HOST] [PORT] TCP 또는 UDP 프로토콜을 사용하는 네트워크 환경에서 데이터를 읽고 쓴다. 일반적으로 서버의 포트 상태를 확인과 접속 가능 여부를 확인하기 위해 사용한다. -z 포트 스캔만 진행한다. -v 더 많은 정보를 출력한다. nc -z google.com 80 telnet\ntelnet [OPTIONS] [HOST] [PORT] 원격으로 호스트에 접속한다. -l 접속할 ID를 지정 -a 현재 사용자를 ID로 지정 telnet만 입력하면 LINEMODE로 진입한다. ? 사용법을 출력한다. logout 사용자가 로그아웃하며 접속을 해제한다. open 지정한 호스트로 연결한다. quit 텔넷을 종료한다. status 텔넷의 상태를 출력한다. … telnet google.com 80 GET / HTTP/1.1 openssl\n# rsa 개인키 생성 openssl genrsa [-des3] -out PRIVATE_KEY_NAME.key [BIT_SIZE;1024, 2048] # rsa 공개키 생성 openssl rsa -in PRIVATE_KEY_NAME.key -pubout -out PUBLIC_KEY_NAME.key # 인증서 생성 openssl req -new -key PRIVATE_KEY_NAME.key [-days n] -out certification.csr # HTTPS 통신 openssl s_client -connect google.com:443 SSL/TLS 프로토콜을 이용하기 위한 오픈소스 라이브러리이다. # rsa 비밀키 생성 공개키 암호화 방식의 개인키를 생성한다. -des3 옵션을 넣으면 des3 대칭키 알고리즘으로 한 번 더 암호화 해준다. 비밀키를 추가로 요구한다. # rsa 공개키 생성 공개키 암호화 방식의 공개키를 생성한다. # 인증서 생성 개인키로 서명한 인증서를 생성한다. -days 옵션으로 유효한 기간을 설정할 수 있다. 인증서는 공개키와 발급자 정보를 식별하는 정보를 가지고 있다. 이 명령어를 수행하면 몇 가지 정보를 요청한다. (국가, 회사, 이메일 등) ab\nab [OPTIONS] \u0026lt;HOST\u0026gt;[:PORT][/PATH] 아파치가 제공하는 HTTP 서버 성능 검증 도구이다. -n 요청의 전체 수, m번 만큼 전체 요청을 수행한다. -c 동시에 요청하는 수, n개의 요청을 동시에 한다. -H 요청 헤더를 지정한다. -C 요청 쿠키를 지정한다. -T 요청 Content-type을 지정한다. ab -n 10 -c 2 https://apigateway.dev1.meshdev.io/neogeo/management/info nslookup\nnslookup [-type=\u0026lt;TYPE\u0026gt;] DOMAIN_NAME [DNS] DNS 서버에서 도메인의 정보를 조회한다. -type=soa origin DNS를 조회한다. host\nhost [OPTIONS] NAME DNS 서버에서 도메인의 정보를 조회한다. netstat\nnetstat [OPTIONS] 네트워크 연결상태, 인터페이스 상태 등을 보여준다. 옵션 설명 -a 모든 소켓 확인한다. -r 라우팅 테이블 확인한다. -n 호스트 이름을 ip 주소로 보여준다. -t TCP 소켓을 확인한다. -u UDP 소켓을 확인한다. -p PID/program name을 확인한다. traceroute\ntraceroute [OPTIONS] HOST HOST까지 가는 네트워크 경로를 확인해준다. 프로세스 top\ntop [OPTIONS] 실시간으로 시스템의 프로세스 상태를 확인한다. -b 배치 모드 -n m 후에 인터렉션 종료 (top 화면을 나간다.) -d 화면 새로고침 주기 shift + p CPU 사용률 내림차순 shift + m 메모리 사용률 내림차순 shift + t 프로세스 런타임 내림차순 k PID 작성시 kill ps\nps [OPTIONS] 현재 실행중인 프로세스의 목록과 상태를 보여준다. -A 모든 프로세스를 출력한다. -f 풀 포맷으로 보여준다. (UID, PPID 등) -r 현재 실행 중인 프로세스를 보여준다. -e 커널 프로세스를 제외한 모든 프로세스를 출력한다. kill / pkill\nkill [SIGNAL] PID PID를 이용해서 프로세스에 signal을 보낸다. pkill [SIGNAL] NAME 프로세스 이름을 이용해서 프로세스에 signal을 보낸다. 9 SIGKILL 강제 종료 시그널 15 SIGTERM 정상 종료 시그널 (termination) kill vs terminate - kill - It is more like pressing PC power and reset button. It wont save any logs or other data. - terminate - it will store all your data before shutting down (write data from RAM to disk, logs, etc) pgrep\npgrep [OPTIONS] [PATTERN] 패턴에 일치하는 프로세스 정보를 출력한다. -u 특정 유저가 실행시킨 프로세스를 검색한다. (이름) -U 특정 유저가 실행시킨 프로세스를 검색한다. (UID) -g 특정 그룹이 실행시킨 프로세스를 검색한다. (이름) -G 특정 그룹이 실행시킨 프로세스를 검색한다. (이름) -l 프로세스 이름을 같이 출력한다. ","permalink":"https://jo-minjun.github.io/notes/linux-command/","summary":"Linux 주요 커맨드와 옵션 커맨드 라인 단축키\nctrl + a: 커서를 라인 가장 앞으로 옮긴다. ctrl + e: 커서를 라인 가장 뒤로 옮긴다. ctrl + k: 커서를 기준으로 뒤쪽을 모두 지운다. 유틸리티 piping, redirect\n\u0026lt;COMMAND\u0026gt; | \u0026lt;COMMAND\u0026gt; |를 기준으로 앞 커맨드의 표준 출력을 뒷 커맨드의 표준 입력으로 사용한다. curl -s https://apigateway.dev1.meshdev.io/neogeo/management/info | jq \u0026lt;COMMAND\u0026gt; \u0026lt; \u0026lt;FILE\u0026gt; \u0026lt;COMMAND\u0026gt; \u0026gt; \u0026lt;FILE\u0026gt; \u0026lt;COMMAND\u0026gt; 1\u0026gt; \u0026lt;FILE\u0026gt; # 위 명령어와 같다. \u0026lt;COMMAND\u0026gt; 2\u0026gt; \u0026lt;FILE\u0026gt; # 커맨드의 에러 내용을 파일에 덮어 쓴다.","title":"Linux 주요 커맨드와 옵션들"},{"content":"배포판 별 패키지 매니저 alpine 참고: Working with the Alpine Package Keeper (apk)\napk [\u0026lt;OPTIONS\u0026gt;...] COMMAND [\u0026lt;ARGUMENTS\u0026gt;...] 존재하는 리포지터리(repository)는 다음과 같다. main 공식적으로 지원하는 패키지들 community testing 리포지터리에서 테스트된 패키지들 testing 새롭거나, 손상됐거나, 오래된 테스트가 필요한 패키지들 Updating repository\napk update 리포지터리 인덱스를 업데이트한다. Searching\napk search [\u0026lt;OPTIONS\u0026gt;...] PATTERN... 리포지터리에서 PATTERN을 검색한다. Option Description \u0026ndash;description -d 설명에서 PATTERN을 검색한다. \u0026ndash;exact -e 패키지 이름을 정확하게 매칭시킨다. Installing\napk add [\u0026lt;OPTIONS\u0026gt;...] PACKAGES... 패키지를 설치한다. 이미 존재하면 업그레이드를 시도한다. Upgrading\napk upgrade [\u0026lt;OPTIONS\u0026gt;...] [\u0026lt;PACKAGES\u0026gt;...] 설치된 패키지를 업그레이드 한다. 특정 패키지가 명시되지 않으면 설치된 패키지 중 가능한 패키지를 업그레이드 한다. Removing\napk del [\u0026lt;OPTIONS\u0026gt;...] PACKAGES... 설치된 패키지를 제거한다. centos(Amazon Linux 2, Amazon Linux 2022) 참고: Chapter 9. Yum Red Hat Enterprise Linux 7 | Red Hat Customer Portal\nyum [\u0026lt;OPTIONS\u0026gt;...] COMMAND [\u0026lt;ARGUMENTS\u0026gt;...] Searching\nyum search PATTERN 패키지 이름은 모르지만 관련 용어를 알고 있을 때 편리한 패키지 검색 명령어이다. Listing\nyum list all 설치 되었거나 설치 가능한 패키지 목록을 보여준다. yum list installed 설치된 패키지 목록을 보여준다. yum list available 설치 가능한 패키지 목록을 보여준다. Installing\nyum install PACKAGE 패키지를 설치한다. Updating packages\nyum check-update 설치된 패키지 중 업데이트가 가능한 패키지를 확인한다. yum update PACKAGE 한 개 이상 패키지에 대한 업데이트를 진행한다. 패키지를 입력하지 않으면 모든 패키지에 대해 업데이트를 진행한다. Removing\nyum remove PACKAGE 패키지를 제거한다. History\nyum history list 실행되었던 yum 관련 명령어들을 확인한다. Rollback\nyum history rollback HISTORY_ID history에서 확인한 ID로 해당 명령어를 수행하기 전으로 되돌린다. ubuntu(debian) 참고: Ubuntu Manpage: apt - command-line interface\napt [options] command Updating\napt update 리포지터리의 설치 가능한 목록을 업데이트 한다. Listing\napt list PATTERN 패키지 이름으로 목록을 검색해서 보여준다. apt -i list 로 설치된 목록을 확인 할 수 있다. Searching\napt search PATTERN 패키지 설명, 이름 등으로 목록을 검색해서 보여준다. Installing\napt install PACKAGE 패키지를 설치한다. Removing\napt remove PACKAGE 패키지를 제거한다. Upgrading\napt upgrade [PACKAGE] 설치된 패키지를 업그레이드 한다. ","permalink":"https://jo-minjun.github.io/notes/linux-package-manager/","summary":"배포판 별 패키지 매니저 alpine 참고: Working with the Alpine Package Keeper (apk)\napk [\u0026lt;OPTIONS\u0026gt;...] COMMAND [\u0026lt;ARGUMENTS\u0026gt;...] 존재하는 리포지터리(repository)는 다음과 같다. main 공식적으로 지원하는 패키지들 community testing 리포지터리에서 테스트된 패키지들 testing 새롭거나, 손상됐거나, 오래된 테스트가 필요한 패키지들 Updating repository\napk update 리포지터리 인덱스를 업데이트한다. Searching\napk search [\u0026lt;OPTIONS\u0026gt;...] PATTERN... 리포지터리에서 PATTERN을 검색한다. Option Description \u0026ndash;description -d 설명에서 PATTERN을 검색한다. \u0026ndash;exact -e 패키지 이름을 정확하게 매칭시킨다. Installing\napk add [\u0026lt;OPTIONS\u0026gt;...] PACKAGES... 패키지를 설치한다.","title":"Linux 배포판 별 패키지 매니저"},{"content":"Docker Docker란 애플리케이션 개발, 실행, 공유를 위한 오픈 플랫폼이다. 호스트 시스템과 격리된 환경에서 애플리케이션을 패키징하고 실행할 수 있게 해준다. (컨테이너) 협업 시 각 로컬에 개발환경을 설치하지 않아도 된다. 서버 관리에 편리하다. https://docs.docker.com/get-started/overview/\n도커 명령어 크게 4가지 종류의 명령어가 있다. Registry 관련 Image 관련 Container 관련 Compose 관련 명령어의 자세한 옵션과 설명은 아래 문서를 참조\ndocker\nRegistry 관련 login\ndocker login Registry에 로그인한다. logout\ndocker logout Registry에서 로그아웃한다. search\ndocker search [OPTIONS] \u0026lt;TERM\u0026gt; Registry에 있는 이미지를 검색한다. Option Default Description \u0026ndash;filter -f key=value 포맷으로 검색을 필터링 한다. stars: star의 개수 (int) is-automated: 자동 빌드 여부 (boolean) is-official: 공식 여부 (boolean) | | \u0026ndash;limit | 25 | 검색 결과의 최대 개수 | | \u0026ndash;no-trunc | | 검색 결과 텍스트를 생략하지 않고 전부 보여준다. | pull\ndocker pull [OPTIONS] \u0026lt;IMAGE\u0026gt; Registry에서 이미지를 내려 받는다. 에 사용자 명을 지정하지 않으면 공식 이미지를 내려 받는다. push\ndocker push [OPTIONS] \u0026lt;IMAGE\u0026gt; 이미지를 Registry에 업로드 한다. Image 관련 build\ndocker image build [OPTIONS] [Dockerfile PATH | URL] Dockerfile을 이용해서 이미지를 빌드한다. ls\ndocker image ls [OPTIONS] 이미지 목록를 보여준다. rm\ndocker image rm [OPTIONS] \u0026lt;IMAGE\u0026gt; [IMAGE...] 하나 또는 하나 이상의 이미지를 제거한다. Option Default Description \u0026ndash;force -f 이미지를 강제로 제거한다. tag\ndocker image tag SOURCE_IMAGE TARGET_IMAGE 이미지에 태그를 설정한다. (IMAGE_ID에 별칭을 부여한다.) 숫자 및 _ - . 으로 이름을 시작할 수 없다. Container 관련 commit\ndocker container commit [OPTIONS] CONTAINER 컨테이너의 변경사항을 이미지로 생성한다. Option Default Description \u0026ndash;author -a 커밋한 사용자를 작성한다. \u0026ndash;message -m 커밋 메시지를 작성한다. diff\ndocker container diff CONTAINER 컨테이너의 변경사항을 확인한다. A: 추가, C: 변경, D: 삭제 exec\ndocker container exec [OPTIONS] CONTAINER COMMAND [ARG...] docker exec 명령어와 같다. 실행 중인 컨테이너에 명령어를 실행한다. Option Default Description \u0026ndash;detach -d 명령어를 백그라운드로 실행한다. \u0026ndash;interactive -i 표준입력을 유지한다. \u0026ndash;tty -t 터미널(pseudo-TTY)을 할당한다. logs\ndocker container logs CONTAINER docker logs 명령어와 같다. 컨테이너의 로그를 보여준다. Option Default Description \u0026ndash;follow -f 로그를 계속 추적하면서 출력한다. \u0026ndash;timestamps -t 시간 데이터를 보여준다. ls\ndocker container ls [OPTIONS] 컨테이너 목록을 보여준다. Option Default Description \u0026ndash;all -a running container 모든 컨테이너를 보여준다. \u0026ndash;size -s 사이즈를 같이 보여준다. prune\ndocker container prune stop 상태인 모든 컨테이너를 제거한다. rename\ndocker container rename CONTAINER NEW_NAME 컨테이너 이름을 변경한다. rm\ndocker container rm [OPTIONS] CONTAINER [CONTAINER...] 하나 또는 하나 이상 컨테이너를 제거한다. Option Default Description \u0026ndash;force -f 동작 중인 컨테이너를 강제로 제거한다. run\ndocker container run [OPTIONS] IMAGE [COMMAND] [ARG...] 이미지를 컨테이너로 생성하고 실행한다. Option Default Description —detach -d 컨테이너의 ID를 출력하고 백그라운드로 실행한다. \u0026ndash;interactive -i 표준입력을 유지한다. \u0026ndash;tty -t 터미널(pseudo-TTY)을 할당한다. \u0026ndash;name random 컨테이너에 이름을 지정한다. \u0026ndash;env -e 환경변수를 설정한다. \u0026ndash;publish -p host(port):container(port) 포맷으로 publish와 bind를 설정한다. \u0026ndash;volume -v 볼륨을 마운트 시킨다. \u0026ndash;rm 종료되면 해당 컨테이너를 삭제한다. start, restart\ndocker container start [OPTIONS] CONTAINER [CONTAINER...] 하나 또는 하나 이상의 컨테이너를 시작한다. 이미 실행 중인 컨테이너를 다시 시작하려면 restart를 사용한다. stop\ndocker container stop [OPTIONS] CONTAINER [CONTAINER...] 하나 또는 하나 이상의 컨테이너를 중지시킨다. Compose 관련 up\ndocker compose up 컴포즈 파일의 컨테이너들을 생성하고 시작한다. down\ndocker compose down 컨테이너를 중단하고 제거한다. Option Default Description \u0026ndash;rmi 서비스에 사용된 이미지를 제거한다. \u0026ndash;volumnes -v 이름이 지정된 volume을 제거한다. Dockerfile Dockerfile을 이용해서 Docker 이미지를 빌드할 수 있다. docker image build 명령어를 사용해서 Dockerfile에 명시된 command line을 수행하도록 할 수 있다. docker image build [Dockerfile 경로] Format\nDockerfile 포맷은 다음과 같다. # Comment INSTRUCTION arguments INSTRUCTION은 대/소문자를 구분하지 않지만, 대문자로 작성하는 것이 컨벤션이다. Dockerfile은 반드시 FROM INSTRUCTION으로 시작해야 한다. Environment replacement\n환경변수는 $variable_name 또는 ${variable_name} 방식으로 사용할 수 있다. ${variable_name} 는 다음과 같은 연산자를 지원한다. ${variable_name:-word} 는 variable_name 이 정의되어있지 않다면 word 로 대체된다. ${variable_name:+word} 는 variable_name 이 정의되어 있다면 word 가 그 값으로 대체되고 정의되어있지 않다면 빈 문자열로 대체된다. FROM\nFROM [--platform=\u0026lt;platform\u0026gt;] \u0026lt;IMAGE\u0026gt; [AS \u0026lt;name\u0026gt;] FROM [--platform=\u0026lt;platform\u0026gt;] \u0026lt;IMAGE\u0026gt;[:\u0026lt;TAG\u0026gt;] [AS \u0026lt;name\u0026gt;] FROM [--platform=\u0026lt;platform\u0026gt;] \u0026lt;IMAGE\u0026gt;[@\u0026lt;DIGEST\u0026gt;] [AS \u0026lt;name\u0026gt;] 생성할 이미지의 베이스 이미지를 설정한다. 멀티 플랫폼 이미지를 참조할 때 --platform 사용하여 플랫폼을 특정할 수 있다. linux/amd64 linux/arm64 windows/amd64 … 뒤에 TAG와 DIGEST는 선택적으로 사용한다. 둘 다 생략했다면 TAG로 latest가 사용된다. AS를 사용해서 빌드 단계에 이름을 줄 수 있다. RUN\nRUN \u0026lt;command\u0026gt; # shell 형식 RUN [\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;] # exec 형식 현재 이미지의 새 레이어에서 실행되고 결과를 커밋되고, 커밋된 이미지는 Dockerfile의 다음 스텝에서 사용된다. RUN 명령어는 두 가지 방식을 따른다. shell 형식 내부적으로 shell 명령어를 호출하여 를 호출한다. exec 형식 사용자가 executable(/bin/sh, /bin/bash…) 을 명시하여 명령어를 실행할 수 있다. CMD\nCMD \u0026lt;command\u0026gt; param1 param2 # shell 형식 CMD [\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;] # exec 형식 컨테이너가 실행될 때 수행될 default 명령어를 설정한다. 컨테이너 실행시 override가 가능하다. CMD는 두 가지 방식을 따른다. shell 형식 내부적으로 shell 명령어를 호출하여 를 호출한다. exec 형식 사용자가 executable(/bin/sh, /bin/bash…) 을 명시하여 명령어를 실행할 수 있다. ENTIRYPOINT\nENTRYPOINT command param1 param2 # shell 형식 ENTRYPOINT [\u0026#34;executable\u0026#34;, \u0026#34;param1\u0026#34;, \u0026#34;param2\u0026#34;] #exec 형식 컨테이너가 실행될 때 가장 먼저 수행되는 명령어를 지정한다. ENTIRYPOINT 명령어는 두 가지 방식을 따른다. shell 형식 내부적으로 shell 명령어를 호출하여 를 호출한다. exec 형식 사용자가 executable(/bin/sh, /bin/bash…) 을 명시하여 명령어를 실행할 수 있다. LABEL\nLABEL \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; ... # 한 줄에 작성 LABEL \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \\ # 여러 줄에 작성 \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \\ \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; \\ ... 키=밸류 방식으로 이미지에 메타데이터를 추가한다. LABEL은 기본 또는 상위 이미지의 LABEL을 현재 이미지에 상속 받는다. 이미지의 라벨은 docker image inspect 명령어로 확인할 수 있다. EXPOSE\nEXPOSE \u0026lt;port\u0026gt; [\u0026lt;port\u0026gt;/\u0026lt;protocol\u0026gt;...] Docker에게 컨테이너가 런타임에서 어떤 네트워크 포트를 사용할 지 알려준다. TCP, UDP를 사용할 수 있고, 명시하지 않는다면 TCP가 사용된다. 실제로 포트를 공개하지는 않지만 docker run -P 명령어를 사용하면 호스트의 랜덤 포트가 컨테이너의 EXPOSE로 명시한 포트에 매핑된다. ENV\nENV \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; ENV \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; ... 환경변수 를 로 설정한다. 컨테이너 실행 시 docker container run —env 명령어로 변경할 수 있다. ADD\nADD [--chown=\u0026lt;user\u0026gt;;\u0026lt;group\u0026gt;] \u0026lt;src\u0026gt;... \u0026lt;dest\u0026gt; ADD [--chown=\u0026lt;user\u0026gt;;\u0026lt;group\u0026gt;] [\u0026#34;\u0026lt;src\u0026gt;\u0026#34;,... \u0026#34;\u0026lt;dest\u0026gt;\u0026#34;] 의 파일, 디렉토리, 리모트 파일의 URL을 에 추가한다. *과 ? 과 같은 패턴을 사용할 수도 있다. # hom으로 시작하는 모든 파일 추가 ADD home* /dir/ # ?는 단일 문자 대체 ADD hom?.txt /dir/ COPY\nCOPY [--chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt;] \u0026lt;src\u0026gt;... \u0026lt;dest\u0026gt; COPY [--chown=\u0026lt;user\u0026gt;:\u0026lt;group\u0026gt;] [\u0026#34;\u0026lt;src\u0026gt;\u0026#34;,... \u0026#34;\u0026lt;dest\u0026gt;\u0026#34;] 이미지에 호스트의 파일이나 디렉토리를 복사한다. ADD는 대상이 압축파일인 경우 해체하여 복사하는 등 기능을 제공하지만, COPY는 복사만 수행한다. WORKDIR\nWORKDIR /path/to/workdir Dockerfile에서 정의한 명령을 실행하기 위한 디렉토리를 지정하며, 경로가 존재하지 않으면 생성한다. ARG\nARG \u0026lt;name\u0026gt;[=\u0026lt;default value\u0026gt;] Dockerfile에서 사용할 변수를 정의한다. ENV와 달리 Dockerfile 내부에서만 사용 가능하다. HEALTHCHECK\nHEALTHCHECK [OPTIONS] CMD command # 사용할 명령을 지정 (curl 등) HEALTHCHECK NONE #기본 이미지에서 상속된 healthcheck 사용 안함 컨테이너가 잘 동작하는지 확인한다. 옵션은 다음과 같다. Option Default Description \u0026ndash;interval=n 30s 헬스 체크 간격 \u0026ndash;timeout=n 30s 헬스 체크 타임아웃 기준 \u0026ndash;retries=n 3 타임아웃 횟수 \u0026ndash;start_period=n 0s 컨테이너 실행 후 대기 시간 Compose file Compose specification\nCompose file versions Reference file What changed in this version https://docs.docker.com/compose/compose-file/ (most current, and recommended) https://docs.docker.com/compose/compose-file/compose-versioning/#versioning https://docs.docker.com/compose/compose-file/compose-file-v3/ https://docs.docker.com/compose/compose-file/compose-versioning/#version-3 https://docs.docker.com/compose/compose-file/compose-file-v2/ https://docs.docker.com/compose/compose-file/compose-versioning/#version-2 Version 1 (Deprecated) https://docs.docker.com/compose/compose-file/compose-versioning/#version-1-deprecated Compose specification Compose specification은 도커가 다중 컨테이너 애플리케이션을 정의하기 위해 만든 새로운 표준 규격이다. **YAML(YML)**을 이용해서 다음과 같은 항목을 정의한다. service(필수), network, volume, config, secret Compose file의 이름은 compose.yaml 또는 docker-compose.yaml을 사용한다. 만약 둘 다 존재하는 경우 Compose spec의 컨벤션인 compose.yaml을 권장한다. Compose 애플리케이션 모델 Compose file은 플랫폼에 의존하지 않는 컨테이너 집합 기반 애플리케이션을 정의한다. 서비스(service) 애플리케이션 컴포넌트를 구성한다. 컨테이너를 실행해서 플랫폼에 구현되는 추상 개념이다. 어떤 서비스는 런타임 또는 플랫폼에 의존적인 **설정(config)**을 필요로 한다. 네트워크(network) 서비스간 통신을 구성한다. 서로 연결된 서비스 컨테이너 간에 IP 라우팅을 위한 플랫폼 기능 추상체이다. 볼륨(volume) 서비스는 볼륨에 데이터를 저장하고 공유한다. config와 secret을 이용해서 컨테이너에 필요한 정책과 보안을 설정할 수 있다. Profile 프로필을 사용해서 환경에 맞게 Compose 애플리케이션 모델을 조정할 수 있다. services는 요소로 서비스 name을 제공하고 그 하위에 profiles 속성을 제공한다. profiles 속성으로 프로필 목록을 정의한다. profiles 속성이 설정되지 않은 서비스는 항상 활성화 된다. 특정 서비스를 실행하는 경우 지정한 프로필이 활성화 된다. services: # 모든 프로필에서 활성화 된다. foo: image: foo # test 프로필에서 활성화 된다. bar: image: bar profiles: - test # test 및 debug 프로필에서 활성화 된다. baz: image: baz depends_on: - bar profiles: - test - debug service의 구성 요소 service의 주요 하위 요소 build image command container_name depends_on environment expose ports healthcheck volumes 다른 구성 요소는 문서를 참고 build\n컨테이너 이미지를 생성하기 위한 빌드 구성을 지정한다. build 요소는 문자열 값을 가지거나 하위 요소를 가질 수 있다. 아래와 같이 build에 문자열 값을 가지면 Dockerfile의 context만 가질 수 있다. services: webapp: build: ./dir build 요소의 하위 요소는 다음과 같다. context: Dockerfile의 context를 지정한다. dockerfile: 사용할 Dockerfile의 이름을 지정한다. args: Dockerfile ARG 값을 정의한다. … services: webapp: build: context: ./dir dockerfile: webapp.Dockerfile args: - GIT_COMMIT=cdc3b19 image\n컨테이너를 시작할 이미지를 지정한다. [\u0026lt;registry\u0026gt;/][\u0026lt;project\u0026gt;/]\u0026lt;image\u0026gt;[:\u0026lt;tag\u0026gt;|@\u0026lt;digest\u0026gt;] 방식으로 기술해야 한다. image: redis image: redis:5 image: library/redis image: docker.io/library/redis image: my_private.registry:5000/redis command\n컨테이너 이미지(CMD)에 선언된 기본 명령을 재정의 한다. services: webapp: command: [\u0026#34;bundle\u0026#34;, \u0026#34;exec\u0026#34;, \u0026#34;thin\u0026#34;, \u0026#34;-p\u0026#34;, \u0026#34;3000\u0026#34;] # exec 형식 command: bundle exec thin -p 3000 # shell 형식 container_name\ncontainer_name은 컨테이너의 이름을 지정한다. services: webapp: container_name: my-web-container **depends_on**\n서비스 간의 시작 및 종료 종속성을 기술한다. 두 가지 방법으로 기술할 수 있다. Short syntax 종속성 서비스 이름만 지정한다. services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 위 예제는 아래와 같은 동작을 의미한다. web 보다 db 및 redis가 빨리 생성된다. web 이 db 및 redis보다 빨리 제거된다. Long syntax 이 방법을 사용하면 추가 필드를 사용할 수 있다. condition: 종속성이 충족된 것으로 간주되는 조건 service_started: (default) 의존하는 서비스가 먼저 시작됨 service_healthy: 의존하는 서비스가 먼저 시작되고, healthy 상태임 service_completed_successfully: 의존하는 서비스가 성공적으로 종료됨 services: web: build: . depends_on: db: condition: service_healthy redis: condition: service_started redis: image: redis db: image: postgres 위 예제는 아래와 같은 동작을 의미한다. web 이 실행되기 전에 db 가 healthy 상태이고 redis가 시작된 상태이다. environment\n컨테이너에 설정된 환경변수를 정의한다. 두 가지 방법으로 환경변수를 정의할 수 있다. Map syntax environment: RACK_ENV: development SHOW: \u0026#34;true\u0026#34; USER_INPUT: Array syntax environment: - RACK_ENV=development - SHOW=true - USER_INPUT expose\n컨테이너에서 노출해야 하는 포트를 정의한다. 호스트 내부의 다른 컨테이너들만 엑세스가 가능하다. expose: - \u0026#34;3000\u0026#34; - \u0026#34;8000\u0026#34; ports\n컨테이너 포트를 노출한다. [HOST:]CONTAINER[/PROTOCOL] ports: - \u0026#34;3000\u0026#34; # 호스트의 랜덤 포트, 컨테이너의 3000번 포트 - \u0026#34;3000-3005\u0026#34; # 컨테이너의 포트 번호 범위내에서 할당 - \u0026#34;8000:8000\u0026#34; - \u0026#34;9090-9091:8080-8081\u0026#34; - \u0026#34;49100:22\u0026#34; - \u0026#34;127.0.0.1:8001:8001\u0026#34; - \u0026#34;127.0.0.1:5000-5010:5000-5010\u0026#34; - \u0026#34;6060:6060/udp\u0026#34; expose vs ports - ports는 호스트와 컨테이너의 포트를 바인딩 시킨다. - ports는 호스트 포트와 컨테이너 포트를 모두 노출시키기 때문에 호스트 내부 컨테이너 간에는 노출된 포트로 접근할 수 있지만, 호스트 외부에서는 컨테이너와 바인딩된 포트로 접근해야 한다. - expose는 호스트 포트를 공개하지 않고 컨테이너의 포트만 공개한다. - 따라서 호스트 외부에서는 컨테이너에 접근할 수 없고 컨테이너 끼리만 접근이 가능하다. healthcheck\n서비스 컨테이너가 healthy 상태인지 확인한다. healthcheck의 하위 구성 요소는 아래와 같다. Element Description disable true 또는 false로 healthcheck 여부를 설정 test 컨테이너 상태를 확인하기 위한 명령 정의. exec 방식과 shell 방식 모두 사용 가능 interval 헬스 체크 간격 timeout 헬스 체크 타임아웃 기준 retries 타임아웃 횟수 start_period 컨테이너 시작 후 대기 시간 healthcheck: test: [\u0026#34;CMD\u0026#34;, \u0026#34;curl\u0026#34;, \u0026#34;-f\u0026#34;, \u0026#34;http://localhost\u0026#34;] interval: 1m30s timeout: 10s retries: 3 start_period: 40s volumes\n서비스 컨테이너에서 엑세스하는 마운트 호스트 경로 또는 정의한 볼륨을 기술한다. 마운트가 단일 서비스에서만 사용되는 경우 최상위 volumes 요소 대신 services 하위 요소로 선언할 수 있다. 여러 서비스가 볼륨을 재사용하려면 최상위 volumes 요소에서 정의된 볼륨을 기술해야 한다. HOST_VOLUME:CONTAINER_PATH:[ACCESS_MODE] HOST_VOLUME: 호스트 경로 또는 최상위 volumes 요소에서 정의한 볼륨 이름 CONTAINER_PATH: 컨테이너의 경로 ACCESS_MODE: 목록은 ,으로 구분된다. rw : 읽기 및 쓰기(기본값) ro : 읽기 전용 services: backend: image: awesome/database volumes: - db-data:/etc/data backup: image: backup-service volumes: - db-data:/var/lib/backup/data volumes: db-data: driver_opts: device: /host/path/to/volume services: backend: image: awesome/database volumes: - /dir1:/etc/data backup: image: backup-service volumes: - /dir2:/var/lib/backup/data:ro ","permalink":"https://jo-minjun.github.io/notes/docker-study/","summary":"Docker Docker란 애플리케이션 개발, 실행, 공유를 위한 오픈 플랫폼이다. 호스트 시스템과 격리된 환경에서 애플리케이션을 패키징하고 실행할 수 있게 해준다. (컨테이너) 협업 시 각 로컬에 개발환경을 설치하지 않아도 된다. 서버 관리에 편리하다. https://docs.docker.com/get-started/overview/\n도커 명령어 크게 4가지 종류의 명령어가 있다. Registry 관련 Image 관련 Container 관련 Compose 관련 명령어의 자세한 옵션과 설명은 아래 문서를 참조\ndocker\nRegistry 관련 login\ndocker login Registry에 로그인한다. logout\ndocker logout Registry에서 로그아웃한다. search\ndocker search [OPTIONS] \u0026lt;TERM\u0026gt; Registry에 있는 이미지를 검색한다.","title":"Docker 스터디"},{"content":"0. 참고 도메인 주도 개발 시작하기\n도메인 주도 개발 시작하기 - YES24 핵사고날 아키텍처\nHexagonal Architecture with Java and Spring\nhttps://herbertograca.com/2017/11/16/explicit-architecture-01-ddd-hexagonal-onion-clean-cqrs-how-i-put-it-all-together/\n예제 프로젝트\nhttps://github.com/jo-minjun/order-delivery-project 1. 도메인이란 무엇일까? wikipedia: Domain (software engineering) A domain is the targeted subject area of a computer program. It is a term used in software engineering. Formally it represents the target subject of a specific programming project, whether narrowly or broadly defined.\n소프트웨어 엔지니어링에서 사용되는 용어 컴퓨터 프로그램의 대상이 되는 영역 Example 소프트웨어 프로젝트의 목표가 특정 병원을 위한 프로그램을 만드는 경우 범위를 확장하여 모든 병원을 대상으로 하는 프로그램을 만드는 경우 상점과 기사를 이어주고 고객에게 물품을 전달해주는 라스트마일 서비스 2. DDD란 무엇일까? Domain Driven Design이다. 프로그램을 도메인별로 나누어 설계하는 방법 모듈(도메인)간 응집도는 높이고, 결합도는 낮춰 준다. DDD의 목표를 달성하기 위해 전략적 설계 패턴과 전술적 설계 패턴을 사용한다. 3. 왜 DDD를 할까? 복잡도 관리 시간 경과에 따라 코드 라인이 늘어나고, 변경 비용이 증가한다. https://dreamix.eu/blog/java/why-good-clean-software-architecture-matters 개발자는 특정 도메인의 전문가보다 도메인에 대한 전문성이 떨어진다. 공인 중개사와 개발자 변호사와 개발자 인사팀과 개발자 … 전문가와 기획자, 개발자의 언어가 다르다. 도저히 이해할 수 없는 말들… 네트워크 광전송 장비: OTN, PTN, ROADM, SERVICE, TUNNEL… → 최소 문서를 읽거나 대화할 때 서로가 하는 말을 이해하고 context를 맞춰 나가야 한다.\n4. 전략적 설계 유비쿼터스 언어 도메인 전문가, 기획자, 개발자 등 구성원들이 서로 다른 용어를 사용하면, 의사소통에 불편함이 있다. 지번주소 vs 구주소 → 유비쿼터스 언어를 사용해야 한다.\n구성원들 모두가 보편적으로 사용하는 언어 구성원들의 공통된 언어를 만들고 대화, 문서, 코드, 테스트 모든 곳에서 같은 용어를 사용한다. 도메인 모델과 경계 다시 도메인에 대해 짚어보자면 소프트웨어 프로젝트에서 대상이 되고, 해결해야 할 영역 온라인 쇼핑몰을 개발하는 프로젝트 도메인은 다시 하위 도메인으로 나뉘어 진다. 회원, 혜택(쿠폰), 주문, 카탈로그, 배송, 결제… 도메인 모델 특정 도메인을 개념적으로 표현한 것 도메인에 대한 이해도에 따라 도메인 모델도 변경된다. 위와 같은 서브 도메인을 하나의 도메인으로 표현하기는 불가능에 가깝다. 서브 도메인마다 같은 대상이라도 지칭하는 용어가 다를 수 있다. → Problem Space가 된다.\n상품 카탈로그의 상품: 이미지, 상품명, 가격… 배송의 상품: 무게, 수량… 회원 회원 도메인의 회원: 회원 주문 도메인의 회원: 주문자 배송 도메인의 회원: 받는 사람 즉, 모델은 특정한 컨텍스트 하에서 완전한 의미를 갖는다. → 각 서브 도메인마다 명시적으로 구분되는 경계를 가져서 섞이지 않도록 해야 한다.\n바운디드 컨텍스트 각 도메인 영역의 경계를 결정하는 명시적인 구분 각각의 도메인이 가진 모델을 정확하게 표현하기 위함이다. → 즉 문제를 해결하기 위한 공간, Solution Space이다.\n바운디드 컨텍스트를 구분하는 조건 같은 용어, 다른 의미 계정을 의미하는 Account 계좌를 의미하는 Account → 이런 경우 두 가지 의미를 하나의 도메인 모델에 포함해서는 안된다. 같은 개념, 다른 용도 회원 서비스의 맴버 주문 서비스의 맴버 → 맴버는 서로 다른 도메인에 집중하고 있고, 발전의 방향성도 다르다. 팀 조직 구조 A팀의 관심사는 주문, B팀의 관심사는 결제. 하나의 주문 도메인에서도 관심사에 따라 컨텍스트가 달라진다. 한 팀이 하나의 시스템에서 온라인 쇼핑을 서비스한다. 서브 도메인은 회원, 카탈로그, 재고, 구매, 결제 등이 있다. 상품 컨텍스트에서 재고와 카탈로그를 구현한다. 이상적으로는 바운디드 컨텍스트와 하위 도메인이 1대1로 대응되는 것이 좋다. 하지만 팀 상황이나 유비쿼터스 언어가 명확하게 정의되지 않아 1대1로 대응되지 않는 경우도 있다. 바운디드 컨텍스트 간 관계 바운디드 컨텍스트는 어떻게든 연결되기 때문에 다양한 방식으로 관계를 형성한다. 고객/공급자 공유 커널 독립 방식 고객/공급자 가장 흔한 관계이다. 한쪽에서 **API를 제공(상류)**하고 다른쪽에서 **API를 호출(하류)**한다. 카탈로그 바운디드 컨텍스트는 추천 바운디드 컨텍스트에 의존한다. 공유 커널 여러 바운디드 컨텍스트가 같은 모델을 공유하는 관계이다. 중복을 줄일 수 있지만 공유 모델을 사용하는 바운디드 컨텍스트가 서로 영향을 받을 수 있다. 독립 방식 여러 바운디드 컨텍스트가 외부에 의해 관계를 맺는다. 수동으로 두 바운디드 컨텍스트 간 통합시킨다. 사람에 의한 관계 자동화 시스템을 개발해서 두 바운디드 컨텍스트를 통합시킨다. 자동화 시스템에 의한 관계 바운디드 컨텍스트 맵 특정 바운디드 컨텍스트에 과도하게 집중하면 전체적인 바운디드 컨텍스트 간의 관계를 인식하지 못할 수 있다. 도메인을 더 잘 이해하거나 컨텍스트 간 관계가 바뀌면 컨텍스트 맵도 바뀐다. 5. 핵사고날 아키텍처 예제 프로젝트에 핵사고날 아키텍처를 적용했다. https://reflectoring.io/spring-hexagonal/ └── xxx ├── adapter │ ├── in │ │ ├── xxxController.java │ │ └── EventHandler.java (or MessageHandler.java) │ └── out │ └── EventPublisher.java (or MessagePublisher.java) ├── application │ ├── xxxService.java │ └── port │ ├── in │ │ ├── xxxCommand.java │ │ ├── xxxDto.java │ │ └── xxxUsecase.java │ └── out │ ├── xxxEvent.java │ ├── xxxEventPublisher.java │ └── xxxRepository.java └── domain ├── AggregateRootEntity.java └── ValueObject.java 6. 전술적 설계 도메인 영역의 주요 구성 요소 요소 설명 엔티티 (ENTITY) 고유의 식별자를 갖는 객체로 자신의 라이프 사이클을 갖는다. 도메인의 고유한 개념을 표현한다. 도메인 모델의 데이터를 포함하며 해당 데이터와 관련된 기능을 함께 제공한다. 밸류 (VALUE) 고유의 식별자를 갖지 않는 객체다. 엔티티의 속성으로 사용할 뿐만 아니라 다른 밸류 타입의 속성으로도 사용할 수 있다. 애그리거트 (AGGREGATE) 애그리거트는 연관된 엔티티와 밸류 객체를 개념적으로 하나로 묶은 것이다. 리포지터리 (REPOSITORY) 도메인 모델의 영속성을 처리한다. 도메인 서비스 (DOMAIN SERVICE) 특정 엔티티에 속하지 않은 도메인 로직을 제공한다. 도메인 로직이 여러 엔티티와 밸류를 필요로 하면 도메인 서비스에서 로직을 구현한다. 엔티티 \u0026amp; 밸류 도메인 모델을 표현할 때 이용한다.\n도메인 모델의 엔티티는 기능을 함께 제공한다.\n도메인 관점에서 도메인 로직을 구현하고 캡슐화해서 데이터가 임의로 변경되는 것을 막는다. package minjun.ddd.delivery.domain; public void changeDeliveryInfo(Address address, String phoneNumber) { canChangeDelivery(); this.address = address; this.phoneNumber = phoneNumber; } private void canChangeDelivery() { if (!this.status.canChangeDelivery()) { throw new RuntimeException(\u0026#34;배송 정보 수정 불가\u0026#34;); } } 외부에서 setter를 이용해 배송지 정보를 변경한다면 배송지 변경 가능 여부 검증이 누락될 수 있고, 같은 로직이 반복될 수도 있다. final DeliveryStatus status = delivery.getStatus(); // 배송지 변경 조건 if (!this.status.canChangeDelivery()) { throw new RuntimeException(\u0026#34;배송 정보 수정 불가\u0026#34;); } delivery.setAddress(newAddress); delivery.setPhoneNumber(newPhoneNumber); 밸류는 도메인 모델에서 두 개 이상의 데이터가 개념적으로 하나인 경우 사용한다.\npackage minjun.ddd.order.domain; @Entity @Table(name = \u0026#34;orders\u0026#34;) @Getter @NoArgsConstructor(access = AccessLevel.PROTECTED) @AllArgsConstructor @EqualsAndHashCode(of = {\u0026#34;id\u0026#34;}) @ToString(of = {\u0026#34;id\u0026#34;, \u0026#34;orderLine\u0026#34;, \u0026#34;totalAmount\u0026#34;, \u0026#34;deliveryId\u0026#34;, \u0026#34;paymentId\u0026#34;}) public class Order implements Serializable { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @Embedded private OrderLine orderLine; // 밸류 타입, AttributeConverter를 이용함. private Money totalAmount = Money.ZERO; ... // 다른 필드 package minjun.ddd.common; @Converter(autoApply = true) public class MoneyConverter implements AttributeConverter\u0026lt;Money, BigDecimal\u0026gt; { @Override public BigDecimal convertToDatabaseColumn(Money attribute) { return attribute.getValue(); } @Override public Money convertToEntityAttribute(BigDecimal dbData) { return new Money(dbData); } } 엔티티는 @Entity 애너테이션을 사용한다.\n밸류는 @Embeddable, @Embedded, @SecondaryTable, @ElementCollection, @CollectionTable을 사용한다.\n@ElementCollection은 생명주기를 상위 엔티티에 종속시킨다. 즉, cascade와 orphanRemoval 옵션을 제공하지 않는다. @OneToMany(cascade = ALL, orphanRemoval = true)와 차이점 @ElementCollection은 식별자를 갖지 않는다. package minjun.ddd.order.domain; @Embedded private OrderLine orderLine; package minjun.ddd.order.domain; @Embeddable public class OrderLine { @ElementCollection @CollectionTable(name = \u0026#34;order_lines\u0026#34;, joinColumns = @JoinColumn(name = \u0026#34;orders_id\u0026#34;)) private Set\u0026lt;LineItem\u0026gt; lineItems = new HashSet\u0026lt;\u0026gt;(); ... // 메서드 } @AttributeOverride를 이용해서 @Embeddable 밸류의 애트리뷰트를 override할 수도 있다. 애그리거트 도메인이 커지면 도메인 모델이 복잡해진다.\n도메인 모델이 복잡해지면 전체 구조에 초점을 맞추지 못하게 되고, 모델 간에 관계를 이해하기 어렵게 된다.\n애그리거트는 관련 객체를 묶어서 상위 개념으로 표현해준다.\nOrder 도메인은 주문, 주문 목록, 총 결제 금액 등 하위 모델로 구성된다. 이를 하나로 묶어 주문이라는 상위 개념으로 표현해준다. 애그리거트는 루트 엔티티를 가지며, 이를 애그리거트 루트라 한다.\n애그리거트 루트는 애그리거트에 속해 있는 엔티티와 밸류 객체를 이용해서 애그리거트가 구현해야 할 기능을 제공한다.\n애그리거트의 내부 구현을 숨겨서 애그리거트 단위로 구현을 캡슐화 한다. package minjun.ddd.delivery.domain; @Entity ... // 애너테이션 public class Delivery { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @Embedded private Address address; private String phoneNumber; ... // 다른 필드 public void changeDeliveryInfo(Address address, String phoneNumber) { canChangeDelivery(); this.address = address; this.phoneNumber = phoneNumber; } 리포지터리 리포지터리는 애그리거트 단위로 도메인 객체를 저장하고 조회한다. package minjun.ddd.order.application.port.out; import minjun.ddd.order.domain.Order; import org.springframework.data.jpa.repository.JpaRepository; public interface OrderRepository extends JpaRepository\u0026lt;Order, Long\u0026gt; { } 애그리거트의 루트 엔티티만 리포지터리를 갖는다.\n애그리거트의 밸류 등은 루트 엔티티와 생명 주기가 같다. 생명 주기가 다르거나 데이터 변경 주체가 다르다면 다른 애그리거트일 가능성이 높다. package minjun.ddd.product.application.port.out; import minjun.ddd.product.domain.Product; import org.springframework.data.jpa.repository.JpaRepository; public interface ProductRepository extends JpaRepository\u0026lt;Product, Long\u0026gt; { } Product 애그리거트는 Order나 Delivery와 연관이 있기 때문에 같은 애그리거트로 생각될 수 있다. 하지만 Order나 Delivery는 변경 주체가 주문자와 기사이지만, Product는 상품 관리자가 관리한다. 도메인 서비스 도메인 영역을 개발하다 보면 한 애그리거트로 기능을 구현하지 못할 때가 있다. 결제 금액 계산 로직에 할인이 적용되는 경우 할인 쿠폰 애그리거트: 쿠폰별로 지정한 금액이나 비율에 따라 총 금액을 할인한다. 회원 애그리거트: 회원 등급에 따라 추가 할인이 가능하다. 주문 애그리거트에 할인 관련 로직을 적용하면 할인 정책 변경시 주문 애그리거트가 변경된다. → 도메인 서비스 사용\npublic class DiscountCalculationService { public Money calculateDiscountAmounts(List\u0026lt;OrderLine\u0026gt; orderLines, List\u0026lt;Coupon\u0026gt; coupons, MemberGrade grade) { Money couponDiscount = coupons.stream() .map(coupon -\u0026gt; calculateDiscount(coupon)) .reduce(new Money(0), (v1, v2) -\u0026gt; v1.add(v2)); Money membershipDiscount = calculateDiscount(orderer.getMember().getGrade()); return couponDiscount.add(membershipDiscount); } private Money calculateDiscount(Coupon coupon) { ... } private Money calculateDiscount(MemberGrade grade) { ... } } 외부 시스템이나 타 도메인과 연동 기능도 도메인 서비스가 될 수 있다.\n상품 관리 시스템에서 사용자가 권한을 가졌는지 확인하기 위해 맴버 시스템을 연동하는 경우\npublic interface PermissionChecker { boolean hasUserPermission(String userId); } 여기서 인터페이스는 외부 시스템의 역할을 표현하기 위해 도메인 로직 관점에서 작성한다. public class CreateProductService { private PermissionChecker permissionChecker; public Long createProduct(CreateProductRequest req) { validate(req); if (!permissionChecker.hasUserPermission(req.getUserId)) { throw new NoPermissionException(); } ... // 생성 } } 이벤트 API를 이용하는 방법은 시스템간 결합 문제를 발생시킨다.\n외부 서비스의 성능 트랜잭션 처리 정책 설계상 문제 외부 서비스의 성능\n트랜잭션 처리 정책\n환불 외부 서비스에서 익셉션이 발생하면 주문까지 트랜잭션을 롤백한다. 주문만 취소 상태로 변경하고 환불은 나중에 처리한다. 설계상 문제\npackage minjun.ddd.order.application.service; @Service @RequiredArgsConstructor @Transactional public class OrderService implements OrderUsecase { private final PaymentPort paymentPort; @Override public void cancelOrder(Long orderId) { final Order order = findOrder(orderId); // Payment 도메인 로직 final Boolean responseFromPayment = paymentPort.cancelPayment(order.getPaymentId()); if (!responseFromPayment) { throw new RuntimeException(\u0026#34;결제 취소 실패\u0026#34;); } // Order 도메인 로직 order.cancelOrder(); } } 다른 도메인의 로직이 섞이고, 트랜잭션 처리 정책 및 외부 서비스 영향이 증가한다. → 시스템의 결합도를 낮추기 위해 이벤트를 사용한다.\n이벤트는 과거에 벌어진 어떤 것을 의미하며, 상태가 변경됐다는 것을 의미한다.\n이벤트는 다음과 같이 네 개의 구성요소를 가진다. 이벤트\n이벤트 종류, 발생 시간, 이벤트 관련 정보 이벤트 생성 주체\n도메인 로직을 실행해서 상태가 바뀌면 관련 이벤트를 발생시킨다. package minjun.ddd.delivery.application; @Override public void startDelivery(Long deliveryId) { final Delivery delivery = deliveryRepository.findById(deliveryId) .orElseThrow(NoSuchElementException::new); delivery.startDelivery(); deliveryEventPublisher.publish(new DeliveryStartedEvent(delivery)); } 이벤트 디스패처\n핸들러에 이벤트를 전파한다. package minjun.ddd.delivery.adapter.out; // org.springframework.context.ApplicationEventPublisher private final ApplicationEventPublisher publisher; @Override public void publish(DeliveryEvent event) { publisher.publishEvent(event); log.info(\u0026#34;Order Event Published: {} {}\u0026#34;, event.getDelivery(), event.getTimestamp()); } 이벤트 핸들러\n이벤트 생성 주체가 발생시킨 이벤트에 반응한다. package minjun.ddd.order.adapter.in; @EventListener(DeliveryStartedEvent.class) public void handleDeliveryStartedEvent(DeliveryStartedEvent event) { orderUsecase.startDelivery(event.getDelivery().getOrderId()); } 위와 같은 방법이 아닌, 메시징 시스템을 이용한 방법도 가능하다.\n이벤트 저장소를 이용한 메시징 (Transactional Outbox Pattern) 이벤트 발행 서비스 이벤트 소비 서비스 ","permalink":"https://jo-minjun.github.io/notes/ddd-study/","summary":"0. 참고 도메인 주도 개발 시작하기\n도메인 주도 개발 시작하기 - YES24 핵사고날 아키텍처\nHexagonal Architecture with Java and Spring\nhttps://herbertograca.com/2017/11/16/explicit-architecture-01-ddd-hexagonal-onion-clean-cqrs-how-i-put-it-all-together/\n예제 프로젝트\nhttps://github.com/jo-minjun/order-delivery-project 1. 도메인이란 무엇일까? wikipedia: Domain (software engineering) A domain is the targeted subject area of a computer program. It is a term used in software engineering. Formally it represents the target subject of a specific programming project, whether narrowly or broadly defined.\n소프트웨어 엔지니어링에서 사용되는 용어 컴퓨터 프로그램의 대상이 되는 영역 Example 소프트웨어 프로젝트의 목표가 특정 병원을 위한 프로그램을 만드는 경우 범위를 확장하여 모든 병원을 대상으로 하는 프로그램을 만드는 경우 상점과 기사를 이어주고 고객에게 물품을 전달해주는 라스트마일 서비스 2.","title":"DDD 핵심 정리"},{"content":"1. 요구사항 아주 간단한 웹 기반 ITunes 주요 데이터는 다음과 같다. 가수 (Singer) 이름 정보를 가진다. 앨범 (Album) 발매 날짜, 앨범 제목 정보를 가진다. 노래 (Song) 노래 제목과 재생 시간 정보를 가진다. 공통 데이터 생성 시간 업데이트 시간 생성한 사람 업데이트한 사람 주요 기능 가수를 등록할 수 있다. 앨범을 등록할 수 있다. 노래를 등록할 수 있다. 노래 목록들을 조회할 수 있다. 노래를 조회할 수 있다. 노래를 업데이트 할 수 있다. 노래를 삭제할 수 있다. 엔티티 Class 2. 프로젝트 scaffolding 섀시 패턴 아래와 같은 프로젝트들의 공통 관심사를 편리하게 설정할 수 있다. health check 패턴: actuator 개발 생산성 확보: spring-configuration-processor, lombok, mapstruct: 로깅 패턴: logback, request - response 로깅 추적 패턴: B3 Propagation(Sleuth), Sentry 적용 로컬 개발 환경: docker-compose를 이용한 local cluster 구성 (UAA + MySQL + Kafka + …) Persistence: QueryDSL, JPA Specification integration API-First: OpenApi Generator 및 Zalando problem details 연동 Scheduler: ShedLock 연동 Security: UAA 및 리소스 서버 통합 CI / CD: 도커 이미지 빌드, 젠킨스 연동 msa-bootcamp 프로젝트 세팅 (Meshkorea) git clone https://github.com/meshkorea/msa-starter.git\nstarter project를 clone한다. cd msa-starter \u0026amp;\u0026amp; ./gradlew generate\n위 명령어를 수행하면 아래와 같은 세팅 메세지가 나온다. Starting a Gradle Daemon (subsequent builds will be faster) \u0026gt; Task :getBuildInfo \u0026gt; WebMVC/JPA 프로젝트인가요(m)? WebFlux/R2DBC 프로젝트인가요(f) (default: m)? \u0026lt;====---------\u0026gt; 33% EXECUTING [17s] \u0026gt; 부릉 프로젝트입니까(y/n, default: n)?: \u0026lt;====---------\u0026gt; 33% EXECUTING [27s] \u0026gt; 사용하려는 자바 버전은 무엇입니까(1.8/11, default: 11)?: \u0026lt;====---------\u0026gt; 33% EXECUTING [31s] 11 \u0026gt; 프로젝트 이름은 무엇입니까(default: example)? \u0026lt;====---------\u0026gt; 33% EXECUTING [35s] \u0026gt; 그룹 이름은 무엇입니까(default: com.vroong)? \u0026lt;====---------\u0026gt; 33% EXECUTING [38s] \u0026gt; 웹 서버 포트는 무엇입니까(default: 8080)? \u0026lt;====---------\u0026gt; 33% EXECUTING [42s] \u0026gt; 웹 요청 및 응답에 사용할 미디어 타입은 무엇입니까(default: application/vnd.vroong.private.v1+json)? \u0026lt;====---------\u0026gt; 33% EXECUTING [47s] 진행할까요(\u0026#39;n\u0026#39; to quit)? [osArch:intel, projectType:v, projectName:example, groupName:com.vroong, packageName:com.vroong.example, portNumber:8080, mediaType:application/vnd.vroong.private.v1+json, javaVersion:11, dockerImage:amazoncorretto:11-alpine-jdk, skipTokens:[.DS_Store]] \u0026lt;====---------\u0026gt; 33% EXECUTING [50s] \u0026gt; Task :generate cp -r build {path-to-your-project}\ncd {path-to-your-project} \u0026amp;\u0026amp; ./gradlew clean build\ngit init\n로컬 개발 환경 구동 방법 JDK 설치 corretto11 jhipster-uaa 세팅 msa-starter 디렉토리의 jhipster-uaa.zip을 해제한다. cd jhipster-uaa \u0026amp;\u0026amp; ./gradlew jibDockerBuild -Djib.to.image=jhipster-uaa -Djib.to.tags=latest 로컬에서는 jhipster-uaa를 사용하지만, EKS에 올렸을 때는 이미 구동중인 vroong-uaa를 사용한다. 도커 구동 ./gradlew clusterUp MySQL (3306) Kafka (9092) jhipster-uaa (9999) 애플리케이션 구동 3. API-First 개발 방법론 API-First 개발 방법론 API를 중심으로 제품을 설계하는 방법이다. API는 중요한 비즈니스 요소이며, 개발 조직에 API를 제공하는 것이 높은 우선순위를 가진다고 인식하는 것이다. API-First 장점 일관성 제공 API-First 도구를 사용하여 일관성 있는 설계 및 문서화를 통해 일관된 개발자 경험을 제공할 수 있도록 해준다. 병렬 개발 편의성 API를 먼저 설계하고 결과물로 나온 API Spec을 이용해서 서버 스켈레톤과 클라이언트 SDK(API 문서 + 클라이언트 라이브러리 Stub)를 생성할 수 있고 클라이언트와 서버가 생성된 코드를 이용해서 빠르게 개발을 시작할 수 있다. 개발 속도 향상 API-First 도구는 클라이언트 SDK를 생성해주고, 이를 사내 Repository에 공유할 수 있다. 개발자들은 Mock API를 사용함으로써, API가 완성되기 전에 클라이언트를 구축할 수 있다. 빠른 피드백 제공 클라이언트 개발자는 서버 개발자가 개발 완료 후 API를 제공할 때까지 기다리지 않고, API 문서와 Mock API를 이용하여 설계를 검토하고 검증해볼 수 있다. API-First 도구 - OAS (OpenApi Specification) OAS는 REST API를 위한 IDL(Interface Defintion Language) 이다. API 스펙 및 기능, 설명을 기술한다. OAS 파일은 YAML 또는 JSON으로 작성할 수 있다. OAS 파일은 아래 내용을 포함한 내용을 기술할 수 있다. API endpoint와 HTTP method (GET /users, POST /users 등) 각 API의 요청과 응답의 파라미터 인증 method 이용 방법, 라이센스, 연락처 등과 기타 정보 Swagger Editor/IDE plugin를 사용하면 OpenApi Specification의 문법 오류와 UI를 확인 할 수 있다. OpenApi Generator의 특징 OpenApi Generator를 사용하면 서버의 코드 스켈레톤과 클라이언트의 SDK를 자동으로 생성해준다. 서버 스켈레톤은 각 API에 대한 기술없이, 구현만 해주면 된다. JAVA 뿐만 아니라 PHP, GO, C++, C#, Python, Ruby, Typescript 등 대부분의 언어를 지원한다. API Interface 뿐만 아니라 model도 구현해주고, 정규 표현식 또는 다른 제한을 validation 까지 해준다. 브라우저에서 사용자가 직접 호출해볼 수 있는 interactive API 문서를 만들어 준다. Ex) Swagger Editor OAS 문법 https://swagger.io/docs/specification/basic-structure/\n간단한 OAS 예시\nopenapi: \u0026#34;3.0.1\u0026#34; info: title: \u0026#34;msa-bootcamp\u0026#34; version: 1.0.0 servers: - url: http://localhost:8080 description: Local server paths: /api/singers: post: description: create an singer operationId: createSinger tags: - Singer requestBody: description: singer model content: application/vnd.vroong.private.v1+json: schema: $ref: \u0026#34;#/components/schemas/CreateSingerRequest\u0026#34; responses: \u0026#34;201\u0026#34;: $ref: \u0026#34;#/components/responses/Created\u0026#34; \u0026#34;400\u0026#34;: $ref: \u0026#34;#/components/responses/BadRequest\u0026#34; \u0026#34;401\u0026#34;: $ref: \u0026#34;#/components/responses/Unauthorized\u0026#34; \u0026#34;403\u0026#34;: $ref: \u0026#34;#/components/responses/Forbidden\u0026#34; \u0026#34;500\u0026#34;: $ref: \u0026#34;#/components/responses/ServerError\u0026#34; components: schemas: CommonProperties: type: object properties: createdAt: $ref: \u0026#34;#/components/schemas/DateTime\u0026#34; updatedAt: $ref: \u0026#34;#/components/schemas/DateTime\u0026#34; createdBy: $ref: \u0026#34;#/components/schemas/UUID\u0026#34; updatedBy: $ref: \u0026#34;#/components/schemas/UUID\u0026#34; Page: type: object properties: size: type: integer format: int32 default: 20 example: 20 totalElements: type: integer format: int64 example: 100 totalPages: type: integer format: int32 example: 5 number: type: integer format: int32 default: 1 example: 1 CreateSingerRequest: type: object required: - name properties: name: type: string Singer: allOf: - $ref: \u0026#34;#/components/schemas/CommonProperties\u0026#34; - type: object properties: singerId: $ref: \u0026#34;#/components/schemas/LongId\u0026#34; name: type: string 서버 코드 스켈레톤 생성 및 클라이언트 SDK 생성 OpenApi Generator를 사용한다.\nhttps://openapi-generator.tech/docs/installation 서버 코드 스켈레톤 생성\n아래와 같이 gradle이 정의되어 있어야 한다. plugin { id \u0026#39;org.openapi.generator\u0026#39; version \u0026#39;4.3.1\u0026#39; } openApiGenerate { generatorName = \u0026#39;spring\u0026#39; inputSpec = \u0026#34;$rootDir/src/main/resources/swagger/api.yml\u0026#34;.toString() outputDir = \u0026#34;$buildDir/openapi\u0026#34;.toString() apiPackage = \u0026#39;com.vroong.msabootcamp.api\u0026#39; modelPackage = \u0026#39;com.vroong.msabootcamp.api.model\u0026#39; modelNameSuffix = \u0026#34;Dto\u0026#34; apiFilesConstrainedTo = [\u0026#34;\u0026#34;] modelFilesConstrainedTo = [\u0026#34;\u0026#34;] supportingFilesConstrainedTo = [\u0026#34;ApiUtil.java\u0026#34;] configOptions = [ delegatePattern: \u0026#34;true\u0026#34;, title: \u0026#34;msabootcamp\u0026#34;, useTags: \u0026#34;true\u0026#34;, dateLibrary: \u0026#34;java8\u0026#34;, java8: \u0026#34;true\u0026#34;, hideGenerationTimestamp: \u0026#34;true\u0026#34; ] validateSpec = true } sourceSets { main { java { srcDir file(\u0026#34;${project.buildDir.path}/openapi/src/main/java\u0026#34;) } } } ./gradlew openApiGenerate Stub을 생성하면 아래의 파일이 생성된다. model에는 OAS에서 정의한 schema를 가진 DTO가 있다. 클라이언트 SDK 빌드 및 배포\n./gradlew :clients:clean :clients:publish -Dorg.gradle.internal.publish.checksums.insecure=true # 배포 결과는 https://nexus.mm.meshkorea.net/ 에서 확인할 수 있습니다. 4. Controller 작성 서버 코드 스켈레톤을 이용해서 controller를 구현한다. SingerApi\n/** * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech) (5.3.0). * https://openapi-generator.tech * Do not edit the class manually. */ @javax.annotation.Generated(value = \u0026#34;org.openapitools.codegen.languages.SpringCodegen\u0026#34;) @Validated @Api(value = \u0026#34;Singer\u0026#34;, description = \u0026#34;the Singer API\u0026#34;) public interface SingerApi { default SingerApiDelegate getDelegate() { return new SingerApiDelegate() {}; } /** * POST /api/singers * create an singer * * @param createSingerRequestDto singer model (optional) * @return Created (status code 201) * or Bad Request (status code 400) * or Unauthorized (status code 401) * or Forbidden (status code 403) * or Internal Server Error (status code 500) */ @ApiOperation(value = \u0026#34;\u0026#34;, nickname = \u0026#34;createSinger\u0026#34;, notes = \u0026#34;create an singer\u0026#34;, authorizations = { @Authorization(value = \u0026#34;jhipster-uaa\u0026#34;, scopes = { }), @Authorization(value = \u0026#34;jhipster-uaa\u0026#34;, scopes = { }) }, tags={ \u0026#34;Singer\u0026#34;, }) @ApiResponses(value = { @ApiResponse(code = 201, message = \u0026#34;Created\u0026#34;), @ApiResponse(code = 400, message = \u0026#34;Bad Request\u0026#34;, response = ProblemDetailsDto.class), @ApiResponse(code = 401, message = \u0026#34;Unauthorized\u0026#34;, response = ProblemDetailsDto.class), @ApiResponse(code = 403, message = \u0026#34;Forbidden\u0026#34;, response = ProblemDetailsDto.class), @ApiResponse(code = 500, message = \u0026#34;Internal Server Error\u0026#34;, response = ProblemDetailsDto.class) }) @RequestMapping( method = RequestMethod.POST, value = \u0026#34;/api/singers\u0026#34;, produces = { \u0026#34;application/problem+json\u0026#34; }, consumes = { \u0026#34;application/vnd.vroong.private.v1+json\u0026#34; } ) default ResponseEntity\u0026lt;Void\u0026gt; createSinger(@ApiParam(value = \u0026#34;singer model\u0026#34;) @Valid @RequestBody(required = false) CreateSingerRequestDto createSingerRequestDto) { return getDelegate().createSinger(createSingerRequestDto); } } SingerApiController\n@javax.annotation.Generated(value = \u0026#34;org.openapitools.codegen.languages.SpringCodegen\u0026#34;) @Controller @RequestMapping(\u0026#34;${openapi.msabootcamp.base-path:}\u0026#34;) public class SingerApiController implements SingerApi { private final SingerApiDelegate delegate; public SingerApiController(@org.springframework.beans.factory.annotation.Autowired(required = false) SingerApiDelegate delegate) { this.delegate = Optional.ofNullable(delegate).orElse(new SingerApiDelegate() {}); } @Override public SingerApiDelegate getDelegate() { return delegate; } } SingerApiDelegate\n/** * A delegate to be called by the {@link SingerApiController}}. * Implement this interface with a {@link org.springframework.stereotype.Service} annotated class. */ @javax.annotation.Generated(value = \u0026#34;org.openapitools.codegen.languages.SpringCodegen\u0026#34;) public interface SingerApiDelegate { default Optional\u0026lt;NativeWebRequest\u0026gt; getRequest() { return Optional.empty(); } /** * POST /api/singers * create an singer * * @param createSingerRequestDto singer model (optional) * @return Created (status code 201) * or Bad Request (status code 400) * or Unauthorized (status code 401) * or Forbidden (status code 403) * or Internal Server Error (status code 500) * @see SingerApi#createSinger */ default ResponseEntity\u0026lt;Void\u0026gt; createSinger(CreateSingerRequestDto createSingerRequestDto) { return new ResponseEntity\u0026lt;\u0026gt;(HttpStatus.NOT_IMPLEMENTED); } } SingerApiDeleateImpl\n@RequiredArgsConstructor @Component public class SingerApiDelegateImpl implements SingerApiDelegate { private final SingerService singerService; @Override public ResponseEntity\u0026lt;Void\u0026gt; createSinger(CreateSingerRequestDto createSingerRequestDto) { SingerDto singerDto = singerService.createSinger(createSingerRequestDto); return ResponseEntity .created(HeaderUtils.uri(String.valueOf(singerDto.getSingerId()))) .build(); } } 5. Messaging 이벤트 메세지 또는 커맨드 메세지를 이용하여 상호간에 통신하는 방식 이벤트 이미 일어난 정보에 대한 메세지이다. immutable 하다. producer는 이벤트의 comsumer가 누구인지, 무엇을 하는지 모른다. ex) 신규 물품이 입고되었을 때 필요한 시스템만 이벤트를 구독한다. 신규 물품이 입고된 것은 이미 일어난 사건이다. 커맨드 수행할 작업에 대한 하나의 시스템에서 다른 시스템으로의 메세지 미래에 발생할 사건의 트리거가 된다. 메시징을 사용하는 이유 REST API는 클라이언트가 요청하는 시점에 서버가 항상 가용해야 하는 문제가 있다. REST와 같은 동기 IPC (Inter Process Communication) 문제점을 해결하고자 비동기 메시징을 사용한다. 메시지 브로커가 가용하다면 consumer의 장애 시점에도 producer가 발행한 메시지는 메시지 브로커에 적재되며, consumer가 장애에서 복구되면 메시지를 소비할 수 있다. Transactional Outbox Pattern 메시징을 통해 데이터를 처리할 때 데이터의 일관성을 처리하기 위해 사용한다. producer 역할을 하는 서비스에서 발생한 도메인 이벤트/메시지는 적어도 한번(at least once) 발행해야 한다. 방법 producer 역할을 하는 서비스에 OUTBOX 테이블을 생성하고, 도메인 이벤트/메시지를 트랜잭션 범위안에서 OUTBOX 테이블에 insert한다. 별도의 MessageRelay가 주기적으로 OUTBOX 테이블에 있는 메세지를 발행한다. MessageRelay는 polling publisher로 구현할 수 있다. 데이터베이스 트랜잭션이 커밋된 경우에만 MessageRelay를 통해서 메시지를 발행한다. MessageRelay를 통하기 때문에 메세지 발행에 시차는 생기지만, Eventual Consistency를 유지한다. 멱등 수신자 (Idempotent Receiver) consumer 역할을 하는 서비스는 동일한 메시지를 중복으로 여러번 수신할 수 있으므로, 중복 메시지로 인한 사이드 이펙트가 발생하지 않도록 멱등 수신자를 구현해야 한다. 방법 PROCESSED_MESSAGE 테이블을 추가한다. 메세지를 수신하면 식별자를 이용해서 테이블에서 조회한다. 테이블에서 조회된다면 메세지를 무시한다. 조회되지 않는 메세지면 PROCESSED_MESSAGE에 저장하고 처리한다. (메세지 식별자에 unique 제약조건을 걸어서 구분할 수도 있다.) Kafka 코드 application.yml\nspring: cloud: stream: kafka: binder: headers: [\u0026#34;messageId\u0026#34;, \u0026#34;messageType\u0026#34;, \u0026#34;messageVersion\u0026#34;, \u0026#34;messageSource\u0026#34;] auto-create-topics: false # Kafka - SASL_SSL설정과 SCRAM-SHA-512 를 이용한 ID Password 설정 # @see https://wiki.mm.meshkorea.net/pages/viewpage.action?pageId=95856174 configuration: sasl: jaas: config: \u0026#39;org.apache.kafka.common.security.plain.PlainLoginModule required username=\u0026#34;alice\u0026#34; password=\u0026#34;alice-secret\u0026#34;;\u0026#39; mechanism: PLAIN security: protocol: SASL_PLAINTEXT bindings: messageChannel: binder: kafka destination: local-msabootcamp-output producer: # @see https://docs.spring.io/spring-cloud-stream-binder-kafka/docs/3.0.10.RELEASE/reference/html/spring-cloud-stream-binder-kafka.html#kafka-producer-properties header-mode: headers partition-key-expression: headers[\u0026#39;partitionKey\u0026#39;] partition-count: 1 subscribableChannel: binder: kafka destination: local-msabootcamp-output content-type: application/json consumer: header-mode: embeddedHeaders checkpointMode: record default-binder: kafka spring.cloud.stream.kafka.binder 를 이용해서 KafkaBinderConfigurationProperties.class 의 값을 세팅 PersistentEventCreator.class\npublic class PersistentEventCreator { private final PersistentEventRepository repository; private final ObjectMapper objectMapper; @Transactional public void create(String eventType, Object source) { String body = \u0026#34;\u0026#34;; try { body = objectMapper.writeValueAsString(source); } catch (IOException e) { log.error(\u0026#34;Serialization failed\u0026#34;, e); } final PersistentEvent entity = PersistentEvent.newInstance(eventType, UUID.randomUUID(), body); repository.save(entity); } } PersistentEventPublisher.class - publish()\n@Transactional @Scheduled(fixedDelayString = \u0026#34;PT50S\u0026#34;, initialDelayString = \u0026#34;PT10S\u0026#34;) @SchedulerLock(name = \u0026#34;PersistentEventPublisher\u0026#34;) @Async public void publish() { final Instant timeScope = Instant.now(Clock.system(ZONE_ID)).minus(1, ChronoUnit.MINUTES); List\u0026lt;PersistentEvent\u0026gt; candidates = repository.findUnproducedByTimeScope(timeScope); // OUTBOX 조회 if (candidates.isEmpty()) { return; } writeLog(\u0026#34;started\u0026#34;, kv(\u0026#34;total\u0026#34;, candidates.size())); int success = 0; for (PersistentEvent candidate : candidates) { try { boolean produced = producer.produce(candidate); // produce if (produced) { candidate.markProduced(); success++; writeLog(\u0026#34;handling\u0026#34;, kv(\u0026#34;persistentEventId\u0026#34;, candidate.getId()), kv(\u0026#34;eventType\u0026#34;, candidate.getEventType()), kv(\u0026#34;eventId\u0026#34;, candidate.getEventId()) ); } else { throw new RuntimeException(\u0026#34;Message was not produced\u0026#34;); } } catch (Exception e) { candidate.markFailed(); reportError(e, kv(\u0026#34;persistentEventId\u0026#34;, candidate.getId())); } } writeLog(\u0026#34;success\u0026#34;, kv(\u0026#34;success\u0026#34;, success), kv(\u0026#34;total\u0026#34;, candidates.size())); } MessageProducer.class\npublic class MessageProducer { private final MessageChannel messageChannel; public boolean produce(PersistentEvent persistentEvent) { final String body = persistentEvent.getBody(); Message\u0026lt;?\u0026gt; message = MessageBuilder .withPayload(body) .setHeader(MessageKey.ID, persistentEvent.getEventId()) .setHeader(MessageKey.TYPE, persistentEvent.getEventType()) .setHeader(MessageKey.VERSION, 1) .setHeader(MessageKey.SOURCE, PROJECT_NAME) .setHeader(MessageKey.RESOURCE, body.getClass().getSimpleName()) .setHeader(MessageKey.PARTITION_KEY, persistentEvent.getPartitionKey()) .build(); log.debug(\u0026#34;Event publish: {}\u0026#34;, message); return messageChannel.send(message, MessagePolicy.DEFAULT_TIMEOUT); } } MessageSubscriber.class\npublic class MessageSubscriber { private final ReceivedEventRepository receivedEventRepository; @StreamListener(value = ConsumerChannel.CHANNEL) public void subscribe(Message\u0026lt;Album\u0026gt; event) { UUID messageId = event.getHeaders().getId(); Optional\u0026lt;ReceivedEvent\u0026gt; receivedEvent = receivedEventRepository.findByMessageId(messageId); if (receivedEvent.isPresent()) { log.info(\u0026#34;Duplicated event: {}\u0026#34;, receivedEvent.get().getMessageId()); return; } receivedEventRepository.save(new ReceivedEvent(event.getHeaders().getId())); log.debug(\u0026#34;Event received: {}\u0026#34;, event.getPayload()); } } 전체 흐름 6. CI/CD CI/CD란 CI (Continuous Integration): 애플리케이션의 소스 변경 사항이 지속적으로 빌드 및 테스트되어 공유 리포지토리에 통합되는 것이다. CD (Continuous Delivery/Deployment): 변경 사항을 테스트 또는 프로덕션 환경에 지속적으로 배포하는 것이다. Jenkinsfile jenkins는 CI 도구이다.\n빌드 → 테스트 → 코드 분석 → 도커 이미지 빌드 → helm chart 빌드 위 과정을 파이프라인으로 자동화 해준다. 파이프라인은 Job들을 순차적 또는 병렬적으로 실행시키거나 작성한 스크립드로 이벤트를 연속적으로 실행시키는 것이다.\n@Library(\u0026#39;meshkorea\u0026#39;) _ vroongNeoMsaJavaPipeline( team: \u0026#39;\u0026#39;, ecrRepoName: \u0026#39;vroong/msabootcamp\u0026#39;, argoAppName: \u0026#39;vroong-msabootcamp\u0026#39;, gradleBuildArguments: \u0026#39;\u0026#39; ) team: 슬랙 {team}-build-alerts 채널에 관련 alert를 발생시킨다. ecrRepoName: Jenkins에서 도커 빌드 후 push할 ECR 이름 argoAppName: argoCD 앱 이름 gradleBuildArguments: jar 파일 빌드시 뒤에 추가할 argument Jenkins 파이프라인 적용 방법\n리포지토리 root에 Jenkinsfile이 있어야만 파이프라인이 실행된다. github push, PR, merge 와 같은 이벤트 발생시 파이프라인이 구동된다. 도커 이미지 tag는 파이프라인에 도커 빌드 과정에서 {tag}-{commit hash} 형태로 빌드 후 ECR에 push된다. tag가 example이고, commit hash가 2d48cj3a인 경우 도커 이미지 tag는 example-2d48cj3a이다. Helm values Helm은 K8S 패키지 관리를 도와주는 패키지 매니저이다. ex) dev와 qa, prod 환경의 DB 주소가 다르다면 이를 관리해 주는 것이다. vroong-{appname}-helm-values 리포지토리 에 필요한 환경 변수 추가 위 리포지토리를 보면 다음과 같은 구조가 있다. dev1 prod qa1 ~ 4 values.yaml argoCD에서 helm values를 배포하면 K8S 서비스, deployment(replica set, pod), 서비스 account, config map 등의 리소스를 만들어준다. values.yaml 모든 환경에 동일하게 적용되어야 하는 내용이 선언되어 있다. 각 환경 별로 values.yaml 파일이 또 있다. 각 환경 별로 바인딩 되어야 하는 환경 변수를 선언한다. override하고 싶은 내용을 선언한다. 빌드 및 배포 과정 Start Init 저장소 checkout 후, commit hash를 구한다. 슬랙에 파이프라인 구동 메세지를 보낸다. Jenkinsfile에 작성한 값을 읽어낸다. Check the docker image ECR에 같은 tag를 가진 이미지가 있는지 확인한다. Gradle build nexus에 접근하기 위한 계정 정보를 복사한다. jar 파일을 빌드한다. code review / unit test sonarqube로 코드 리뷰를 하고 unit 테스트를 수행한다. Docker / ECR login 도커 이미지를 빌드하고 tag를 붙인다. ECR에 login한다. ECR push ECR에 도커 이미지를 push한다. ArgoCD trigger argoCD에 login한다. 슬랙에 빌드 완료 메세지를 보낸다. End Jenkins 과정을 거친 후 APP DIFF 버튼을 눌러, helm values 변경 사항을 확인한다.\n변경 사항에 이상이 없으면 SYNC 버튼을 누른다.\npod가 잘 교체 되는지 확인한다.\nk9s /{서비스 이름으로 검색} 상단 Context에서 현재 환경을 확인할 수 있다. 새로운 pod가 실행된 후 완료되면 기존 pod를 교체한다. 모니터링한다.\n7. UAA User Account and Authentication\nMSA Resource 서버를 보호하기 위한 Authorization Server\nOAuth2 (Open Authorization) 방식\nAuthorization Code Grant Type Resource Owner Password Grant type Client Credentials Grant Type Client Credentials Grant Type Flow https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2\u0026amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FAGn3b%2FbtqVyURyeZN%2F77J24Xr2Y3aAIZyLUsQZg1%2Fimg.png\nsecurity: oauth2: client: access-token-uri: http://localhost:9999/oauth/token user-authorization-uri: http://localhost:9999/oauth/token client-id: internal client-secret: internal scope: web-app grant-type: client_credentials authorized-grant-type: password, client_credentials, refresh_token resource: jwt.key-uri: http://localhost:9999/oauth/token_key ","permalink":"https://jo-minjun.github.io/notes/msa-stack-quick-peek/","summary":"1. 요구사항 아주 간단한 웹 기반 ITunes 주요 데이터는 다음과 같다. 가수 (Singer) 이름 정보를 가진다. 앨범 (Album) 발매 날짜, 앨범 제목 정보를 가진다. 노래 (Song) 노래 제목과 재생 시간 정보를 가진다. 공통 데이터 생성 시간 업데이트 시간 생성한 사람 업데이트한 사람 주요 기능 가수를 등록할 수 있다. 앨범을 등록할 수 있다. 노래를 등록할 수 있다. 노래 목록들을 조회할 수 있다. 노래를 조회할 수 있다. 노래를 업데이트 할 수 있다. 노래를 삭제할 수 있다.","title":"MSA 개발 스택 빠르게 훑어보기"},{"content":"1. MAC, IP, Port 번호의 식별 MAC, IP, Port는 각 다음과 같은 레이어의 식별자이다. * DoD로 구분한 Layer * user mode ============================================ - Application kernel mode ============================================ - Transport: PORT - Network: IP H/W ============================================ - Access: MAC Transport\nPort가 식별자가 된다. Network\nHost에 대해서 IP가 식별자가 된다. Host: 네트워크에 연결된 컴퓨터, NIC 하나에 IP 주소를 여러 개 바인딩 할 수 있다.\n→ Host에 IP가 여러개 존재한다. Access\nNetwork Interface Card에 대해서 MAC이 식별자가 된다. 하드웨어 식별자지만, MAC 변경이 가능하다. Network Interface Card: 노트북은 유선/무선 랜카드가 2개 → NIC가 2개 2. Host, Switch, Network의 관계 Host는 Network에 연결된 컴퓨터이다.\nNetwork는 다음과 같이 두 가지로 나뉜다.\nNetwork 이용 주체 → End-Point가 된다. (Peer, Server, Client 등) Network 자체 → 이 Computer를 Switch라 한다. (Firewall, Router 등) Network는 Router(L3 Switch)와 DNS의 집합체이다.\n(스위칭 비용 증가) user mode ============================================ L7 -------------------------------------------- L6 -------------------------------------------- L5 -------------------------------------------- kernel mode ============================================ L4 - TCP -------------------------------------------- L3 (Router) - IP -------------------------------------------- H/W ============================================ L2 -------------------------------------------- L1 -------------------------------------------- (스위칭 비용 감소) 3. IPv4 주소 체계 IP 주소 Host에 대한 식별자\nIP 주소는 다음과 같이 두가지 표현 방법이 있다.\nIPv4: 32bit IPv6: 128bit IPv4의 32bit는 다음과 같이 이루어져 있다.\n32bit는 8bit씩 나누어 표기한다. 121.123.223.10 크게 두 부분으로 나뉜다. Net ID, Host ID Net ID Host ID ----------- -- 121.123.223.10 이때 Net ID의 길이를 구분하기 위해 서브넷 마스크를 사용한다. 서브넷 마스크 서브넷 마스크도 32bit로, 8bit씩 나누어 표기한다.\n서브넷 마스크와 IP 주소를 and 연산하면 Net ID를 확인할 수 있다.\n하지만 일반적으로 다음과 같이 Net ID의 길이를 함께 표기한다.\n121.123.223.10/24 → 121.123.223.0은 Net ID, Host는 10이다.\n이 표기하는 것을 CIDR라 한다. 4. Port 번호의 이해 Port는 관점에 따라 여러 의미를 가진다.\nProcess 식별자 Service 식별자 Interface 번호 여기서는 개발자 관점에서 Process 식별자를 알아본다.\nuser mode ============================================ - Process kernel mode ============================================ - TCP - IP - Driver H/W ============================================ - NIC kernel mode는 user mode가 접근이 가능하게 하기 위해 file이라는 인터페이스를 제공한다. 하지만 이를 프로토콜 관점에서 추상화하면 socket이 된다. 이때 socket에 attach되는 정보 중 하나가 Port 번호이다. Port는 다음과 같은 특징이 있다.\nsocket에 attach되는 정보이다. 16bit 정보이다. → 2^16\n→ Port 번호의 범위는 0 ~ 61535 이다. (하지만 0과 61535는 사용할 수 없다.)\n패킷이 하위 레이어에서 상위 레이어로 올라갈 때 Port를 이용해서 프로세스를 식별한다. 5. Switch, Switching Switching은 경로 또는 인터페이스를 선택하는 것이다.\n이 때 선택지가 나오는 곳을 Switch라 한다.\nNetwork는 라우터와 DNS의 집합이다.\n라우터는 L3 스위치이다. 라우터는 라우팅 테이블을 근거로 최적의 경로를 찾아낸다. 6. 네트워크 데이터 단위 user mode ============================================ - Application (Socket 수준) kernel mode ============================================ - TCP - IP H/W ============================================ - 위에서 설명한 user와 kernel 모드 사이의 file(socket)은 Stream이다. 기본적으로 file은 사용자가 계속 데이터를 입력하면 계속해서 데이터가 커진다. TCP에서 다루는 데이터 단위: Segment IP에서 다루는 데이터 단위: Packet IP 아래 단계에서 다루는 데이터 단위: Frame 이 데이터 단위의 흐름은 다음과 같다.\nStream이 Segment로 넘어갈 때 일정한 길이로 데이터를 분해한다. 이때 **Segment의 최대 크기를 Maximum Segment Size(MSS)**라 한다. MSS는 Packet의 최대 크기으로 결정하게 되는데, Packet의 최대 크기를 (Maximum Transport Unit)MTU라 한다. 이 Packet을 Frame 데이터로 캡슐화하여 전달한다. 7. 네트워크 인터페이스 선택 원리와 기준 user mode ============================================ - HTTP (L7) - - SSL kernel mode ============================================ - TCP, UDP (L4) - IP (L3) H/W ============================================ - Ethernet - 아래와 같은 상황에서 인터페이스는 어떻게 선택될까?\n사용자가 브라우저를 켰다. (Socket이 열리고, TCP와 IP가 바인딩 되어야 한다.) KT 유선 인터넷과 SKT 무선 인터넷을 두 개 연결했다. (일반적으로 IP 주소는 2개가 된다.) → 메트릭(쉽게 말해 비용) 값으로 결정한다.\n→ 따라서 위 경우에는 KT 유선과 SKT 무선 중 메트랙 값이 적은 쪽으로 바인딩 된다.\n8. 웹 서비스를 만드신 분에 대해 웹 탄생 배경 영국 물리학 연구원 팀 버너스 리 연구원은 논문을 많이 읽는다. 논문에는 항상 참고문헌이 많았다. 하지만 당시 링크 개념이 존재하지 않았고 문서는 모두 Text 파일이었다. → 문서(Text) + Link 를 이용해서 HTML이라는 문서 형식을 만들었다.\n→ HTML의 인터넷 전달 방법을 위해서 HTTP라는 프로토콜을 만들었다.\n→ 여러 문서들이 계속해서 연결되니, Web이 형성되었다.\n→ 이는 웹 서비스가 되었고, 팀 버너스 리가 창안했다.\n9. 초창기 웹 서비스의 구조 **웹 클라이언트 (브라우저)**는 인터넷을 통해서 웹 서버와 연결된다.\n이때 연결은 HTTP라는 TCP/IP 기반으로 된다.\nHTTP는 Stateless하다. 웹 클라이언트의 IP 주소가 있고 웹 서버에도 IP 주소가 있다.\n→ 이 주소 URL을 알고 리소스(HTML 문서)에 대한 요청을 하면 연결이 되고, 응답을 준다.\n→ 응답을 받은 클라이언트는 HTML 구문 분석을 하고, 내용을 렌더링 한다.\n즉, 이 당시 브라우저는 원격 문서 뷰어 역할(단방향 작용)을 했다.\n10. 웹 서비스 3대 요소 위 구조에는 문제가 있었다.\n문서의 내용과는 별개로 UI를 개선하고 싶었다.\n→ HTML에 기능을 추가하니 유지보수가 불편하다.\n→ CSS와 이미지가 나왔다.\n→ 요청하면 HTML + CSS + IMAGE(서버에 저장되어 있다.)가 순서대로 응답된다.\n문서를 변경해야 했다.\n→ 문서를 변경하기 위해 처리를 담당하는 서버가 생겼다.\n→ 단방향 작용이 양방향 상호 작용이 되면서 상태를 처리해야 했다.\n→ DB를 이용해서 처리하게 되었다.\n문서가 변경되고, 처리가 되니 문서가 복잡해졌다.\n→ 기능에 따라 동적인 움직임을 주는 것이 필요해졌다.\n→ 브라우저에서 렌더링 후에 연산하는 기능을 가지게 되었다. (Javascript)\n즉, 웹 서비스 3대 요소는 다음과 같다.\nHTML 구문 분석 렌더링 연산 11. LAN vs WAN 주의) 이 내용은 명확한 구분은 아니다. user mode ============================================ - HTTP - - SSL kernel mode (Logical == virtual) ============================================ - TCP, UDP - IP(IP 주소) --\u0026gt; [Internet] == [virtual network] -\u0026gt; *WAN H/W (Physical) ============================================ - Ethernet(MAC 주소) --\u0026gt; *LAN - LAN과 WAN은 흔히 범위의 차이로 구분한다.\n하지만 논리/물리적 구성요소로 구분하는 방법은 아래와 같다.\n시스템은 S/W와 H/W로 구분된다. S/W(kernel mode 이상)은 IP(Internet Protocol) 를 이용해서 통신한다. Internet은 virtual network이다. → WAN H/W는 MAC 주소를 이용한다. (이는 물리적인 주소이다.) → 하드웨어로 설명되는 네트워크 → LAN 12. 패킷의 생성 원리와 캡슐화 user mode ============================================ - HTTP - - SSL kernel mode ============================================ - TCP, UDP - IP H/W ============================================ - Ethernet - user mode 영역은 socket에 데이터를 IO한다. socket은 file을 추상화한 것이다. 때문에 데이터를 계속해서 쓰기할 수 있다. 이때 데이터의 단위는 Stream이다. user mode의 Stream이 Kernel mode에서 일정 단위로 나누어진다. 이때 데이터의 단위는 Segment이다. 이 Segment가 한 번 캡슐화되어 Packet이 된다. Packet의 최대 크기: MTU(Maximum Transport Unit) 일반적으로 1500이다. Packet의 구조: Header, Payload Header에는 IP(L3)와 TCP(L4) 데이터가 있다. 이때 크기는 일반적으로 각 20씩으로 총 40이다. MTU 크기 - Header 크기 = 1460이다. 이 크기가 MSS(Maximum Segment Size) 이다. Stream을 1460 크기로 나눈 것이다. H/W영역에서 Packet이 한 번 더 캡슐화된다. Frame이 된다. 13. L2 스위치 L2 스위치는 MAC 주소(48bit)로 스위칭시킨다.\n(multilayer switch) NIC L2 Access L2 Distribution L2 Access NIC | (Up-link) (Up-link) |---------------#---------------| PC1------| | |---------PC3 | | | | | | | | |---------PC4 PC2------| | | | | | | | (Up-link) | (gateway) @ 라우터 | (방화벽) L2 Access: End-Point가 네트워크에서 가장 처음 만나는 스위치 L2 Distribution: L2 Access와 L3 라우터를 연결해주는 스위치 Up-link: 상위 계층 스위치로 연결되는 케이블 14. IP Header 위에서 언급한 것처럼 IP의 헤더는 20바이트이다. (+ @ Opitonal)\n최상단 우측에 Total Length는 16비트인데, 이것은 패킷의 최대 크기를 나타낸다.\n따라서 패킷의 최대 크기는 2^16정도인 65536이다. Identification ~ Fragment Offset은 단편화에 관련된 부분이다.\n단편화는 큰 패킷을 작은 패킷으로 나눈 것을 말한다. MTU가 1400인 곳에 1500짜리 패킷을 보내는 경우 단편화가 일어난다. TTL은 패킷이 라우터 하나를 지날때마다 1씩 감소하고 0이 되면 패킷이 사라진다.\n일반적으로 값은 256이다. (2^8) Protocol은 상위 계층 프로토콜이다.\n이 값을 보고 데이터가 TCP인지 UDP 인지 다른 값인지 확인할 수 있다. Header checksum은 전송간에 오류가 있는지 확인한다.\n15. Proxy 구조와 원리 Proxy는 대리자 역할을 한다.\n\u0026lt;Proxy 미적용\u0026gt;\nHTTPS TCP/IP PC1 (1.1.1.1)--------------Internet--------------------SERVER(9.9.9.9) \u0026lt;Proxy 적용\u0026gt;\nPC1 (1.1.1.1) SERVER(9.9.9.9) | | | | Internet | | | | (Proxy) | PC2 (2.2.2.2)---------------- Internet---------------------| \u0026lt;PC2의 역할\u0026gt;\nuser mode | PC2 ============================================ - HTTP | Proxy 역할을 하는 - | Process - SSL | (Stream) | socket1 socket2 kernel mode | ============================================ - TCP, UDP | - IP | | H/W | ============================================ - Ethernet | - | socket1은 외부에서 접속하길 대기하고 있다. PC1이 접근 정보가 들어오면 socket2를 이용해서 9.9.9.9에 접근 16. Proxy의 활용 1. 우회 Proxy를 사용하면 SERVER 입장에서 PC2의 아이피를 확인한다.\n그러나 PC2는 PC1의 모든 통신을 감청할 수 있다.\n2. 분석 웹 통신에 SSL을 적용하면 패킷 레벨에서 데이터가 암호화되어 있다.\n때문에 와이어 샤크등 프로그램에서 복호화된 데이터를 확인할 수 없다.\n이때 프록시를 아래와 같이 사용할 수 있다.\nProxy를 127.0.0.1:8080으로 건다. (내 PC) HTTP 요청을 보내면 8080번 포트의 소켓으로 데이터가 지나간다. 이 평문 데이터를 Stream 레벨에서 확인한다. 17. TCP 송신/수신 원리 Stream을 Segment로 나눈다. 이때 TCP Buffer(Window Size)에 데이터를 저장하고, 일정 크기가 되면 Segment로 나눈다. Segment를 Packet으로 캡슐화한다. Packet을 Frame으로 캡슐화한다. Frame을 전달한다. 전체를 보내는 것은 아니다. (n개 만큼 보낸다.) 일반적으로 Frame은 바뀔 수 있다. (Packet은 그대로 이지만) Frame을 전달받고 Segment로 만든다. n개의 Segment를 받으면 TCP Buffer에 저장하고 ackn+1을 송신쪽에 전달한다. ack에는 Window Size가 포함되어 있다. 송신쪽은 ackn+1을 받고 Segment를 n+1번부터 다시 보낸다. 이 과정때문에 속도 지연이 발생한다. (UDP 보다 느리다.) 만약 ack로 받은 수신 측 Window Size가 작으면 Segment를 보내지 않는다. 18. TCP 연결에 대해 TCP는 연결지향 프로토콜이다.\n우선 아래 TCP 헤더를 보자\n출발지/목적지 Port 번호가 가장위에 위치한다. Sequence Number: 32bit → 4GB (2^32), Segment의 순서 TCP Flags: Ack, Sync 3-way handshake에 사용 3-way handshake\nSeq번호와 MSS를 교환하는 행위 혼잡 제어 정책 교환 19. Unicast, Broadcast, Multicast NIC L2 Access L2 Distribution L2 Access NIC | (Up-link) (Up-link) |---------------#---------------| PC1------| | |---------PC3 | | | | | | | | |---------PC4 PC2------| | | | | | | | (Up-link) | @ 라우터 (gateway) (방화벽) Unicast\nL2 스위치 내부에서 연결이 끝나는 것 (라우터 이전) 한번에 한 지점에게만 신호를 보낸다. Broadcast\n어떤 지점에서 다수의 지점에 신호를 보내는 것 네트워크 효율을 떨어뜨린다. 2진수 IP의 끝자리가 모두 1이다. (210.153.0.255) Multicast\nBroadcast와 유사하나 관심이 없는 지점은 신호를 보내지 않음 Group을 등록해서 Group에 전달함 20. IP의 종류 Global\n인터넷(public, global network)에서 라우터가 라우팅 시켜주는 IP이다. Private\n작은 소규모 사설 인터넷을 구축할 때 사용한다. 공유기에서도 자주 사용한다. 공유기는 하나의 Global IP를 Private IP에 공유해주는 역할을 한다. 4개의 클래스로 나뉜다. A: network id: 8bit host id: 24bit 10.xxx.xxx.xxx B network id: 12bit host id: 20bit 172.16.xxx.xxx C network id: 16bit host id: 16bit 192.168.xxx.xxx D multicast를 할 때 사용한다. Loopback\n127.0.0.1 호스트 자신을 의미한다. 패킷이 만들어지지만 L2로 가지는 않는다. Broadcast\n다수의 지점에 신호를 보낼 때 사용한다. 21. DNS Domain Name\n숫자로된 IP를 사람이 보기 편하도록 해준다. naver.com google.com DNS\nIP와 Domain Name을 연결하는 테이블 역할 DNS는 계층적 구조로 되어 있다. (분산형 DB 구조) 가장 상위 DNS인 root DNS는 전세계에 13대가 있다. Domain Name으로 IP를 찾는 과정\n컴퓨터 캐시에서 검색 host file에서 검색 DNS에서 검색 root DNS에서 .com, co.kr 등을 관리하는 DNS 목록을 검색 DNS 목록에서 검색 … 22. TCP/IP 통신과 MAC 주소 TCP/IP 통신을 할 때의 MAC 주소의 변화\n패킷이 프레임으로 캡슐화된다. 프레임 헤더에도 시작/목적 지점이 있다. L2 구간(라우터)을 지나면 프레임 헤더가 새로 교체된다. L2구간에 새로 접근할 때마다 프레임 헤더의 시작/목적 지점도 계속해서 변경된다. MAC 주소만 고려하고, IP 주소는 고려하지 않는다. 23. MTU와 Packet 단편화 위 그림에서 2번째 줄(Identification, Fragment Offset)이 단편화 관련 부분이다. MTU는 1500이 기본값인 경우가 많다. MTU - 20(IP 헤더) - 20(TCP 헤더) = MSS이다. 아래와 같은 경우에는 단편화가 어떻게 이루어 질까?\nMTU:1500 MTU:1500 MTU:1400 MTU:1500 MTU:1500 PC1 ---|---#-----R1-------------R2-------------R3-----SERVER 위 경우 R1 → R2에서 단편화가 이루어져야 한다. 1500짜리 패킷을 어느 지점에서 자른다. A와 B가 생긴다. 헤더와 A를 붙이고, 헤더와 B를 붙여서 2개의 패킷을 만든다. 이때 두 패킷 헤더의 Idenfication이 같은 값이 된다. Fragment Offset 값은 A는 0, B는 A의 길이만큼이 된다. 수신하는 쪽에서 단편화를 조립한다. (SERVER) 24. 서브넷팅 ISP(Internet Service Provider)에게 어떤 회사가 100개의 사설 IP를 요청하면 어떻게 될까?\nC레벨(Net ID: 24, Host ID: 8)인 private IP를 할당한다. 그런데 C레벨 private IP를 할당하면 2^8 - 100 = 146개의 IP를 낭비하게 되는 것이다. 이런 경우 서브넷팅을 사용할 수 있다. 서브넷팅은 Net ID에 몇 개의 비트를 더 할당하는 것이다.\n192.168.0.1/25라면 마지막 4번째 자리의 1의 가장 앞부분 비트를 Net ID로 할당 시킨다. (192.168.0.0)0000001 (192.168.0.1)0000001 하지만 Host ID가 0인 경우는 아무것도 가리키지 않고, 2진수에서 모두 1인 경우는 broadcast IP 이므로 서브넷 하나마다 2개의 IP를 손실보게 된다. 예를 들어 이 경우라면 192.168.0.1/25 192.168.0.00000000, 192.168.0.01111111 192.168.0.10000000, 192.168.0.11111111 위 4가지 IP를 손실보게 된다. Reference https://www.youtube.com/watch?v=k1gyh9BlOT8\u0026amp;list=PLXvgR_grOs1BFH-TuqFsfHqbh-gpMbFoy ","permalink":"https://jo-minjun.github.io/notes/networkbasic/","summary":"1. MAC, IP, Port 번호의 식별 MAC, IP, Port는 각 다음과 같은 레이어의 식별자이다. * DoD로 구분한 Layer * user mode ============================================ - Application kernel mode ============================================ - Transport: PORT - Network: IP H/W ============================================ - Access: MAC Transport\nPort가 식별자가 된다. Network\nHost에 대해서 IP가 식별자가 된다. Host: 네트워크에 연결된 컴퓨터, NIC 하나에 IP 주소를 여러 개 바인딩 할 수 있다.\n→ Host에 IP가 여러개 존재한다. Access\nNetwork Interface Card에 대해서 MAC이 식별자가 된다.","title":"네트워크 기초 지식"},{"content":"1. Avro 란? 아브로(Avro)는 아파치의 하둡 프로젝트에서 개발된 RPC 및 데이터 직렬화 프레임워크이다.\nschema를 json으로 정의하여 바이너리 포맷으로 직렬화 한다.\n2. 장점 데이터의 타입을 알 수 있다. 스키마가 직렬화되어 네트워크 통신에 자유롭다. 스키마에 설명이 포함되어 schema 구조를 이해하는데 도움을 준다. 다양한 language를 지원한다. (java, c, c++ 등) default 값을 정의할 수 있다. 3. Data Type 이름 태그 null no value boolean a binary value int 32bit signed integer long 62bit signed integer float single precision(단정밀도) 32bit floating-point number double double percision(배정밀도) 64bit floating-point number bytes sequence of 8-bit unsigned bytes string unicode character sequence Enums name, namespace, aliases, doc, symbols, default 등을 가진다.\n{ \u0026#34;type\u0026#34;: \u0026#34;enum\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Suit\u0026#34;, \u0026#34;symbols\u0026#34;: [\u0026#34;SPADES\u0026#34;, \u0026#34;HEARTS\u0026#34;, \u0026#34;DIAMONDS\u0026#34;, \u0026#34;CLUBS\u0026#34;] } Arrays items를 가진다.\n{ \u0026#34;type\u0026#34;: \u0026#34;array\u0026#34;, \u0026#34;items\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;default\u0026#34;: [] } Maps values를 가진다.\n{ \u0026#34;type\u0026#34;: \u0026#34;map\u0026#34;, \u0026#34;values\u0026#34;: \u0026#34;long\u0026#34;, \u0026#34;default\u0026#34;: {} } Unions string, int, boolean 등과 같은 여러개의 서로 다른 타입을 가짐으로써 선택적인 값을 저장할 수 있도록 한다.\n4. Schema 필드 이름 태그 name json을 지원하는 스키마의 이름 namespace name을 구별하는 패키지 doc 스키마를 설명하는 doc aliases name의 별칭 fields name, doc, type, default, order, aliases 등을 가지는 json type object 5. Avro Schema 예시 { \u0026#34;type\u0026#34;: \u0026#34;record\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;LongList\u0026#34;, \u0026#34;aliases\u0026#34;: [\u0026#34;LinkedLongs\u0026#34;], // old name for this \u0026#34;fields\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;value\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, // each element has a long { \u0026#34;name\u0026#34;: \u0026#34;next\u0026#34;, \u0026#34;type\u0026#34;: [\u0026#34;null\u0026#34;, \u0026#34;LongList\u0026#34;] } // optional next element ] } { \u0026#34;type\u0026#34; : \u0026#34;record\u0026#34;, \u0026#34;namespace\u0026#34; : \u0026#34;tutorialspoint\u0026#34;, \u0026#34;name\u0026#34; : \u0026#34;empdetails \u0026#34;, \u0026#34;fields\u0026#34; : [ { \u0026#34;name\u0026#34; : \u0026#34;experience\u0026#34;, \u0026#34;type\u0026#34;: [\u0026#34;int\u0026#34;, \u0026#34;null\u0026#34;] }, { \u0026#34;name\u0026#34; : \u0026#34;age\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;int\u0026#34; } {\u0026#34;name\u0026#34;: \u0026#34;additional\u0026#34;, \u0026#34;type\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;map\u0026#34;, \u0026#34;values\u0026#34;: \u0026#34;string\u0026#34;}} ] } ","permalink":"https://jo-minjun.github.io/notes/avro-schema/","summary":"1. Avro 란? 아브로(Avro)는 아파치의 하둡 프로젝트에서 개발된 RPC 및 데이터 직렬화 프레임워크이다.\nschema를 json으로 정의하여 바이너리 포맷으로 직렬화 한다.\n2. 장점 데이터의 타입을 알 수 있다. 스키마가 직렬화되어 네트워크 통신에 자유롭다. 스키마에 설명이 포함되어 schema 구조를 이해하는데 도움을 준다. 다양한 language를 지원한다. (java, c, c++ 등) default 값을 정의할 수 있다. 3. Data Type 이름 태그 null no value boolean a binary value int 32bit signed integer long 62bit signed integer float single precision(단정밀도) 32bit floating-point number double double percision(배정밀도) 64bit floating-point number bytes sequence of 8-bit unsigned bytes string unicode character sequence Enums name, namespace, aliases, doc, symbols, default 등을 가진다.","title":"Avro schema"},{"content":"1. Schema registry 란? 데이터 관리의 중요한 관점들 중 하나는 schema의 버전 관리이다. 응용프로그램의 시간이 지날수록 schema가 정의되기 시작한 시점부터 schema는 점점 바뀌어가고, producer와 consumer는 직접적인 관계가 끊어져있기 때문에 운영상에 발생하는 이슈가 있다.\nproducer는 consumer가 어떤 메세지를 소비할지 알 수 없다.\nconsumer는 producer가 어떤 메세지를 생산했는지 알 수 없다.\n위와 같은 상황에서 producer가 갑자기 다른 schema를 이용해서 메세지를 생산할 경우, consumer는 이 메세지에 대해서 대처하지 못할 수 있다.\n이는 구조적인 결합도는 낮지만, 메세지 schema에 대한 의존성이 높기 때문인데, schema registry는 이를 보완하기 위해 고안되었다.\nConfluent Schema registry는 Avro, Json, Protobuf 등의 schema 정보의 history를 subjects를 통해 관리하며, REST API를 통해 compatibility settings을 결정하고 현재 버전과 이전 버전간의 호환성을 지원한다.\nSchema registry는 kafka boroker와 독립적으로 존재하며, producer와 consumer는 kafka broker와 읽고 쓰는 동안 Schema registry와 동작하며 데이터 모델을 확인할 수 있다.\n2. Schemas, Subjects and Topics 란? topic은 kafka의 topic을, schema는 Avro, Json, Protobuf 등으로 정의된 데이터 포맷 구조를 의미한다.\nSubject는 Schema registry에 schema가 등록된 이름이며, 여러 버전의 schema가 등록될 수 있다.\n따라서 Subject를 통해 계속해서 Schema의 정보를 관리할 수 있고, 새로운 버전의 Schema ID와 버전을 확인할 수 있다.\nkafka topic은 메세지가 포함되어 있으며, 각 메세지는 key - value 쌍으로 되어있으며 메세지의 key와 value는 Avro, Json, Protobuf 등으로 직렬화할 수 있다. Schema는 데이터 포맷의 구조를 정의한다. kafka의 topic 이름은 schema의 이름과 의존적이지 않다. Schema의 ID는 전역적이다. 3. Compatibility settings 란? schema compatibility checking는 모든 schema를 버전화해서 schema registry compatibility type에 의해서 구현된다.\n즉, 아래의 schema 전략에 의한 패턴으로 호환성을 유지하게 된다.\nCompatibility type 허가되는 변경 비교하는 schema upgrade 순서 BACKWARD - 필드 삭제- Optional 필드 추가 마지막 버전 Consumers BACKWARD_TRANSITIVE - 필드 삭제- Optional 필드 추가 모든 이전 버전 Consumers FORWARD - 필드 추가- Optional 필드 삭제 마지막 버전 Producers FORWARD_TRANSITIVE - 필드 추가- Optional 필드 삭제 모든 이전 버전 Producers FULL - Optional 필드 추가- Optional 필드 삭제 마지막 버전 Any order FULL_TRANSITIVE - Optional 필드 추가- Optional 필드 삭제 모든 이전 버전 Any order NONE 모든 변경 허용 비교하지 않음 Depends BACKWARD: (default) consumer가 새로운 스키마를 사용하여 producer가 마지막 버전의 스키마로 생성한 메세지를 읽을 수 있다. (새로운 스키마로 이전 스키마 메세지를 읽는다.) (새로운 스키마 필드에 default value가 없으면 오류가 발생한다.) BACKWARD_TRANSITIVE: consumer가 새로운 스키마를 사용하여 producer가 모든 마지막 버전 스키마로 생성한 메세지를 읽을 수 있다. FORWARD: consumer가 마지막 버전의 스키마를 사용하여 producer가 새로운 스키마로 생성한 메세지를 읽을 수 있다. (이전 스키마로 새로운 스키마 데이터를 읽는다.) (새로운 스키마에서 필드가 삭제되면, 이전 스키마에 default value가 있어야 한다.) FORWARD_TRANSITIVE: consumer가 모든 마지막 버전의 스키마를 사용하여 producer가 새로운 스키마로 생성한 메세지를 읽을 수 있다. FULL: BACKWARD 와 FORWARD 를 모두 만족한다. FULL_TRANSITIVE: BACKWARD_TRANSITIVE 와 FORWARD_TRANSITIVE 를 모두 만족한다. NONE: schema compatibility checks are disabled 4. Rest API Interface Reference - Schemas, Subjects Schema Registry REST API 서버는 사용된 API의 버전과 데이터의 직렬화 포맷을 표시하기 위해 요청과 응답에 content type을 사용한다.\n현재는 직렬화 포맷은 JSON만을 지원하고 API의 버전은 v1만 사용할 수 있다. 하지만 나중 버전의 호환을 위해서 반드시 content type을 사용해야한다.\n추천하는 content type은 application/vnd.schemaregistry.v1+json이다. v1은 API의 버전이고, json은 직렬화 포맷이다.\n모든 API endpoint는 다음과 같은 error message 포맷을 사용한다.\nHTTP/1.1 422 Unprocessable Entity Content-Type: application/vnd.schemaregistry.v1+json { \u0026#34;error_code\u0026#34;: 422, \u0026#34;message\u0026#34;: \u0026#34;schema may not be empty\u0026#34; } 추가적으로 요청시 json은 string 형태로 전달해야 한다.\nSchemas 관련 GET /schemas/ids/{int: id} 입력한 id를 이용하여 스키마 정보를 요청한다.\nParameters:\nid (int) - 전역적으로 unique한 스키마 id\nResponse JSON Object: schema (string) - id로 구분한 schema string\nStatus Codes: 404 Not Found - schema not found 500 Internal Server Error - Error in the backend datastore\nExample request:\nGET /schemas/ids/1 HTTP/1.1 Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json { \u0026#34;schema\u0026#34;: \u0026#34;{\\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;}\u0026#34; } GET /schemas/types/ Schema Registry에 저장된 스키마 타입을 요청한다.\nResponse JSON Object: schema (string) - Schema Registry에서 현재 사용가능한 스키마 타입\nStatus Codes: 404 Not Found - schema not found 500 Internal Server Error - Error in the backend datastore\nExample request:\nGET /schemas/types HTTP/1.1 Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json { [\u0026#34;JSON\u0026#34;, \u0026#34;PROTOBUF\u0026#34;, \u0026#34;AVRO\u0026#34;] } GET /schemas/ids/{int: id}/versions Schema Registry에 저장된 스키마 타입을 요청한다.\nParameters:\nid (int) - 전역적으로 unique한 스키마 id\nResponse JSON Object: subject - subject의 이름 version - return된 subject의 버전\nStatus Codes: 404 Not Found - schema not found 500 Internal Server Error - Error in the backend datastore\nExample request:\nGET /schemas/ids/1/versions HTTP/1.1 Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json [{\u0026#34;subject\u0026#34;:\u0026#34;test-subject1\u0026#34;,\u0026#34;version\u0026#34;:1}] Subjects 관련 subject resource는 Schema Registry에 저장된 모든 subject 목록을 제공한다.\nsubject는 스키마가 저장된 이름을 나타낸다.\n만약 Kafka에 Schema Registry를 사용하고 있다면, subject는 topic에 대한 key 또는 value 스키마를 등록하고 있는지에 따라 \u0026lt;topic\u0026gt;-key 또는 \u0026lt;topic\u0026gt;-value를 참조한다.\nGET /subjects Schema Registry에 저장된 subject의 목록을 요청한다.\nParameters:\nsubject (string) - subject의 이름\ndeleted (boolean) - default는 false이다. ?deleted=true로 요청하면 soft delete된 subject 목록을 함께 return 한다.\nResponse JSON Object: name (string) - subject\nStatus Codes: 500 Internal Server Error - Error in the backend datastore\nExample request:\nGET /subjects HTTP/1.1 Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json [\u0026#34;subject1\u0026#34;, \u0026#34;subject2\u0026#34;] GET /subjects/(string: subject)/versions Schema Registry에 저장된 subject의 버전 목록을 요청한다.\nParameters:\nsubject (string) - subject의 이름\nResponse JSON Object: version (int) - subject 아래에 저장된 스키마의 버전\nStatus Codes: 404 Not Found - schema not found 500 Internal Server Error - Error in the backend datastore\nExample request:\nGET /subjects/test/versions HTTP/1.1 Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json [ 1, 2, 3, 4 ] DELETE /subjects/(string: subject) 등록된 특정 subject를 삭제한다. 이 API는 topic을 재사용하거나 개발 환경에서만 사용하는 것이 권장된다.\nParameters:\nsubject (string) - subject의 이름\npermanent (boolean) - ?permanent=true를 추가하여 hard delete를 표시한다.\nResponse JSON Object: version (int) - subject 아래에 저장된 스키마의 버전\nStatus Codes: 404 Not Found - schema not found 500 Internal Server Error - Error in the backend datastore\nExample request:\nDELETE /subjects/test HTTP/1.1 Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json [ 1, 2, 3, 4 ] GET /subjects/(string: subject)/versions/(versionId: version) 등록된 특정 subject를 요청한다.\nParameters:\nsubject (string) - subject의 이름\nversion (versionId) - return될 스키마의 버전이다. [1, 2^31 - 1] 또는 latest가 유효한 값이다.\nResponse JSON Object: subject (string) - subject의 이름 id (int) - 전역적으로 unique한 shema의 id version (int) - subject 아래에 저장된 return될 스키마의 버전 schemaType (string) - schema의 format (default: AVRO) schema (string) - schema의 내용\nStatus Codes: 404 Not Found - schema not found 422 Unprocessable Entity - Invalid version 500 Internal Server Error - Error in the backend datastore\nExample request:\nGET /subjects/test/versions/1 HTTP/1.1 Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json { \u0026#34;name\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;version\u0026#34;: 1, \u0026#34;schema\u0026#34;: \u0026#34;{\\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;}\u0026#34; } GET /subjects/(string: subject)/versions/(versionId: version)/schema 등록된 특정 subject를 요청한다. unescaped schema만 return 된다.?\nParameters:\nsubject (string) - subject의 이름\nversion (versionId) - return될 스키마의 버전이다. [1, 2^31 - 1] 또는 latest가 유효한 값이다.\nResponse JSON Object: schema (string) - schema의 내용\nStatus Codes: 404 Not Found - subject not found or version not found 422 Unprocessable Entity - Invalid version 500 Internal Server Error - Error in the backend datastore\nExample request:\nGET /subjects/test/versions/1/schema HTTP/1.1 Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json {\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;} POST /subjects/(string: subject)/versions 등록된 특정 subject에 새로운 스키마를 등록한다. 만약 성공적으로 등록되면, unique한 스키마의 id가 return 된다. 동일한 스키마가 다른 subject에 등록되면 동일한 id가 return 된다. 그라나 스키마의 버전은 subject에 따라 다를 수 있다.\nParameters:\nsubject (string) - subject의 이름\nnormalize (boolean) - ?normalize=true를 추가하여 normalize 상태를 표시한다.?\nRequest JSON Object: schema (string) - schema의 내용 schemaType - 스키마의 포맷 (default: AVRO) references - 스키마의 이름 지정 (optional)\nResponse JSON Object: subject (string) - subject의 이름 id (int) - 전역적으로 unique한 스키마의 id version (int) - return 되는 스키마의 버전 schema (string) - schema의 내용\nStatus Codes: 409 Conflic - Incompatible schema 422 Unprocessable Entity - Invalid version 500 Internal Server Error - Error in the backend datastore or Operation timed out or Error while forwarding the request to the primary\nExample request:\nPOST /subjects/test/versions HTTP/1.1 Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json { \u0026#34;schema\u0026#34;: \u0026#34;{ \\\u0026#34;type\\\u0026#34;: \\\u0026#34;record\\\u0026#34;, \\\u0026#34;name\\\u0026#34;: \\\u0026#34;test\\\u0026#34;, \\\u0026#34;fields\\\u0026#34;: [ { \\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;, \\\u0026#34;name\\\u0026#34;: \\\u0026#34;field1\\\u0026#34; }, { \\\u0026#34;type\\\u0026#34;: \\\u0026#34;com.acme.Referenced\\\u0026#34;, \\\u0026#34;name\\\u0026#34;: \\\u0026#34;int\\\u0026#34; } ] }\u0026#34;, \u0026#34;schemaType\u0026#34;: \u0026#34;AVRO\u0026#34;, \u0026#34;references\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;com.acme.Referenced\u0026#34;, \u0026#34;subject\u0026#34;: \u0026#34;childSubject\u0026#34;, \u0026#34;version\u0026#34;: 1 } ] } Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json {\u0026#34;id\u0026#34;:1} POST /subjects/(string: subject) 특정 subject에 schema가 이미 등록됐는지 확인한다. 만약 존재하면 전역적으로 unique한 id와 schema를 return 한다.\nParameters:\nsubject (string) - subject의 이름\nnormalize (boolean) - ?normalize=true를 추가하여 normalize 상태를 표시한다.\nRequest JSON Object: schema (string) - schema의 내용 schemaType - 스키마의 포맷 (default: AVRO) references - 스키마의 이름 지정 (optional)\nResponse JSON Object: subject (string) - subject의 이름 id (int) - 전역적으로 unique한 스키마의 id version (int) - return 되는 스키마의 버전 schema (string) - schema의 내용\nStatus Codes: 404 Not Found - Subject not found 500 Internal Server Error - Internal server error\nExample request:\nPOST /subjects/test HTTP/1.1 Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json { \u0026#34;schema\u0026#34;: \u0026#34;{ \\\u0026#34;type\\\u0026#34;: \\\u0026#34;record\\\u0026#34;, \\\u0026#34;name\\\u0026#34;: \\\u0026#34;test\\\u0026#34;, \\\u0026#34;fields\\\u0026#34;: [ { \\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;, \\\u0026#34;name\\\u0026#34;: \\\u0026#34;field1\\\u0026#34; }, { \\\u0026#34;type\\\u0026#34;: \\\u0026#34;int\\\u0026#34;, \\\u0026#34;name\\\u0026#34;: \\\u0026#34;field2\\\u0026#34; } ] }\u0026#34; } Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json { \u0026#34;subject\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;id\u0026#34;: 1 \u0026#34;version\u0026#34;: 3 \u0026#34;schema\u0026#34;: \u0026#34;{ \\\u0026#34;type\\\u0026#34;: \\\u0026#34;record\\\u0026#34;, \\\u0026#34;name\\\u0026#34;: \\\u0026#34;test\\\u0026#34;, \\\u0026#34;fields\\\u0026#34;: [ { \\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;, \\\u0026#34;name\\\u0026#34;: \\\u0026#34;field1\\\u0026#34; }, { \\\u0026#34;type\\\u0026#34;: \\\u0026#34;int\\\u0026#34;, \\\u0026#34;name\\\u0026#34;: \\\u0026#34;field2\\\u0026#34; } ] }\u0026#34; } DELETE /subjects/(string: subject)/versions/(versionId: version) 특정 subject에 등록된 schema의 버전을 삭제한다. 이 API는 호환성 목적으로 이전에 등록한 스키마를 삭제하거나 이전에 등록한 스키마를 다시 등록해야 하는 개발 환경이나 극단적인 상황에서만 사용하는 것이 좋다.\nParameters:\nsubject (string) - subject의 이름\nversion (versionId) - 삭제될 schema 버전을 표시한다. [1, 2^31 - 1] 또는 latest가 될 수 있다.\npermanent (boolean) - ?permanent=true를 추가하여 hard delete를 표시한다.\nResponse JSON Object: int - 삭제된 schema의 버전\nStatus Codes: 404 Not Found - Subject not found or Version not found 422 Unprocessable Entity - Invalid version 500 Internal Server Error - Error in the backend data store\nExample request:\nDELETE /subjects/test/versions/1 HTTP/1.1 Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json 1 GET /subjects/(string: subject)/versions/{versionId: version}/referencedby 주어진 subject와 버전에 대한 schema의 id의 목록을 요청한다.\nParameters:\nsubject (string) - subject의 이름\nversion (versionId) - return 되는 schema 버전을 표시한다. [1, 2^31 - 1] 또는 latest가 될 수 있다.\nRequest JSON Array of Objects: id (int) - 전역적으로 unique한 스키마의 id\nStatus Codes: 404 Not Found - Subject not found 500 Internal Server Error - Error in the backend data store\nExample request:\nGET /subjects/test/versions/1/referencedby HTTP/1.1 Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json [ 1, 2, 3, 4 ] 5. REST API Interface Reference - Compatibility, Config Compatibility compatibility resource는 모든 버전 또는 특정 버전에 대해 사용자가 스키마의 호환성을 검사할 수 있도록 한다.\nPOST /compatibility/subjects/(string: subject)/versions/(versionId: version) input 스키마에 대해서 특정 스키마의 버전에 대한 호환성을 검사한다.\nParameters: subject (string) - 호환성을 테스트할 subject의 이름\nversion (versionId) - 호환성을 테스트할 대상의 schema 버전을 표시한다. [1, 2^31 - 1] 또는 latest가 될 수 있다.\nverbose (boolean) - ?verbose=true를 추가하여 호환성 테스트에 실패하는 이유를 출력한다.\nRequest JSON Object: schema - 스키마의 내용 schemaType - 스키마의 포맷 (default: AVRO) references - 참조된 스키마의 이름을 지정한다. (optional)\nResponse JSON Object: is_compatible (boolean) - 호환가능 여부\nStatus Codes: 404 Not Found - Subject not found or Version not found 422 Unprocessable Entity - Invalid schema or Invalid version 500 Internal Server Error - Error in the backend data store\nExample request:\nPOST /compatibility/subjects/test/versions/latest HTTP/1.1 Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json { \u0026#34;schema\u0026#34;: \u0026#34;{ \\\u0026#34;type\\\u0026#34;: \\\u0026#34;record\\\u0026#34;, \\\u0026#34;name\\\u0026#34;: \\\u0026#34;test\\\u0026#34;, \\\u0026#34;fields\\\u0026#34;: [ { \\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;, \\\u0026#34;name\\\u0026#34;: \\\u0026#34;field1\\\u0026#34; }, { \\\u0026#34;type\\\u0026#34;: \\\u0026#34;int\\\u0026#34;, \\\u0026#34;name\\\u0026#34;: \\\u0026#34;field2\\\u0026#34; } ] }\u0026#34; } Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json { \u0026#34;is_compatible\u0026#34;: true } POST /compatibility/subjects/(string: subject)/versions 호환성 전략에 따라 subject의 하나의 버전 또는 여러 버전의 호환성을 확인한다.\nParameters: subject (string) - 호환성을 테스트할 subject의 이름 verbose (boolean) - **?verbose=true**를 추가하여 호환성 테스트에 실패하는 이유를 출력한다.\nRequest JSON Object: schema - 스키마의 내용 schemaType - 스키마의 포맷 (default: AVRO) references - 참조된 스키마의 이름을 지정한다. (optional)\nResponse JSON Object: is_compatible (boolean) - 호환가능 여부\nStatus Codes: 404 Not Found - Subject not found 422 Unprocessable Entity - Invalid schema 500 Internal Server Error - Error in the backend data store\nExample request:\nPOST /compatibility/subjects/test/versions Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json { \u0026#34;schema\u0026#34;: \u0026#34;{ \\\u0026#34;type\\\u0026#34;: \\\u0026#34;record\\\u0026#34;, \\\u0026#34;name\\\u0026#34;: \\\u0026#34;test\\\u0026#34;, \\\u0026#34;fields\\\u0026#34;: [ { \\\u0026#34;type\\\u0026#34;: \\\u0026#34;string\\\u0026#34;, \\\u0026#34;name\\\u0026#34;: \\\u0026#34;field1\\\u0026#34; }, { \\\u0026#34;type\\\u0026#34;: \\\u0026#34;int\\\u0026#34;, \\\u0026#34;name\\\u0026#34;: \\\u0026#34;field2\\\u0026#34; } ] }\u0026#34; } Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json { \u0026#34;is_compatible\u0026#34;: true } Config PUT /config 전역적 호환성 전략을 변경한다.\nRequest JSON Object:\ncompatibility (string) - 새롭게 변경된 호환성 전략을 표시한다.\nStatus Codes: 422 Unprocessable Entity - Invalid compatibility level 500 Internal Server Error - Error in the backend data store or Error while forwarding request to the primary\nExample request:\nPUT /config HTTP/1.1 Host: kafkaproxy.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json { \u0026#34;compatibility\u0026#34;: \u0026#34;FULL\u0026#34; } Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json { \u0026#34;compatibility\u0026#34;: \u0026#34;FULL\u0026#34; } **GET /config** 전역적 호환성 전략을 요청한다.\nResponse JSON Object:\ncompatibility (string) - 현재 호환성 전략을 표시한다.\nStatus Codes: 500 Internal Server Error - Error in the backend data store\nExample request:\nGET /config HTTP/1.1 Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json { \u0026#34;compatibilityLevel\u0026#34;: \u0026#34;FULL\u0026#34; } PUT /config/(string: subject) 특정 subject에 대한 호환성 전략을 변경한다.\nParameters: subject (string) - subject의 이름\nRequest JSON Object: compatibility (string) - 새롭게 변경된 호환성 전략을 표시한다.\nStatus Codes: 422 Unprocessable Entity - Invalid compatibility level 500 Internal Server Error - Error in the backend data store or Error while forwarding request to the primary\nExample request:\nPUT /config/test HTTP/1.1 Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json { \u0026#34;compatibility\u0026#34;: \u0026#34;FULL\u0026#34; } Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json { \u0026#34;compatibility\u0026#34;: \u0026#34;FULL\u0026#34; } GET /config/(string: subject) 특정 subject에 대한 호환성 전략을 요청한다.\nParameters:\nsubject (string) - subject의 이름\ndefaultToGlobal (boolean) - **?defaultToBlobal=false**를 추가하여 호환성을 표시한다.\n**?defaultToBlobal=true**를 추가하면 호환성 검사에 필요한 사항을 표시한다.\nResponse JSON Object: compatibility (string) - 현재 호환성 전략을 표시한다.\nStatus Codes: 404 Not Found - Subject not found 500 Internal Server Error - Error in the backend data store\nExample request:\nGET /config/test HTTP/1.1 Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json { \u0026#34;compatibilityLevel\u0026#34;: \u0026#34;FULL\u0026#34; } DELETE /config/(string: subject) 특정 subject에 대한 호환성 전략을 삭제하고, 전역적 호환성 전략을 사용한다.\nParameters:\nsubject (string) - subject의 이름\nStatus Codes: 404 Not Found - Subject not found 500 Internal Server Error - Error in the backend data store\nExample request:\nDELETE /config/test HTTP/1.1 Host: schemaregistry.example.com Accept: application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json Example response:\nHTTP/1.1 200 OK Content-Type: application/vnd.schemaregistry.v1+json { \u0026#34;compatibility\u0026#34;: \u0026#34;NONE\u0026#34; } 6. Subject Name Strategy subject 이름을 만들어 내기 위한 subject naming strategy가 있다.\nStrategy 설명 TopicNameStrategy (default) - topic 이름으로부터 subject의 이름을 만든다.- 항상 하나의 topic에 있는 메세지는 같은 schema를 가지는 것을 보장한다. RecordNameStrategy - record 이름으로부터 subject의 이름을 만들고, subject 아래에 서로 다른 schema를 가질 수 있는 논리적으로 관련된 그룹화를 제공한다.- 하나의 topic에 여러개의 schema를 가지는 것을 허용한다.- 이 전략은 메세지가 서로 다른 데이터 구조를 가질때 유용하게 사용할 수 있다. TopicRecordNameStrategy - topic과 record 이름으로부터 subject의 이름을 만들고, subject 아래에 서로 다른 schema를 가질 수 있는 논리적으로 관련된 그룹화를 제공한다.- 하나의 topic에 여러개의 schema를 가지는 것을 허용한다.- 이 전략은 메세지가 서로 다른 데이터 구조를 가질때 유용하게 사용할 수 있다. Reference https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html# ","permalink":"https://jo-minjun.github.io/notes/schema-registry/","summary":"1. Schema registry 란? 데이터 관리의 중요한 관점들 중 하나는 schema의 버전 관리이다. 응용프로그램의 시간이 지날수록 schema가 정의되기 시작한 시점부터 schema는 점점 바뀌어가고, producer와 consumer는 직접적인 관계가 끊어져있기 때문에 운영상에 발생하는 이슈가 있다.\nproducer는 consumer가 어떤 메세지를 소비할지 알 수 없다.\nconsumer는 producer가 어떤 메세지를 생산했는지 알 수 없다.\n위와 같은 상황에서 producer가 갑자기 다른 schema를 이용해서 메세지를 생산할 경우, consumer는 이 메세지에 대해서 대처하지 못할 수 있다.\n이는 구조적인 결합도는 낮지만, 메세지 schema에 대한 의존성이 높기 때문인데, schema registry는 이를 보완하기 위해 고안되었다.","title":"Schema registry란?"},{"content":"1. 스프링이란? 스프링의 생태계 필수: 스프링 프레임워크, 스프링 부트\n선택: 스프링 데이터, 스프링 세션, 스프링 시큐리티, 스프링 Rest Docs, 스프링 배치, 스프링 클라우드\n가장 중요한 것: 스프링 프레임워크 핵심 기술: 스프링 DI 컨테이너, AOP, 이벤트, 기타 웹 기술: 스프링 MVC, 스프링 webFlux 데이터 접근 기술: 트랜잭션, JDBC, ORM 지원, XML 지원 기술 통합: 캐시, 이메일, 원격접근, 스케줄링 테스트: 스프링 기반 테스트 지원 언어: 코틀린, 그루비 *최근에는 스프링 부트를 통해서 스프링 프레임워크의 기술들을 편리하게 사용한다.\n*스프링 부트:\n스프링을 편리하게 사용할 수 있도록 지원, 최근에는 기본으로 사용 단독으로 실행할 수 있는 스프링 애플리케이션을 쉽게 생성 Tomcat 같은 웹 서버를 내장해서 별도의 웹 서버를 설치하지 않아도 됨 손쉬운 빌드 구성을 위한 starter 종속성 제공 스프링과 3rd party(외부) 라이브러리 자동 구성 메트릭, 상태 확인, 외부 구성 같은 프로덕션 준비 기능 제공 관례에 의한 간결한 설정 스프링 부트는 스프링 프레임워크를 기반으로 나머지 외부 라이브러리를 자동으로 구성해주는 기술이지, 자체적으로 사용할 수 있는 것이 아님 스프링의 의미 스프링이라는 단어는 문맥에 따라 다르게 사용된다. 스프링 DI 컨테이너 기술 스프링 프레임워크 스프링 부트, 스프링 프레임워크 등을 모두 포함한 스프링 생태계 스프링의 핵심 개념 자바 언어 기반의 프레임워크 자바 언어의 가장 큰 특징 - 객체 지향 언어 스프링은 객체 지향 언어가 가진 강력한 특징을 살려내는 프레임워크 스프링은 좋은 객체 지향 애플리케이션을 개발할 수 있게 도와주는 프레임워크 객체 지향 프로그래밍은 스프링의 근원 2. 좋은 객체 지향 프로그래밍이란? 객체 지향 프로그래밍이란? 프로그램을 명령어의 목록으로 보는 시각에서 벗어나 여러개의 독립된 단위, 즉 “객체\u0026ldquo;들의 모임으로 파악하고자 하는 것이다. 각각의 객체는 메세지를 주고받고 데이터를 처리한다. (협력) 객체 지향 프로그래밍은 프로그램을 유연하고 변경이 용이하게 만들기 때문에 대규모 소프트웨어 개발에 많이 사용된다. 유연하고 변경이 용이?\n레고 블럭 조립하듯이 키보드, 마우스 갈아 끼우듯이 컴퓨터 부품 갈아 끼우듯이 컴포넌트를 쉽고 유연하게 변경하면서 개발할 수 있는 방법 객체 지향의 특징 추상화 캡슐화 상속 다형성 → 유연하고 변경이 용이하도록 하는데에 크게 기여함 다형성의 실세계 비유 실세계와 객체 지향이 1:1로 매칭되지는 않음 그러나 실세계의 비유로 이해하기 편리함 역할과 구현으로 세상을 구분 운전자 - 자동차 예시\n자동차의 역할(인터페이스)을 3개의 자동차로 구현함 운전자는 K3를 타다가 아반떼로 차를 변경할 수 있음 차가 바뀌어도 운전자는 운전을 할 수 있음 → 유연하고 변경이 용이 클라이언트에 영향을 주지 않고, 새로운 기능을 제공할 수 있음 → 유연하고 변경이 용이 이외의 예시\n공연에서 각 인물의 역할 키보드, 마우스, 세상의 표준 인터페이스들 정렬 알고리즘 할인 정책 예시\n역할과 구현을 분리 역할과 구현으로 구분하면 세상이 단순해지고 유연해지며, 변경도 편리해진다. 장점 클라이언트는 대상의 역할(인터페이스)만 알면 된다. 클라이언트는 구현 대상의 내부 구조를 몰라도 된다. 클라이언트는 구현 대상의 내부 구조가 변경되어도 영향을 받지 않는다. 클라이언트는 구현 대상 자체를 변경해도 영향을 받지 않는다. 자바 언어에서의 역할과 구현 자바 언어의 다형성을 활용 역할: 인터페이스 구현: 인터페이스를 구현한 클래스, 구현 객체 객체를 설계할 때 역할과 구현을 명확히 분리 객체 설계시 역할(인터페이스)을 먼저 부여하고, 그 역할을 수행하는 구현 객체 만들기 (구현보다 역할이 중요하다.) 객체의 협력이라는 관계부터 생각 혼자있는 객체는 없다. 클라이언트: 요청 서버: 응답 수 많은 객체 클라이언트와 객체 서버는 서로 협력 관계를 가진다. 자바 언어의 다형성 오버라이딩을 떠올려보자 오버라이딩된 메서드가 실행 다형성으로 인터페이스를 구현한 객체를 실행 시점에 유연하게 변경할 수 있다. 물론 상속 관계도 다형성, 오버라이딩 적용 가능 public class MemberService { private MemberRepository memberRepository1 = new MemoryMemberRepository(); private MemberRepository memberRepository2 = new JdbcMemberRepository(); } 다형성의 본질 인터페이스를 구현한 객체 인스턴스를 실행 시점에 유연하게 변경할 수 있다. 다형성의 본질을 이해하려면 협력이라는 객체 사이의 관계에서 시작해야함 클라이언트를 변경하지 않고, 서버의 구현 기능을 유연하게 변경할 수 있다. 역할과 구현을 분리 - 정리 실세계의 역할과 구현이라는 편리한 컨셉을 다형성을 통해 객체 세상으로 가져올 수 있음 유연하고, 변경이 용이 확장 가능한 설계 클라이언트에 영향을 주지 않는 변경 가능 인터페이스를 안정적으로 잘 설계하는 것이 중요 역할과 구현을 분리 - 한계 역할(인터페이스) 자체가 변하면 클라이언트, 서버 모두에 큰 변경이 발생한다. 자동차를 비행기로 변경해야 한다면? 대본 자체가 변경된다면? USB 인터페이스 자체가 변경된다면? 인터페이스를 안정적으로 잘 설계하는 것이 중요 스프링과 객체 지향 다형성이 가장 중요하다! 스프링은 다형성을 극대화해서 이용할 수 있게 도와준다. 스프링에서 이야기하는 제어의 역전(IoC), 의존관계 주입(DI)은 다형성을 활용해서 역할과 구현을 편리하게 다룰 수 있도록 지원한다. 스프링을 사용하면 마치 레고 블럭 조립하듯이, 공연 무대의 배우를 선택하듯이, 구현을 편리하게 변경할 수 있다. 그리고 또 중요한 것 - SOLID 3. 좋은 객체 지향 설계의 5가지 원칙 (SOLID) SOLID 클린코드로 유명한 로버트 마틴이 좋은 객체 지향 설계의 5가지 원칙을 정리\nSRP: 단일 책임 원칙 (Single Responsibility Principle) OCP: 개방 - 폐쇄 원칙 (Open - Closed Principle) LSP: 리스코프 치환 원칙 (Liskov Substitution Principle) ISP: 인터페이스 분리 원칙 (Interface Segregation Principle) DIP: 의존관계 역전 원칙 (Dependency Inversion Principle) SRP: 단일 책임 원칙 (Single Responsibility Principle) 한 클래스는 하나의 책임만 가져야 한다. 하나의 책임이라는 것은 모호하다. 클 수 있고, 작을 수 있다. 문맥과 상황에 따라 다르다. 중요한 기준은 변경이다. 변경이 있을 때 파급효과가 적으면 단일 책임 원칙을 잘 따른 것 Ex) UI 변경, 객체의 생성과 사용을 분리 OCP: 개방 - 폐쇄 원칙 (Open - Closed Principle) 가장 중요한 원칙 소프트웨어 요소는 확장에는 열려있으나 변경에는 닫혀있어야 한다. 다형성을 활용 인터페이스를 구현한 클래스를 하나 만들어서 새로운 기능을 구현 지금까지 배운 역할과 구현의 분리를 생각해보자 Ex) 운전자 - 자동차 자동차가 바뀌어도 운전자는 똑같이 운전함 → 확장에 열림 문제점 MemberService 클라이언트가 구현 클래스를 직접 선택 public class MemberService { // 기존 코드 // private MemberRepository memberRepository1 = new MemoryMemberRepository(); // 변경 코드 private MemberRepository memberRepository2 = new JdbcMemberRepository(); } 구현 객체를 변경하려면 클라이언트 코드를 변경해야 한다. 다형성을 사용했지만 OCP 원칙을 지킬 수 없다. 객체를 생성하고, 연관관계를 맺어주는 별도의 조립, 설정자가 필요하다. 이 역할을 스프링 컨테이너가 해결해줌 LSP: 리스코프 치환 원칙 (Liskov Substitution Principle) 프로그램의 객체는 프로그램의 정확성을 깨뜨리지 않으면서 하위 타입의 인스턴스를 바꿀 수 있어야 한다. 다형성에서 하위 클래스는 인터페이스 규약을 다 지켜야 한다는 것 다형성을 지원하기 위한 원칙 인터페이스를 구현한 구현체를 믿고 사용하려면 이 원칙이 필요하다. 단순히 컴파일에 성공하는 것을 넘어서는 이야기 Ex) 자동차 인터페이스의 엑셀은 앞으로 가라는 기능 → 뒤로가게 구현하면 리스코프 치환 원칙 위반 ISP: 인터페이스 분리 원칙 (Interface Segregation Principle) 특정 클라이언트를 위한 인터페이스 여러 개가 범용 인터페이스 하나보다 낫다. 자동차 인터페이스 → 운전 인터페이스, 정비 인터페이스로 분리 사용자 클라이언트 → 운전자 클라이언트, 정비사 클라이언트로 분리 분리하면 정비 인터페이스 자체가 변해도 운전자 클라이언트에 영향을 주지 않음 인터페이스가 명확해지고, 대체 가능성이 높아진다. DIP: 의존관계 역전 원칙 (Dependency Inversion Principle) “추상화에 의존해야지, 구체화에 의존하면 안된다.” 이 원칙을 따르는 방법 중 하나다. 쉽게 이야기 해서 구현 클래스에 의존하지 말고, 인터페이스에 의존하라는 뜻 앞에서 이야기한 역할에 의존하게 해야 한다는 것과 같다. 객체 세상도 클라이언트가 인터페이스에 의존해야 유연하게 구현체를 변경할 수 있다. 구현체에 의존하게 되면 변경이 아주 어려워진다. Ex) 운전자 - 자동차 운전자는 운전 역할에 의존해야지, 자동차 종류에 의존할 경우 차량이 바뀌면 운전이 어려워짐 그런데 개방 - 폐쇄 원칙에서 설명한 MemberService는 인터페이스에 의존하지만, 구현 클래스도 동시에 의존한다. MemberService가 구현 클래스를 직접 선택 → DIP 위반 정리 객체 지향의 핵심은 다형성 다형성만으로는 쉽게 부품을 갈아 끼우듯이 개발할 수 없다. 다형성만으로는 구현 객체를 변경할 때 클라이언트 코드도 함께 변경된다. 다형성만으로는 개방 - 폐쇄 원칙, 의존관계 역전 원칙을 지킬 수 없다. 4. 객체 지향 설계와 스프링 왜 스프링 이야기에 객체 지향이야기가 나오는가? 스프링은 다음 기술로 다형성 + 개방 - 폐쇄 원칙, 의존관계 역전 원칙을 가능하게 지원한다. DI (Dependency Injection): 의존관계, 의존성 주입 DI 컨테이너 제공 클라이언트 코드의 변경 없이 기능 확장 쉽게 부품을 교체하듯이 개발 총 정리 모든 설계에 역할과 구현을 분리하자 자동차, 공연의 예를 떠올려보자 애플리케이션 설계도 공연을 설계하듯이 배역만 만들어두고, 배우는 언제든지 유연하게 변경할 수 있도록 만드는 것이 좋은 객체 지향 설계이다. 이상적으로는 모든 설계에 인터페이스를 부여하자. 실무 고민 하지만 인터페이스를 도입하면 추상화라는 비용이 발생한다. 인터페이스도 만들고 구현체도 만들고 개발자가 구현된 코드가 안보여서 한 번더 열어봐야 됨 기능을 확장할 가능성이 없다면 구체 클래스를 직접 사용하고, 향후에 꼭 필요할 때 리팩토링을 해서 인터페이스를 도입하는 것도 방법이다. Reference 인프런 강의 스프링 핵심 원리(김영한) ","permalink":"https://jo-minjun.github.io/notes/spring-core-basic/","summary":"1. 스프링이란? 스프링의 생태계 필수: 스프링 프레임워크, 스프링 부트\n선택: 스프링 데이터, 스프링 세션, 스프링 시큐리티, 스프링 Rest Docs, 스프링 배치, 스프링 클라우드\n가장 중요한 것: 스프링 프레임워크 핵심 기술: 스프링 DI 컨테이너, AOP, 이벤트, 기타 웹 기술: 스프링 MVC, 스프링 webFlux 데이터 접근 기술: 트랜잭션, JDBC, ORM 지원, XML 지원 기술 통합: 캐시, 이메일, 원격접근, 스케줄링 테스트: 스프링 기반 테스트 지원 언어: 코틀린, 그루비 *최근에는 스프링 부트를 통해서 스프링 프레임워크의 기술들을 편리하게 사용한다.","title":"객체 지향 설계와 스프링"},{"content":"1. kafka 란? apache kafka는 오픈 소스 분산 이벤트 스트리밍 플랫폼이다.\n*데이터 파이프 라인 구성시, 주로 사용되는 오픈 소스로 대용량 실시간 로그 처리에 특화되어 많은 사람들이 사용하고 있다.\n*데이터 파이프 라인: 데이터 처리 단계의 출력이 다음 단계의 입력으로 이어지는 형태로 연결된 구조를 가리킨다.\n2. kafka의 특성 2.1. Publisher-Subscriber 모델 Publisher-Subscriber 모델은 중간에 데이터 큐를 두고 서로 간 독립적으로 데이터를 생산하고 소비한다.\n이러한 구조를 통해, Publisher나 Subscriber에 장애가 생겨도, 독립적이기 때문에 안정적으로 데이터를 처리할 수 있다.\n2.2. 고가용성 및 확장성 (High availablility and Scalability) kafka는 cluster 구조로 데이터를 분산하여 저장한다.\n따라서 하나의 broker에 장애가 생겨도 가용성이 높다.\n또한 클러스터를 수평적으로 늘려 안정성 및 성능을 향상시키는 Scale-out이 가능하다.\n2.3. 디스크 순차 저장 및 처리 메세지를 메모리 큐에 적재하는 기존 메세지 시스템과 달리 kafka는 메세지를 디스크에 순차적으로 저장한다.\n따라서\n서버에 장애가 나도 메세지가 디스크에 저장되어 안정성이 높고 순차적으로 저장되어 I/O작업이 줄어들어 성능이 좋아진다.\n2.4. 분산 처리 kafka는 partition을 통해 여러개의 partition을 여러개의 서버에 분산시켜 나누어 처리할 수 있다.\n3. kafka의 구조 3.1. Publisher-Subscriber 모델 Pub-Sub (발행-구독) 모델은 특정 시스템에 직접 메세지를 전달하는 시스템이 아니다.\npublisher은 메세지를 *Topic을 통해서 분류하여 관리하고, receiver은 전달받기를 원하는 *Topic을 구독하여 메세지를 전달 받는다.\n즉 *kafka cluster를 중심으로 producer가 push하고, consumer가 메세지를 pull하는 구조이다.\n*kafka cluster: kafka 서버 (broker)로 이루어진 클러스터를 말한다.\nbroker: 메세지 중계 역할을 하는 kafka서버를 말한다.\n*topic: kafka cluster에 메세지를 관리할 때, 기준이 되는 논리적 모델이다. 여러개를 생성할 수 있으며, 하나의 topic은 1개 이상의 partition으로 구성되어 있다.\npartition: 토픽에서 메세지를 분산 처리하는 단위이다. 토픽을 partition으로 나누어 나눈 만큼 분산 처리를 한다. kafka option에서 지정한 replica (replication factor)의 수만큼 partition이 broker들에게 복제된다.\nleader \u0026amp; follower: kafka 에서는 복제된 partition들 중에서 하나의 leader가 선출된다. leader는 read, write 연산을 담당하며, follower들은 leader의 메세지를 복사한다. leader partition이 포함된 broker에서 장애가 발생하면 follower partition들 중 하나가 leader가 된다.\n*consumer group - 상세 설명: consumer의 집합을 구성하는 단위이다. kafka에서는 consumer group 단위로 메세지를 처리하고, consumer group의 consumer 수만큼 파티션의 데이터를 분산처리하게 된다.\n*offset - 상세 설명: consumer group들은 partition의 offset을 기준으로 데이터를 순차적으로 처리한다.\n3.1.1. consumer group\n여러개의 producer 들이 메세지를 전달하는 속도가 consumer가 메세지를 처리하는 속도보다 빠르면 하나의 consumer 만으로는 전달되는 메세지를 모두 처리할 수 없다.\n따라서 consumer group을 통해 메세지를 처리한다.\nconsumer group은 같은 토픽의 여러개의 partition을 분담하여 처리하게 된다.\n가령 partition의 수가 4개이고, consumer group의 consumer가 2개라면 각 consumer는 2개씩의 partition을 분담하여 메세지를 처리한다. 또한, partition의 수가 consumer group의 consumer 수보다 적다면 partition을 분담하지 못한 consumer는 idle이 된다.\n3.1.2. offset\nproducer는 메세지를 순차적으로 전달하고 디스크에 순차적으로 저장한다. 따라서 저장된 메세지 뒤에 세로운 메세지를 붙이는 append 방식으로 write를 진행한다. 이 때 partition 들은 각 메세지의 순차적인 위치인 offset으로 구성된다.\n따라서 offset은 partition 내에서 메세지의 위치를 표시하는 유니크한 숫자이다. consumer는 자신이 어디까지 메세지를 처리했는지 offset을 이용해서 관리한다.\n4. zookeeper 란? zookeeper는 분산 애플리케이션이 안정적으로 서비스될 수 있도록 각 애플리케이션의 구성 정보를 중앙 집중시키고, 네이밍, 동기화 등의 서비스를 지원한다.\nzookeeper 여러개를 하나의 클러스터로 구성하고, 각각의 zookeeper 서버는 클라이언트 애플리케이션과 커넥션을 유지하며, 상태 정보를 공유한다.\n상태 정보는 zookeeper의 데이터 레지스터의 공유 계층 name space에 저장된다. 그리고 이 공간을 znode라고 부른다.\nznode는 key-value 형태이며, 자식 노드를 가지고 있는 계층형 구조로 구성되어 있다.\nzookeeper는 클러스터로 구성될 시 몇개의 서버가 다운되더라도 과반수 구조에 의해 서비스가 유지된다.\n따라서 일반적으로 클러스터는 홀수개의 서버로 구성된다.\n3대 구성 클러스터: 1대 down, 2대 up: 서비스가 유지된다. 2대 down, 1대 up: 서비스가 유지되지 않는다.\n","permalink":"https://jo-minjun.github.io/notes/kafka/","summary":"1. kafka 란? apache kafka는 오픈 소스 분산 이벤트 스트리밍 플랫폼이다.\n*데이터 파이프 라인 구성시, 주로 사용되는 오픈 소스로 대용량 실시간 로그 처리에 특화되어 많은 사람들이 사용하고 있다.\n*데이터 파이프 라인: 데이터 처리 단계의 출력이 다음 단계의 입력으로 이어지는 형태로 연결된 구조를 가리킨다.\n2. kafka의 특성 2.1. Publisher-Subscriber 모델 Publisher-Subscriber 모델은 중간에 데이터 큐를 두고 서로 간 독립적으로 데이터를 생산하고 소비한다.\n이러한 구조를 통해, Publisher나 Subscriber에 장애가 생겨도, 독립적이기 때문에 안정적으로 데이터를 처리할 수 있다.","title":"Kafka란?"}]